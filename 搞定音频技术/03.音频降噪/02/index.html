<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog/umi.css" />
    <script>
      window.routerBase = "/blog";
    </script>
    <script>
      //! umi version: 3.5.17
    </script>
    <script>
      !(function () {
        var e = localStorage.getItem("dumi:prefers-color"),
          t = window.matchMedia("(prefers-color-scheme: dark)").matches,
          r = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === r[2] ? (t ? r[1] : r[0]) : r.indexOf(e) > -1 ? e : r[0]
        );
      })();
    </script>
    <title>06｜如何将AI技术运用到降噪中？</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/搞定音频技术/03.音频降噪/02" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog/编译原理之美">编译原理之美</a></li><li><a href="/blog/编译原理实战">编译原理实战</a></li><li><a href="/blog/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog/详解http">详解http</a></li><li><a href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/网络排查案例课">网络排查案例课</a></li><li><a href="/blog/linux操作系统">linux操作系统</a></li><li><a href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/程序员数学基础">程序员数学基础</a></li><li><a href="/blog/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog/操作系统实战">操作系统实战</a></li><li><a href="/blog/软件工程之美">软件工程之美</a></li><li><a href="/blog/sql必知必会">sql必知必会</a></li><li><a href="/blog/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog/网络编程实战">网络编程实战</a></li></ul></span><span>算法<ul><li><a href="/blog/常用算法25讲">常用算法25讲</a></li><li><a href="/blog/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog/浏览器工作原理与实践">浏览器工作原理与实践</a></li><li><a href="/blog/新时代产品经理进阶之路">新时代产品经理进阶之路</a></li><li><a href="/blog/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog/flutter核心技术与实战">flutter核心技术与实战</a></li><li><a href="/blog/java-script核心原理解析">java-script核心原理解析</a></li><li><a href="/blog/说透低代码">说透低代码</a></li><li><a href="/blog/nodejs应用开发实战">nodejs应用开发实战</a></li><li><a href="/blog/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li><li><a href="/blog/reactnative新架构实战课">reactnative新架构实战课</a></li><li><a href="/blog/正则表达式入门">正则表达式入门</a></li><li><a href="/blog/重学前端">重学前端</a></li><li><a href="/blog/serverless入门课">serverless入门课</a></li><li><a href="/blog/type-script入门实战笔记">type-script入门实战笔记</a></li><li><a href="/blog/图解googlev8">图解googlev8</a></li><li><a href="/blog/vue3源码分析">vue3源码分析</a></li><li><a href="/blog/玩转Vue3全家桶">玩转Vue3全家桶</a></li><li><a href="/blog/webassembly入门">webassembly入门</a></li><li><a href="/blog/手把手带你写一个Web框架">手把手带你写一个Web框架</a></li><li><a href="/blog/web漏洞挖掘实战">web漏洞挖掘实战</a></li><li><a href="/blog/跟月影学可视化">跟月影学可视化</a></li><li><a aria-current="page" class="active" href="/blog/搞定音频技术">搞定音频技术</a></li><li><a href="/blog/攻克视频技术">攻克视频技术</a></li></ul></span><span>前端工程化<ul><li><a href="/blog/logger">logger</a></li><li><a href="/blog/webpack">webpack</a></li><li><a href="/blog/webpackChain">webpackChain</a></li></ul></span><span>前端性能优化<ul><li><a href="/blog/react性能调优">react性能调优</a></li></ul></span><span>软件测试<ul><li><a href="/blog/全链路压测实战30讲">全链路压测实战30讲</a></li><li><a href="/blog/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog/自动化测试高手课">自动化测试高手课</a></li><li><a href="/blog/软件测试52讲">软件测试52讲</a></li></ul></span><span>面试<ul><li><a href="/blog/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a href="/blog/Git实战手册">Git实战手册</a></li><li><a href="/blog/NodeJS">NodeJS</a></li><li><a href="/blog/ReactJS">ReactJS</a></li><li><a href="/blog/UI设计">UI设计</a></li><li><a href="/blog/webpack4系列教程">webpack4系列教程</a></li><li><a href="/blog/前端知识体系">前端知识体系</a></li><li><a href="/blog/剑指offer刷题笔记">剑指offer刷题笔记</a></li><li><a href="/blog/思考与成长">思考与成长</a></li><li><a href="/blog/设计模式手册">设计模式手册</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog/编译原理之美">编译原理之美</a></li><li><a href="/blog/编译原理实战">编译原理实战</a></li><li><a href="/blog/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog/详解http">详解http</a></li><li><a href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/网络排查案例课">网络排查案例课</a></li><li><a href="/blog/linux操作系统">linux操作系统</a></li><li><a href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/程序员数学基础">程序员数学基础</a></li><li><a href="/blog/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog/操作系统实战">操作系统实战</a></li><li><a href="/blog/软件工程之美">软件工程之美</a></li><li><a href="/blog/sql必知必会">sql必知必会</a></li><li><a href="/blog/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog/网络编程实战">网络编程实战</a></li></ul></li><li>算法<ul><li><a href="/blog/常用算法25讲">常用算法25讲</a></li><li><a href="/blog/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog/浏览器工作原理与实践">浏览器工作原理与实践</a></li><li><a href="/blog/新时代产品经理进阶之路">新时代产品经理进阶之路</a></li><li><a href="/blog/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog/flutter核心技术与实战">flutter核心技术与实战</a></li><li><a href="/blog/java-script核心原理解析">java-script核心原理解析</a></li><li><a href="/blog/说透低代码">说透低代码</a></li><li><a href="/blog/nodejs应用开发实战">nodejs应用开发实战</a></li><li><a href="/blog/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li><li><a href="/blog/reactnative新架构实战课">reactnative新架构实战课</a></li><li><a href="/blog/正则表达式入门">正则表达式入门</a></li><li><a href="/blog/重学前端">重学前端</a></li><li><a href="/blog/serverless入门课">serverless入门课</a></li><li><a href="/blog/type-script入门实战笔记">type-script入门实战笔记</a></li><li><a href="/blog/图解googlev8">图解googlev8</a></li><li><a href="/blog/vue3源码分析">vue3源码分析</a></li><li><a href="/blog/玩转Vue3全家桶">玩转Vue3全家桶</a></li><li><a href="/blog/webassembly入门">webassembly入门</a></li><li><a href="/blog/手把手带你写一个Web框架">手把手带你写一个Web框架</a></li><li><a href="/blog/web漏洞挖掘实战">web漏洞挖掘实战</a></li><li><a href="/blog/跟月影学可视化">跟月影学可视化</a></li><li><a aria-current="page" class="active" href="/blog/搞定音频技术">搞定音频技术</a></li><li><a href="/blog/攻克视频技术">攻克视频技术</a></li></ul></li><li>前端工程化<ul><li><a href="/blog/logger">logger</a></li><li><a href="/blog/webpack">webpack</a></li><li><a href="/blog/webpackChain">webpackChain</a></li></ul></li><li>前端性能优化<ul><li><a href="/blog/react性能调优">react性能调优</a></li></ul></li><li>软件测试<ul><li><a href="/blog/全链路压测实战30讲">全链路压测实战30讲</a></li><li><a href="/blog/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog/自动化测试高手课">自动化测试高手课</a></li><li><a href="/blog/软件测试52讲">软件测试52讲</a></li></ul></li><li>面试<ul><li><a href="/blog/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a href="/blog/Git实战手册">Git实战手册</a></li><li><a href="/blog/NodeJS">NodeJS</a></li><li><a href="/blog/ReactJS">ReactJS</a></li><li><a href="/blog/UI设计">UI设计</a></li><li><a href="/blog/webpack4系列教程">webpack4系列教程</a></li><li><a href="/blog/前端知识体系">前端知识体系</a></li><li><a href="/blog/剑指offer刷题笔记">剑指offer刷题笔记</a></li><li><a href="/blog/思考与成长">思考与成长</a></li><li><a href="/blog/设计模式手册">设计模式手册</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog/搞定音频技术">搞定音频技术</a></li><li><a href="/blog/搞定音频技术/01.开篇词">01.开篇词</a><ul><li><a href="/blog/搞定音频技术/01.开篇词/01"><span>开篇词｜实时互动强势发展，如何快速入门音频技术？</span></a></li></ul></li><li><a href="/blog/搞定音频技术/02.音频基础">02.音频基础</a><ul><li><a href="/blog/搞定音频技术/02.音频基础/01"><span>01｜声音是如何保存成数字信号的？</span></a></li><li><a href="/blog/搞定音频技术/02.音频基础/02"><span>02｜如何量化分析语音信号？</span></a></li><li><a href="/blog/搞定音频技术/02.音频基础/03"><span>03｜如何分析与处理音乐信号？</span></a></li><li><a href="/blog/搞定音频技术/02.音频基础/04"><span>04｜如何评价音频质量的好与坏？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog/搞定音频技术/03.音频降噪">03.音频降噪</a><ul><li><a href="/blog/搞定音频技术/03.音频降噪/01"><span>05｜音频降噪如何对症下药？</span></a></li><li><a aria-current="page" class="active" href="/blog/搞定音频技术/03.音频降噪/02"><span>06｜如何将AI技术运用到降噪中？</span></a></li></ul></li><li><a href="/blog/搞定音频技术/04.回声消除">04.回声消除</a><ul><li><a href="/blog/搞定音频技术/04.回声消除/01"><span>07｜如何通过算法自动快速地消除回声？</span></a></li><li><a href="/blog/搞定音频技术/04.回声消除/02"><span>08｜回声消除算法实践指南</span></a></li></ul></li><li><a href="/blog/搞定音频技术/05.音频网络传输">05.音频网络传输</a><ul><li><a href="/blog/搞定音频技术/05.音频网络传输/01"><span>09｜音频编解码器是如何工作的？</span></a></li><li><a href="/blog/搞定音频技术/05.音频网络传输/02"><span>10｜如何选择一个适合你的编解码器？</span></a></li><li><a href="/blog/搞定音频技术/05.音频网络传输/03"><span>11｜网络差怎么办？音频网络传输与抗弱网策略</span></a></li></ul></li><li><a href="/blog/搞定音频技术/06.空间音频">06.空间音频</a><ul><li><a href="/blog/搞定音频技术/06.空间音频/01"><span>12｜空间音频入门：如何实现“声临其境”？</span></a></li><li><a href="/blog/搞定音频技术/06.空间音频/02"><span>13｜如何利用HRTF实现听音辨位？</span></a></li></ul></li><li><a href="/blog/搞定音频技术/07.音频特效生成与算法">07.音频特效生成与算法</a><ul><li><a href="/blog/搞定音频技术/07.音频特效生成与算法/01"><span>14｜音效三剑客：变调、均衡器、混响</span></a></li><li><a href="/blog/搞定音频技术/07.音频特效生成与算法/02"><span>加餐｜音频技术漫谈之好声音是怎么炼成的？</span></a></li><li><a href="/blog/搞定音频技术/07.音频特效生成与算法/03"><span>15｜AI变声：音频AI技术的集大成者</span></a></li></ul></li><li><a href="/blog/搞定音频技术/08.结束语">08.结束语</a><ul><li><a href="/blog/搞定音频技术/08.结束语/01"><span>结束语｜选择比努力更重要</span></a></li><li><a href="/blog/搞定音频技术/08.结束语/02"><span>期末测试｜来赴一场满分之约吧！</span></a></li></ul></li><li><a href="/blog/搞定音频技术/summary">搞定音频技术</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="AI降噪模型的基础知识" data-depth="2"><a href="/blog/搞定音频技术/03.音频降噪/02#ai降噪模型的基础知识"><span>AI降噪模型的基础知识</span></a></li><li title="常见模型结构" data-depth="3"><a href="/blog/搞定音频技术/03.音频降噪/02#常见模型结构"><span>常见模型结构</span></a></li><li title="模型训练方法" data-depth="3"><a href="/blog/搞定音频技术/03.音频降噪/02#模型训练方法"><span>模型训练方法</span></a></li><li title="基于频域掩码的AI降噪算法" data-depth="2"><a href="/blog/搞定音频技术/03.音频降噪/02#基于频域掩码的ai降噪算法"><span>基于频域掩码的AI降噪算法</span></a></li><li title="AI降噪模型的工程部署" data-depth="2"><a href="/blog/搞定音频技术/03.音频降噪/02#ai降噪模型的工程部署"><span>AI降噪模型的工程部署</span></a></li><li title="因果性" data-depth="3"><a href="/blog/搞定音频技术/03.音频降噪/02#因果性"><span>因果性</span></a></li><li title="AI降噪模型存储空间和算力限制" data-depth="3"><a href="/blog/搞定音频技术/03.音频降噪/02#ai降噪模型存储空间和算力限制"><span>AI降噪模型存储空间和算力限制</span></a></li><li title="小结" data-depth="2"><a href="/blog/搞定音频技术/03.音频降噪/02#小结"><span>小结</span></a></li><li title="思考题" data-depth="2"><a href="/blog/搞定音频技术/03.音频降噪/02#思考题"><span>思考题</span></a></li><li title="参考文献" data-depth="2"><a href="/blog/搞定音频技术/03.音频降噪/02#参考文献"><span>参考文献</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="06如何将ai技术运用到降噪中"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#06如何将ai技术运用到降噪中"><span class="icon icon-link"></span></a>06｜如何将AI技术运用到降噪中？</h1><p>你好，我是建元。</p><p>上节课我们讲了噪声的分类和一些常见的传统降噪算法。传统算法通过统计的方法对噪声进行估计，并可以对稳态噪声起到比较好的降噪作用，但是<strong>在非稳态噪声和瞬态噪声等噪声类型下，传统降噪算法往往不能起到比较好的效果</strong>。</p><p>最近几年，随着AI技术的不断演进，在降噪等音频处理领域，都出现了很多基于Artificail Intelligence（AI）或者说基于人工神经网络模型的降噪算法。这些AI算法在降噪能力上较传统算法都有很大的提升。但<strong>AI降噪算法和很多其它AI算法一样，在部署的时候也会受到诸如设备算力、存储体积等条件的限制</strong>。</p><p>这节课就让我们看看AI降噪算法是如何一步步实现的，以及在实时音频互动场景中，我们如何解决AI降噪算法的部署难题。</p><h2 id="ai降噪模型的基础知识"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#ai降噪模型的基础知识"><span class="icon icon-link"></span></a>AI降噪模型的基础知识</h2><p>AI模型也就是我们经常听到的深度学习模型、机器学习模型或人工神经网络模型。其实AI模型的定义更为广泛，后面的这几种说法都是从不同角度描述了目前常用AI模型的特点。</p><p>AI模型的构建普遍采用<strong>大量数据训练</strong>的方式，来让模型学习到数据内隐含的信息，这就是所谓的机器学习。<strong>在降噪这个领域，模型的输入是带噪的语音信号，模型的输出是纯净的语音信号</strong>，我们通过大量的这样成对的带噪和纯净的语音数据，来训练AI模型，使其具有降噪的能力。</p><p>下面我们来看看常见的AI降噪模型的结构，以及AI降噪模型的训练方法。</p><h3 id="常见模型结构"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#常见模型结构"><span class="icon icon-link"></span></a>常见模型结构</h3><p>AI模型常采用人工神经网络来模拟人脑神经的记忆和处理信号的能力。常见的人工神经网络类型有深度神经网络（Deep Neural Network，DNN）、卷积神经网络（Convolutional Neural Network，CNN）、循环神经网络（Recurrent Neural Network，RNN）等。</p><p><strong>DNN</strong></p><p>一个典型的DNN网络结构如图1所示：</p><p><img src="https://static001.geekbang.org/resource/image/8d/7c/8d8d5c380e4bf76e1df94135f2dff87c.png?wh=1711x873" alt="图片" title="图１DNN的结构示意图"/></p><p>可以看到图1中信号从输入层到输出层中间经历了n个隐藏层。每层都是线性连接，并且每层中的圆圈都代表一个神经元。举个例子，图1中隐藏层1中的第一个数$h_<!-- -->{<!-- -->1<!-- -->}<!-- -->$，就是由输入层的（$x_<!-- -->{<!-- -->1<!-- -->}<!-- -->$，$x_<!-- -->{<!-- -->2<!-- -->}<!-- -->$，$x_<!-- -->{<!-- -->3<!-- -->}<!-- -->$）的线性加权得到的，即</p><p>$$h_<!-- -->{<!-- -->1<!-- -->}<!-- -->=w(1,1)x_<!-- -->{<!-- -->1<!-- -->}<!-- -->+w(2,1)x_<!-- -->{<!-- -->2<!-- -->}<!-- -->+w(3,1)x_<!-- -->{<!-- -->3<!-- -->}<!-- -->,$$</p><p>其中$w$就是第一个隐藏层的权重。在DNN的计算中，每个神经元都是前一层的加权平均。这样就可以通过一个多层的线性的网络，来对复杂的信号处理过程建模。</p><p><strong>CNN</strong></p><p>比较典型的CNN网络结构图如图2.1和2.2所示：</p><p><img src="https://static001.geekbang.org/resource/image/4e/33/4ee9a76c1821ab6d3905297418402433.png?wh=1213x713" alt="图片" title="图2.1 一维卷积结构示意图"/></p><p><img src="https://static001.geekbang.org/resource/image/2b/21/2byy747cf60d3d3bfccdaa827f567f21.png?wh=1770x723" alt="图片" title="图2.2 二维卷积结构示意图（邱锡鹏 著，神经网络与深度学习）"/></p><p>图2.1是CNN中的一维卷积的示意图，这里红黄绿三线代表卷积核为（-1,0,1）的卷积计算过程。每一层输出信号都是输入信号和卷积核卷积的结果。比如，输出层中第一个数为$$1\times 1+1\times 0+2\times -1=-1.$$</p><p>图2.2的二维卷积也是同样的道理，只不过二维卷积中输入、输出和卷积核都是二维的。比如结果里右上角的-1，就是由标红的输入矩阵与卷积核做点乘，然后再把得到的结果做累加得到的。</p><p>CNN网络就是由多个这样的一维或者二维的卷积层串联得到的。一维的CNN网络，可以直接在一维音频信号上使用，而二维的CNN网络最早是用于图像这种二维信号的处理。但其实对音频做了STFT后，得到的频谱图也是二维的。所以在频域上做计算时，可以使用二维的CNN网络结构。</p><p><strong>RNN</strong></p><p>典型的RNN网络结构如图3所示：</p><p><img src="https://static001.geekbang.org/resource/image/c5/fc/c57444c3c568da8d2d45d7d1d2cb19fc.png?wh=1020x489" alt="图片" title="图3 RNN网络结构示意图"/></p><p>可以看到RNN网络中隐藏层的每个神经元（粉色圆圈），除了和输入层的信号相关，还和隐藏层本身的状态相关。这种<strong>自回归</strong>的结构是RNN的特点。常见的的RNN网络有<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1503.04069.pdf?fbclid=IwAR377Jhphz_xGSSThcqGUlAx8OJc_gU6Zwq8dABHOdS4WNOPRXA5LcHOjUg">LSTM<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/ftp/arxiv/papers/1701/1701.05923.pdf">GRU<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>等，由于篇幅所限，这里我们不再介绍。如果你有兴趣可以自行查看一下文献。</p><p>从物理含义来解释，如果我们把输入从左到右按照时间来排列，那么RNN的自回归特性可以感知信号在时间轴上的特征。换句话说，每个时间点的隐藏特征，除了由自身信号提取，还可以从前后时间点上的信息来得到。所以RNN在时序建模中是常见的方法。</p><h3 id="模型训练方法"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#模型训练方法"><span class="icon icon-link"></span></a>模型训练方法</h3><p>好的，知道了AI模型的基本结构，我们来看看AI降噪模型是如何训练的。AI模型中大量的参数，比如DNN、RNN中每个神经元的计算权值，以及CNN中的卷积核，都需要依靠训练来得到。</p><p>所谓训练就是，假设我们给予模型$y=f(x)$一个输入$x$，比如1，然后模型可能会计算出$\hat<!-- -->{<!-- -->y<!-- -->}<!-- -->=1.5$，接着我们再告诉模型输出应该是2。这时模型的误差为0.5，而模型就会朝着输入为1时结果为2的方向调整模型的参数值。这样经过多次训练模型就可以拟合出$y$和$x$的之间的映射关系。所以我们只需要准备一组$x$、$y$作为输入和标签数据，就可以开始训练模型了。</p><p>其实AI模型训练按照是否有标签数据分类，可分为<strong>有监督的训练和无监督的训练</strong>。而降噪算法万变不离其宗，目的都是将目标信号与噪声信号分离开来。这节课我们讲的<strong>AI降噪主要是消除人声之外的所有其<strong><strong>它</strong></strong>声音</strong>。所以目标信号主要是语音信号。因此，在降噪模型的训练时，<strong>我们一般用<strong><strong>的</strong></strong>是有监督的训练方式。</strong></p><p>在训练数据里我们一般用纯净的语音作为目标或者说标签，然后用纯净语音加入一些噪声生成含噪数据，作为模型的输入。这里的噪声主要是指环境噪声。回想一下上节课的内容，环境噪声一般为加性噪声，所以在准备训练数据时，我们需要先准备一个纯净语音库和一个噪声库，而含噪的数据可以直接把纯净语音和噪声信号相加来得到。<strong>AI降噪模型训练</strong>的步骤如下：</p><ol><li>通过预处理把含噪数据转换为AI模型的输入信号；</li><li>通过AI降噪模型得到估计的纯净语音信号；</li><li>计算模型估计和实际纯净语音信号的差距，也就是常说的Loss；</li><li>Loss通过反向传播，结合梯度下降的方法更新模型的参数；</li><li>重复步骤1～4直至收敛（也就是Loss下降至一个稳定的数值）。</li></ol><p>其中，步骤3里所说的Loss，可以用均方差（Mean Suqared Error ，MSE)等形式。MSE如下所示：</p><p>$$\text <!-- -->{<!-- -->MSE<!-- -->}<!-- --> =\sum_<!-- -->{<!-- -->i=0<!-- -->}<!-- -->^<!-- -->{<!-- -->N<!-- -->}<!-- -->\frac<!-- -->{<!-- -->{<!-- -->(s_<!-- -->{<!-- -->i<!-- -->}<!-- -->-\hat<!-- -->{<!-- -->s_<!-- -->{<!-- -->i<!-- -->}<!-- -->}<!-- -->)^2<!-- -->}<!-- -->}<!-- -->{<!-- -->N<!-- -->}<!-- -->，$$</p><p>其中$s_<!-- -->{<!-- -->i<!-- -->}<!-- -->$和$\hat<!-- -->{<!-- -->s_<!-- -->{<!-- -->i<!-- -->}<!-- -->}<!-- -->$分别代表纯净语音信号和模型估计的语音信号，$N$表示信号的长度，模型训练的目标就是最小化模型预估和纯净语音信号的差距。<strong>不同Loss的设计会对AI模型的结果产生影响</strong>，而在AI降噪中，还有很多不同Loss的尝试。有兴趣，可以到[参考文献 <a target="_blank" rel="noopener noreferrer" href="http://www.apsipa.org/proceedings/2020/pdfs/0000711.pdf">5<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]中详细了解。</p><p>这样，我们就通过迭代的方法，不断的训练模型，从而得到一组最佳的模型参数。在实际使用的时候，我们就可以用训练好的模型来进行降噪了。那么有了这些基础知识，让我们总结一下作为<strong>一个AI降噪模型的设计者要设计哪些东西</strong>：</p><ol><li>一个AI降噪的模型，包括模型的预处理和后处理流程；</li><li>一个合适的Loss，用于迭代计算模型的参数；</li><li>一个合适的语音信号和噪声信号的数据库，用于模型训练。</li></ol><p>其实AI降噪模型经过这些年的发展，人们已经总结出了一系列比较成熟的方法。基于时域的AI降噪算法，输入和输出都是时域的音频信号，无需任何预处理和后处理，可以实现我们常说的“端到端”处理。具有代表性的模型结构有基于RNN或CNN的TasNet [参考文献 <a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=59c4974257a4dc741c3145275eedbcf1&amp;tn=SE_baiduxueshu_c1gjeupa&amp;ie=utf-8&amp;site=baike">1<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>,<a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1f3q0gx08m160as0364500g01k643100">2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]等。</p><p>而更多的是基于频域信号，进行建模处理的模型。这类模型是对傅里叶变换后的频域信号进行处理，需要先把原始信号经过STFT转换为频谱，然后通过模型和含噪频谱估计出一个纯净语音的频谱，最后需要通过逆STFT作为后处理，将频谱转换为时域的音频信号。其中的代表有基于RNN的RNNoise [参考文献 <a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=cf4024fe7a244ddd949b195443a86ce1&amp;site=xueshu_se">3<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]，或者结合CNN和RNN的CRN模型[参考文献 <a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1w400pe0jn5k0t20tt0b0p30km748020&amp;site=xueshu_se">4<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]。如果你有兴趣，可以看看附录里的文献。</p><p>了解了AI降噪模型的基础知识，接下来我们主要介绍一种最为常用且效果比较好的方法：基于频域掩码的AI降噪算法。</p><h2 id="基于频域掩码的ai降噪算法"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#基于频域掩码的ai降噪算法"><span class="icon icon-link"></span></a>基于频域掩码的AI降噪算法</h2><p>在传统降噪中，我们讲的维纳滤波等方法，都是通过计算先验信噪比，然后在频域上对每一个频谱的频点都乘以一个小于等于1的系数来抑制噪声。<strong>这些在频域上乘的系数我们统称为频域掩码</strong>。而如何计算这个频域掩码就成了解决降噪问题的关键，传统降噪是基于统计的方法来得到这个频域掩码的，而AI算法则是通过人工神经网络模型来对这个频域掩码进行建模的。</p><p><strong>基于频域掩码的AI降噪算法的主要步骤</strong>如下：</p><ol><li>带噪的音频信号经过STFT得到频域信号；</li><li>频域信号作为输入，利用人工神经网络得到频域掩码；</li><li>将第1步中的频域信号乘以频域掩码，得到降噪后的频域信号；</li><li>将降噪后的频域信号做STFT的逆变换得到纯净的语音信号。</li></ol><p>值得一提的是通过STFT后得到的频域信号实际上是复数域的。对复数域的频谱取模就是我们所说的幅度谱（Magnitude Spectrum），它代表不同频点的能量分布。而对复数谱中的实部和虚部的比值求反正切（arctan），可以得到一个取值从-π到+π的相位谱（Phase Spectrum）。如果在频谱上乘以一个0～1的实数频域掩码，则修改的就是幅度谱，而相位谱或者说实部、虚部的比值并没有变化。</p><p><img src="https://static001.geekbang.org/resource/image/71/67/715dbd8471fd055d18d8d5e11efca667.png?wh=778x740" alt="图片" title="图4 基于频域掩码的AI降噪时域和频域对比图\n"/></p><p>如图4所示就是一个基于频域掩码的AI降噪后的对比图，我们可以看到在频谱上噪声的部分能量被抑制了，且在降噪后能看到一个比较清晰的语谱能量分布。</p><p>STFT中相位谱没有可准确描述的物理含义，所以对相位谱的建模会比较困难，而人耳对相位不是很敏感。因此，在传统算法和大部分基于频域掩码的AI算法中，都只对幅度谱进行处理，且模型得到的纯净语音和带噪语音的相位还是一样的。虽然人们对相位的差异感知不是很明显，但不改变相位谱的频域掩码就不能做到对纯净语音的完美重建。听感上还是能听出一些不同。</p><p>近些年，人们开始用AI模型来对相位谱或者说对整个复数域的频谱整体进行建模降噪。其中具有代表性的，如微软的PHASEN和2020DNS降噪比赛中夺冠的DCCRN模型等。若你有兴趣，可以到[参考文献<a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=134f0gg0by2q04y04r4c0cs04x447781&amp;site=xueshu_se">6<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，<a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1x4e00107v100xf0j01g0810em681402&amp;site=xueshu_se">7<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]中自行了解一下。但是在实践中，增加相位谱的恢复相比只对幅度谱做修正，需要消耗更多的算力和模型存储空间，这可能会为模型的部署造成困难。</p><h2 id="ai降噪模型的工程部署"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#ai降噪模型的工程部署"><span class="icon icon-link"></span></a><strong>AI降噪模型的工程部署</strong></h2><p>通常AI模型在算力和模型参数存储上，都比传统的方法要求要更高一些。现在就让我们看看在实时音频系统中部署一个AI降噪模型都需要注意些什么吧。</p><h3 id="因果性"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#因果性"><span class="icon icon-link"></span></a><strong>因果性</strong></h3><p>在RTC等实时音频的应用场景中，降噪处理需要考虑到因果性。也就是说，音频未来的信息是拿不到的。在AI降噪模型的选择中，一些双向的网络结构，比如双向的RNN模型就不能使用。但语音信号是有短时相关性的，如果一点未来的信息都不用，可能会导致模型的降噪能力下降。</p><p>我们可以采用引入一点延迟的方式来提升模型的降噪能力。比如在第i+m帧，输出第i帧的降噪信号，这样就引入了m帧长度的延迟，一般m不超过3。AI模型的输入可以往前看3帧，这种方法也就是我们常说的“look ahead”。</p><h3 id="ai降噪模型存储空间和算力限制"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#ai降噪模型存储空间和算力限制"><span class="icon icon-link"></span></a>AI降噪模型存储空间和算力限制</h3><p>在模型部署的时候，尤其是手机、IOT等移动端的部署，设备的算力和存储空间都会受到限制。这个需要我们在设计模型结构的时候就加以考虑。模型结构、算力复杂度（Computation Complexity）和参数量（Number of Parameters）之间的关系可参考图5：</p><p><img src="https://static001.geekbang.org/resource/image/8e/85/8eb59c0a9f65739c9cb759f0079b0985.png?wh=958x448" alt="图片" title="图5 不同模型结构的算力复杂度和参数量分布"/></p><p>在图5中我们可以看到CNN的参数量最小，这是因为<strong>CNN的卷积核是可以复用计算的</strong>。一般基于纯卷积的模型，它的参数量会比较小，而RNN和DNN本质上都是线性层的计算，所以参数量会比较大。因此，在为移动端等存储空间小的设备设计算法时，会尽量选择CNN，或者CNN结合其它结构的形式来压缩参数量。</p><p>另一方面，我们也可以<strong>通过参数量化的方式来对模型进行压缩</strong>。比如，采用int 8bit的形式对本来float 32bit 格式的参数进行量化。注意，参数量化会对模型的精度产生损伤。对于卷积这种可复用的模型结构就不适合做量化，而RNN、DNN等结构做量化时对精度的损失就没有那么敏感。</p><p>在算力限制方面，我们可以从模型的输入特征着手。比如采用比较小的模型输入，如在RNNoise中就是采用BFCC这种压缩后的频谱特征作为输入，这样输入信号小了，计算量也就降下来了。另外，刚才说的量化对计算速度也会产生影响。在计算芯片支持不同精度的计算的情况下，量化后的计算速度会更快。模型计算时还可以通过对模型参数和输入数据，按照内存连续读取最优的方式进行重排，来进行计算加速。</p><p>我们上面说的量化、加速计算等过程除了自己一个个去完善外，我们在工程部署模型的时候也可以使用一些现成的工具，能帮助我们加速AI模型的部署。下表罗列了一些可以使用的AI模型部署工具：</p><p><img src="https://static001.geekbang.org/resource/image/77/33/77d11393e80c32e273d4b016d06bfe33.png?wh=623x283" alt="" title="表1 常用AI模型部署工具"/></p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#小结"><span class="icon icon-link"></span></a>小结</h2><p>好的，让我们来总结一下这节课的内容。AI模型常用的结构包括DNN、CNN和RNN等。AI降噪模型在结构设计时，可以选择其中一种，也可以把这些结构组合使用。AI降噪模型一般采用有监督的训练方式，并以带噪语音作为模型的输入、纯净语音作为训练的目标。利用反向传播结合梯度下降的方法不断提升模型预估和纯净语音的相似程度。这个相似程度我们一般用，例如MSE等形式的Loss来表示，并且Loss越小，模型得到的结果就越接近于纯净语音。</p><p>和传统降噪类似，基于频域掩码的AI降噪模型是目前最为常用的AI降噪设计。纯净语音频谱的获得，需要对幅度谱和相位谱都进行修正。但如果是在移动端部署AI降噪模型，受算力影响，基于幅度谱的AI降噪模型可能是最好的选择。</p><p>在实时音频信号系统中，降噪模型需要考虑到模型的因果性。在移动端部署时，由于算力和存储空间受到限制，我们需要通过对模型的输入进行降维、模型参数进行量化等操作来进行设备适配。当然我们也可以通过一些现成的工具来快速实现AI降噪模型的部署。</p><p>在实践中，如果你要自己训练一个AI降噪模型，那么数据库（语音、噪声）是不可少的。正好在最近的<a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/DNS-Challenge">DNS challenge<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>的降噪比赛里，主办方为我们整理了不少语音、噪声等数据库，有兴趣可自行了解一下。</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>其实这里AI降噪的模型就是从音频中提取人声部分，如果除了人声之外还想把音乐也保留，那么我们应该怎么设计AI模型的输入和输出呢？</p><p>你可以把你的答案和感受写下来，分享到留言区，与我一起讨论。我们下节课再见。</p><h2 id="参考文献"><a aria-hidden="true" tabindex="-1" href="/blog/搞定音频技术/03.音频降噪/02#参考文献"><span class="icon icon-link"></span></a>参考文献</h2><p><a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=59c4974257a4dc741c3145275eedbcf1&amp;tn=SE_baiduxueshu_c1gjeupa&amp;ie=utf-8&amp;site=baike">1、Luo Y, Mesgarani N. Tasnet: time-domain audio separation network for real-time, single-channel speech separation[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 696-700.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p><a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1f3q0gx08m160as0364500g01k643100">2、Luo Y, Mesgarani N. Conv-tasnet: Surpassing ideal time–frequency magnitude maskingfor speech separation[J]. IEEE/ACM transactions on audio, speech, and language processing, 2019, 27(8): 1256-1266.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p><a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=cf4024fe7a244ddd949b195443a86ce1&amp;site=xueshu_se">3、Valin J M. A hybrid DSP/deep learning approach to real-time full-band speech enhancement[C]//2018 IEEE 20th international workshop on multimedia signal processing (MMSP). IEEE, 2018: 1-5.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p><a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1w400pe0jn5k0t20tt0b0p30km748020&amp;site=xueshu_se">4、Strake M, Defraene B, Fluyt K, et al. Fully convolutional recurrent networks for speech enhancement[C]//ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020: 6674-6678.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p><a target="_blank" rel="noopener noreferrer" href="http://www.apsipa.org/proceedings/2020/pdfs/0000711.pdf">5、Ma C, Li D, Jia X. Optimal scale-invariant signal-to-noise ratio and curriculum learning for monaural multi-speaker speech separation in noisy environment[C]//2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE, 2020: 711-715.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p><a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=134f0gg0by2q04y04r4c0cs04x447781&amp;site=xueshu_se">6、Yin D, Luo C, Xiong Z, et al. PHASEN: A phase-and-harmonics-aware speech enhancement network[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(05): 9458-9465.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p><a target="_blank" rel="noopener noreferrer" href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1x4e00107v100xf0j01g0810em681402&amp;site=xueshu_se">7、Hu Y, Liu Y, Lv S, et al. DCCRN: Deep complex convolution recurrent network for phase-aware speech enhancement[J]. arXiv preprint arXiv:2008.00264, 2020.<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/docs/搞定音频技术/03.音频降噪/02.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">5/2/2022 10:57:07</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog/umi.js"></script>
  </body>
</html>
