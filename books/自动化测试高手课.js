exports.category = "test";
exports.title = "自动化测试高手课";
exports.data = [
  {
    chapterTitle: "开篇词",
    children: [
      {
        title: "开篇词 | 做性价比最高的自动化测试",
        id: 496850,
        content:
          '<p>你好，我是柳胜。很高兴通过这个专栏和你探讨自动化测试。</p><p>先简单介绍一下我自己，我在摩托罗拉和甲骨文做过开发工程师、测试工程师、测试经理和高级开发经理。从B端的企业应用测试到C端的云计算开发，我都做过。在甲骨文工作的13年时间里，我带领团队设计、开发了Automation Center框架，补全了视频会议二十多年来的自动化测试解决方案空白。</p><p>相比开发，我在自动化测试领域里得到的收获最多，教训也最多。因此，我把这些踩坑的血泪史总结沉淀，期待通过专栏的形式分享给你，帮助你在自动化测试的职业工作中，建立全局思维，找准工作的焦点，让手中的测试项目事半功倍。</p><h2>自动化测试的终点是什么？</h2><p>刚入门的自动化测试工程师，很容易陷入到工具和框架的汪洋大海里。的确，从代码静态扫描到单元测试、API测试、系统测试、性能测试，每个细分领域的工具都不少。</p><p>但是，工具之后呢？</p><p>从普通开发到架构师，软件开发的职业体系清晰可见。测试则不然，我观察过业界自动化测试人员的职业发展路线，有的公司有自动化测试架构师这个职位，有的公司设立了测试架构师，自动化架构算作测试架构师的职责之一，更多的公司根本就没有自动化测试的高级角色，各个产品线测试和开发混在一起玩。</p><!-- [[[read_end]]] --><p>我也问过测试业界不少朋友，你的公司为什么要自动化测试？预期的效果是什么？</p><p>答案是五花八门，有的说是节省手工开支，有的说是业界趋势，还有的说我们研发领导非常重视，干就是了。在团队中，基本认识都出现了这么大的差别，后面的乱象就出来了，项目投入不稳定，可多可少跟着感觉走。自动化测试人员严重缺乏表达自己工作价值的话语权，被迫和开发人员一起内卷技术工具。</p><p>经历了这些，你甚至怀疑自动化测试工作的尽头就是工具，随后一边“内卷”，一边在忙碌中更加迷茫。其实，<strong>要想成为高手，就必须要看到并解决更有价值的问题，对更高的结果负责</strong>，对应的职位和收入会随后而至，它可能叫自动化架构师，也可能叫测试专家，或什么ABC。</p><p>既然说到“更高的结果”，我们就有必要以终为始，先想想自动化测试的最终结果是什么？换个问法，自动化测试的最终交付价值是什么？</p><ul>\n<li>是自动化跑起来么？这个要求太初级了。</li>\n<li>是领导满意么？我见过很多案例，一个自动化测试项目因一个领导的支持而发起，但成也萧何，败也萧何，往往也因为换了一个领导，项目就半途而废。</li>\n<li>是100%自动化么？理想很丰满，现实很骨感，高度自动化并不会一定带来高质量，我也见过开发人员为了达到100%单元覆盖率，就写一个Test函数，把程序运行起来了事，有的连一个检查点都不做。</li>\n</ul><p>所有这一切，都让我深深意识到，无法清晰认知自动化测试的价值，测试工作就会举步维艰。在我看来，<strong>自动化测试项目的最终交付价值是它产生的效益，也就是投入回报率比ROI。一个成功的自动化测试项目必然是获得了高ROI的收益</strong>。自动化测试高手就是要做出成功的自动化测试项目。</p><h2>怎样成为高手？</h2><p>明确了目标，我们还需要找到高效的实现路径。</p><p><strong>我对自动化测试架构师的定义是，不仅仅是写代码让自动化测试跑起来，而且能够超脱于工具框架的层面，对测试需求和自动化ROI一起抽象建模，对自动化测试项目的最终ROI负责。</strong></p><p>为了达到这个目标，有两种学习路径。</p><p>第一是升级打怪型。</p><p>先是提高代码能力，学习编程、操作系统和数据库。这个的确很重要，尤其对于刚入门的朋友，首先搞一个Hello World程序，有个感官的体验，后面再逐步深入。</p><p>然后是工具能力，使用各种工具和框架，Xunit系列、API测试框架、系统测试工具，编写自动化测试案例，运行、出报告，之后和DevOps pipeline集成。</p><p>最后是架构能力，熟悉测试需求和技术架构，设计自动化测试整体方案和技术路线，能够选型工具和框架，搭建测试基础设施。</p><p><img src="https://static001.geekbang.org/resource/image/92/16/924b3cec32fba5d78f2e30c072ab1216.jpg?wh=1920x868" alt="图片" title="学习路径1：升级打怪型\n"></p><p>这是我们熟知的自底向上学习路线，是认知方法的归纳法。见过的鱼多了，就知道鱼是什么了，逐渐积累捕鱼的经验。这个方法的优点是门槛低，缺点是耗时，周期长。</p><p>第二种是航海指南型。</p><p>和第一种方法相对应，另外一种认知学习方法是自顶向下，属于认知方法中的演绎法。从道术器三个层面从高到低推进，每一步都有自己的逻辑。</p><p>知道什么是鱼和它的游动规律，就相当于带着导航去捕鱼，甚至你还可以发明新的捕鱼工具。这个方法优点是速度快，但需要你自带脑袋瓜，跟着我一起思考。</p><p><img src="https://static001.geekbang.org/resource/image/b2/f7/b2785904147099d03e217520ed2a21f7.jpg?wh=1920x1080" alt="图片" title="学习路径2：航海指南型"></p><p><strong>专栏中我们采取的学习方法是以自顶向下为主，自底向上为辅。</strong>通过整个专栏的学习，你将系统了解自动化测试的道、术、器，同时收获一种颠覆性的认知，跳出工具和框架的层面重新审视自动化测试设计，知道自己想要什么样的自动化测试架构。</p><p>自动化测试道的部分，主要是逻辑和常识，你不需要有工作经验和技术，也能听得懂，我期望你会和我一起演绎思考，就是说，这些方法如果应用到我的工作，会怎么样。</p><p>术的部分会涉及度量数据分析、代码逻辑和Job建模，这个也对应着软件开发里的数据、算法和建模。我会在GitHub上创建一个<a href="https://github.com/sheng-geek-zhuanlan/autmation-arch">repo</a>（随课程进展陆续更新），放入专栏所讲到的整体代码和相关文件，希望你能动脑思考，动手运行代码。手脑结合，学习效果会更好。</p><p>器，也就是工具和框架。在第三讲里会列出业界主流工具框架以及选择策略和落地实践。在每个模块里也会穿插一些具体的落地案例，介绍相应的工具和代码相关例子。</p><p>不过，本专栏里具体工具和代码的篇幅不会超过20%。我这样克制，是因为这些东西网上搜搜也能免费获取。我会在最后附上全栈自动化测试工具列表，从单元测试到性能测试相关的网站地址。相信你通过自学，就能掌握个七七八八。</p><p>授之以鱼，不如授之以渔。我不希望你一下子扑到工具技术的茫茫大海里，等过几年之后，有一种学不完、学不精、用不好的绝望，这都是我曾经历过的。如果能再来一次，我更愿意早点了解鱼的规律，带着导航驶入大海，有方法地探索，最后满载而归。</p><h2>这门课如何安排</h2><p>课程一共分成了四大模块，分别是：价值篇、策略篇、设计篇与度量篇，自动化测试的道、术、器会贯穿其中。</p><p><img src="https://static001.geekbang.org/resource/image/2c/20/2cc1921668ebda517bf9ab098db23f20.jpg?wh=1920x845" alt="图片" title="专栏模块设计"></p><p><strong>第一模块价值篇</strong>会带你重新审视自动化测试的基本概念和规律，掌握自动化测试效益的量化思维方法——<strong>投入产出比ROI模型</strong>。它是自动化测试项目成长的DNA，也是隐藏的命脉，在工作中紧紧抓住它，效果就来了：自动化测试使用的场景越来越丰富，越来越稳定和可信，交付发布的速度越来越快。</p><p>这些都可以帮你在述职报告中，用ROI的方式表达业绩，比如：“老板，我做的自动化测试案例，去年一年被n个场景使用，重复运行x次，发现bug y个，节省手工工作量z人月”。</p><p>ROI如何落地呢？我们会从立项、设计、代码、运营各个阶段逐步深入解读。</p><p><img src="https://static001.geekbang.org/resource/image/dc/f3/dcba05528c731a2192abd4c31cee9af3.jpg?wh=1920x913" alt="图片" title="四测试阶段ROI落地示意图"></p><p>通过这个模块的学习，你会获得一个新的思维角度，用它来审视自动测试项目，判断项目中哪些是过度工作，哪些是工作做得还不够。同时你也掌握了一门和管理者和团队沟通的语言，在述职、评审等交流环节，能把自己工作的价值表达清楚。</p><p>到了<strong>第二模块策略篇</strong>，我们会从一个订餐系统的例子出发，从单体应用升级到微服务集群，来观察测试需求的变化。针对微服务集群关系复杂、依赖多的挑战，建立起多层测试策略：单元测试、集成测试、接口测试、契约测试、UI测试和验收测试，通过逐层测试来全面验证需求。</p><p>每一种测试策略，我会用一讲的篇幅来讲述它的方法论和工具，能做什么、不能做什么，如何设计自动化测试案例。</p><p>在<strong>第三模块设计篇</strong>，我们一起推演模型设计。像开发的设计模式一样，自动化测试设计也应该有自己的方法论。</p><p>这里我提出的微测试Job模型，也是业界首创，会让你耳目一新。在这个Job模型里，没有TestSuite和TestCase的概念，也没有具体工具和框架的依赖，而是面向测试需求和自动化测试ROI要求设计。它可以帮你厘清测试的场景、工作流、需要代码实现的案例原子，同时内建自动化测试ROI需求，这正是自动化测试设计阶段需要关注和要做的事情，对吗？</p><p>基于Job模型的设计产出是一个XML的树形结构文档，描述了我们的自动化测试任务，基于这个需求，我们的工具选型就会更加科学。<strong>一个测试案例，A工具和B工具都能做自动化，那它们都可以去实现需求，将来它们被替换成C工具，对其他案例没有影响，我们的自动化测试设计也依然保持不变。这就保证自动化测试项目有了持续重构优化的能力，而不是走向腐化。</strong></p><p>同时，我给出了3个案例，分别针对领域业务型金融交易自动化测试设计，DevOps型持续集成pipeline设计，分布式型的复杂场景视频会议系统自动化测试设计，帮助你理解怎么使用Job模型来设计不同的自动化测试场景。</p><p>掌握了怎么把一个自动化测试项目送入到它的运行轨道，就可以坐享ROI的红利了么？不，还不够，你还要考虑怎么让这个项目始终可观测、可控，有反馈，这样就能保证这个项目始终在预定轨道上推进，即使有偏离，也能第一时间发现纠正回来。在<strong>第四模块度量篇</strong>，我还会提供一些度量模型和驱动改进的流程样例，供你参考实践。</p><p>另外，本专栏提出了不少新的方法论，3KU测试金字塔（第二讲），Job模型（第十七讲），而且是业界第一次出现，你刚看到不一定会很快适应。有时可以多看几遍，我相信你每次看都会有不同的收获。</p><p>马斯克最近说过一句话，我对此很有感触，也分享给你：</p><blockquote>\n<p>死亡对我们来说很重要，因为大多数时候人们不会改变主意，他们只是死去。如果人们长生不老，我们可能会成为一个非常僵化的社会，导致新想法无法成功。</p>\n</blockquote><p>我思故我在，思维的碰撞是痛苦的，也是快乐的。期待你加入我的自动化测试专栏，一起扬帆探索自动化测试的深海区！</p>',
        article_title: "开篇词 | 做性价比最高的自动化测试",
      },
    ],
  },
  {
    chapterTitle: "活着还是死去 - 价值篇",
    children: [
      {
        title: "01｜ROI价值内核：自动化测试的价值可以量化么？",
        id: 496857,
        content:
          '<p>你好，我是柳胜。</p><p>作为测试人员，我们都想做好自动化测试，但是每个行业都有自己的规律，也就是说常说的道，自动化测试也有自己的道。所以，在这个模块，我们的目标是了解自动化测试的道是什么，怎么能运用它让自己的测试工作更加有成效。</p><p>今天是价值篇的第一讲，我们先来弄清楚自动化测试的价值究竟是什么？看到这你可能有点困惑，自动化测试有那么多公司都在搞，自然是有价值的啊，有啥可讨论的呢？</p><p>其实这个问题非常关键，在开始工作之前，要把我们的工作价值想清楚，后续工作才能事半功倍。我列几个工作中我们频繁听到的问题，你会更有感触。</p><ul>\n<li>（上级沟通）“产品要上线了，QA人手紧，能不能搞一下测试自动化，减少点人手？”</li>\n<li>（调动人手）“什么？你还要再增加2个自动化测试开发工程师来完成这个项目，他们都要做什么？”</li>\n<li>（工作述职）“听说你开发了个什么自动化脚本，它给公司带来了什么价值？用量化的数据给我讲一讲！”</li>\n</ul><p>这样的问句是不是似曾相识？其实它们都指向了一个硬核问题“自动化测试项目的价值是什么？”</p><p>在这节课，我要和你捋一下，为什么要做自动化测试，并且带你找到度量它价值的方法。掌握了这些，就能对自己的工作目标更清楚、更有信心，别人问到的时候，我们也能讲清楚、说明白，得到了团队理解工作将事半功倍。</p><!-- [[[read_end]]] --><h2>为什么要搞自动化测试</h2><p>开篇词中我提了出海捕鱼的场景，不只自动化测试，整个测试工作就像织网一样，会有弹性的空间，网眼大了、小了，捕到多少鱼，这些都有不确定性，但是这个不确定性又关系到成本和收益这些敏感问题，这是测试工作的一个特点。</p><p>我曾经跟我的团队说过 “咱们做测试工作，甭管用什么方法和技术，目标就是用最小的成本，得出对软件质量最大的确定性结论”。</p><p>自动化测试也面临相同的困难，为了解决这样的不确定，我们有必要好好分析一下，自动化的成本和收益究竟怎么算？</p><p>如果感觉这样问还有些抽象，我们不妨换个问法，自动化测试实施之前和之后，自动化带来的改变是什么？为了进一步完善思路，我们结合一个更具体的例子来做推理、估算。</p><p>这个例子是：一个Web UI 订火车票的软件，成功订一张火车票这个测试案例，要做自动化所花费的成本、还有得到的收益，会是多少呢？</p><p>自动化实施之前，测试案例的执行要靠手工完成，一个工程师需要花费0.5个小时，运行完登录、订车票，查看数据库这样一个测试流程。</p><p>而自动化测试实施之后，流程可以用Selenium脚本自动完成，原先手工测试半个小时的工作量就省下来了。那么，省下来的这半个小时这就是自动化测试带来的价值。对不对？</p><p>对，但还不全面，我们衡量效益，不应该只看回报，还要看成本，我们要算上开发自动化测试花费的成本。为了开发Selenium订火车票的这个脚本，自动化测试工程师花费了1天的时间，合计就是8个小时。</p><p>现在，这个Selenium自动化测试案例，它的投资收益比ROI应该这么计算（产出和投入都用时间作为单位）：</p><p>产出/投入 = 0.5/8= 0.0625</p><p>结果不到7%。哇，投入了8个小时，才收获了0.5个小时。如果这是一项投资的话，那肯定是亏本的。哪个公司愿意做这样的买卖呢？</p><p>但是，上面的公式只计算了运行一次自动化测试案例的ROI。实际上，自动化测试案例开发出来后，肯定不止运行一次的。多运行一次，就会多节省下来一份工作量，如果用n来指代运行次数，t指代单次测试时间，现在的产出变成了n*t，n越大，产出就会越大。</p><p>那上面订火车票案例，运行多少次才能收回成本呢？1/0.0625=16，只要这个selenium脚本运行超过16次，我们就可以让ROI=1，收支平衡，收回成本了。</p><p><img src="https://static001.geekbang.org/resource/image/7f/82/7fa80bffaae0f230411b67310e9ca582.jpg?wh=1900x801" alt="图片" title="运行次数&amp;ROI关系示意图"></p><p>太棒了，现在你就可以对公司说：“我的自动化测试收益是可以量化的，只要我保证开发出来的脚本，能运行超过16次，就是为公司省钱了。”</p><p>且慢，还有一笔账没有算，除了开发成本，还有维护成本。自动化测试开发出来后，还需要维护版本升级、诊断错误、优化结构等等的工作，这笔成本是需要持续投入的。</p><p>现在这个Selenium在它线上运营生命周期内的ROI计算公式，变成了后面这样：</p><p>产出/投入 =  0.5*N/(8+维护成本）</p><p>我们把它提炼成一个计算公式，就是：</p><p><img src="https://static001.geekbang.org/resource/image/cd/00/cd34280bc70b3633e696a7ba16f9e300.jpg?wh=1920x868" alt="图片" title="ROI计算公式"></p><p>这个公式很简单，但仔细揣摩可以推导出几个有意思的结论。</p><p><strong>1.ROI大于1就是赚了，小于1就是亏了。</strong>那么，给定一个测试案例，要不要对它做自动化，判断的依据是（自动化测试）预期ROI至少要大于1。</p><p><strong>2.自动化测试是一个长收益模式。</strong>在理想情况下，是一次性投入（投入为开发成本），之后每运行一次，就会增加一份产出。所以，时间越长，次数越多，收到的回报就会越大。</p><p>3.关于开发成本（包括开发成本d和维护成本m），类似估算软件开发工作量，代码行法、功能点法，我们也可以引入到估算开发工作量里，比较好掌握。<strong>但维护成本就有点模糊了，这里包含了多种可变因素，是自动化测试项目风险的主要来源。</strong></p><p>维护成本来自于多个地方。一段代码从产生以后，就会持续产生维护工作量，而且，因为存在架构腐化等问题，维护工作量增加速度是以非线性来增长的。</p><p>到了最后，一个陈旧的老破系统，加入一个新功能需要写10行代码，只要花5分钟。但是搞清楚这10行代码，应该加到哪个文件里，要花费3天时间。在这种时候，这个软件系统就已经不可维护了，它要寿终正寝了。自动化测试代码的维护成本更复杂，不仅面临着腐化的问题，还有被测产品更新带来的维护等等。</p><p>所以，在实践中，你看不到前面图里，那样简单漂亮的ROI直线，它会表现为一段曲线：自动化的ROI增长速度，要比运行次数增长慢一些，直到最后，每运行一次，花费的维护工作量，比节省的工作量还多，自动化就该退休了，也就是下线，重构完了再上线。</p><p><img src="https://static001.geekbang.org/resource/image/73/4d/73e3da46cce6542dceda6ddee0a5e54d.jpg?wh=1900x801" alt="图片" title="运行次数&amp;ROI关系示意图2.0版"></p><p>这里我想提醒你注意，<strong>ROI模型提供的是一种自动化测试投资收益比的量化思路，方便我们明确哪些因素影响着自动化测试效益。</strong>不可能存在一个万能的公式，把参数往里一带，就会算出ROI的数字如果世间的事都这么简单，还需人类干什么。我们需要做的是尽可能量化，你对量化的了解越多，对自动化测试的理解就会更加深入全面。</p><h2>做不做自动化测试，能用数据说话么？</h2><p>从ROI的公式来看，自动化测试的收益取决于t和n，t指的是节省下来的手工工作量，还是比较容易理解的。在字面上，n是一份自动化测试案例重复运行的次数，那么在实践中，n是什么呢？</p><p>聪明的你可能已经猜到了，n是测试案例的稳定回归次数。软件的新功能开发出来后，第1次测试之后，第2次，第3次到第n次，都是对第1次的回归。它们都是重复的工作，应该被自动化替代。</p><p>你看，从ROI公式，我们很容易推导出业界熟知的经验<strong>“自动化测试是用来做回归测试的”</strong>。自动化是开发出来不会只运行一次，除非它的t特别大，实现了手工测试做不到的事情，比如单元测试、性能测试。</p><p>我们再回到回归测试，n作为回归测试次数，对自动化测试工作有什么启发呢？它的作用很大，因为它能帮助我们量化地去回答一个 “做不做自动化测试” 的关键问题</p><p>一个测试案例A做不做自动化测试？首先要看看它的n能有多大。</p><p>假设软件发布周期持续一年，每两周迭代一次，每次迭代都需要一次测试，那么在这一年里，需要回归测试次数至少是365/14=26次。如果还考虑一些紧急feature、patch的发布，那实际的回归次数要大于26次。这样，我们就能得到一个n的估算值，比如说30次。</p><p>得到估算值后，你的决策不再依赖直觉，而是有了可量化的思考逻辑。30次能不能收回来成本？能！那这个测试案例A就可以搞自动化。不能，你就面临亏本风险，自动化一顿操作猛如虎，测试工作还是苦，这是项目组里的每一个人都会感受到的。</p><p>刚才说的是基于软件发布周期不变的情况下，如何估算回归次数n。在实际工作中，自动化测试一旦做起来，带来的变化是：测试执行时间变快，软件发布周期缩短，又反过来增加回归次数n，自动化测试的收益也在增加。</p><p><strong>这里我们又得到一个结论：软件发布周期变短是自动化测试ROI提升的产物。</strong></p><p>总结来说，只要我们把注意力关注放在ROI上，后面的好处都会相继而来，测试质量提高了，发布周期缩短了，团队也更加有信心了。</p><h2>实践中，冒烟测试是你自动化的开始</h2><p>紧接着，咱们再考虑下一个问题，测试案例A需要30次回归，是不是在刚引入新功能A的第1次迭代，就开始运行自动化？我的答案是要根据情况来判断。</p><p>上面说到n是测试案例的稳定回归次数，注意<strong>稳定</strong>这两个字，它代表功能A已经稳固下来，不再变了。更精确地说，功能A即使有变化，但是变化规律已经可以被自动化测试吸纳。这种情况下，自动化测试运行才能发挥效益。</p><p>这里你可以看看后面这张图，画的是加特纳的技术成熟曲线，它也可以用来描述软件功能的发展过程。</p><p><img src="https://static001.geekbang.org/resource/image/2f/e6/2fcb06174dca22b246630c5b5a5379e6.jpg?wh=1920x921" alt="图片" title="加特纳技术成熟度曲线"></p><p>通过加特纳成熟度曲线可以看出，新功能在产生初期，一般是不稳定的，和它的预期有一个差距。经过几轮调整后，才会进入到一个平缓的阶段，这也是稳定回归测试的阶段。而不同类型的软件，它的功能成熟时间长短，变化剧烈程度可能是非常不一样。</p><p>有的软件是做标准化产品的，比如专业性强的B端财务软件，计税模块发布出来就很稳定，我们采取的策略是在第1个版本做计税模块的自动化。</p><p>有的互联网软件第1版是投放试验性的，我看过国外一个招聘网站经过产品设计，AB测试多轮后，打磨了x版才稳定下来简历模块，那么这时的策略是在x版本进行简历模块自动化。</p><p>还有的生命周期比较短的软件项目，虽然有迭代，但功能一直无法稳定，那可能需要考虑完全手工测试，根本不需要自动化测试。其实这些都可以通过ROI模型讲得通。</p><p>到这里，咱们总结一下我们通过ROI得出的三个核心观点：</p><p>1.自动化测试是用来做回归测试的。</p><p>2.自动化测试从哪里开始？实施顺序从ROI高到低，也就是（给定一个软件系统），优先做回归次数最高的那部分功能，先做自动化回归次数最高的案例，再做低的，直到ROI等于1的案例。在功能模块的初期，可以考虑先做手工测试。</p><p>3.自动化测试什么时候开始？功能模块稳定的时候。</p><p>实际上，有一个很好的测试实践可以匹配上面的要求，那就是冒烟测试。冒烟测试是测试用例的子集，用来验证系统中基础的、影响发布软件的功能。甄选冒烟测试的一个常用办法就是二八原则。</p><p>二八原则又叫帕累托原则，在因果关系中，仅有20%的因素会影响80%的结果。它在各个领域都有体现，比如在市场营销领域，80%的利润是由20%的用户创造的；在经济学里，80%的财富掌握在20%的人的手里。</p><p>在软件领域，80%用户，常用的是系统中20%的功能。冒烟测试覆盖的这部分20%功能，是常用的，一般也是核心的，最先被开发出来的。所以，它同时满足稳定和回归次数高两个特点。</p><p>进而我们就可以得到推论：<strong>在实践中，可以设定目标，冒烟测试100%自动化。</strong>这时，自动化测试就可以和手工测试配合，形成一个新版本发布+冒烟测试的简单流水线。</p><p>如图所示，先从代码管理工具比如CVS、Gitlab中的开发分支中拉取代码，build构建，做一轮冒烟测试。如果冒烟测试通过，开发分支可以merge到发布分支，如果冒烟测试失败，那开发人员必须修改代码，直到冒烟测试通过。</p><p>这个流水线Pipeline充分利用了自动化无人参与，执行速度快的特点，可以帮助开发人员在第一时间验证代码的正确。由于是每次分支归并都会调用冒烟测试，所以n的次数高，自动化测试的ROI也会高。</p><p><img src="https://static001.geekbang.org/resource/image/fe/62/fe138ec5e6513c05e111f72328414962.jpg?wh=1920x726" alt="图片" title="新版本发布+冒烟测试流程图解"></p><h2>小结</h2><p>今天这一讲，我们通过一个投资产出视角来观察自动化测试，它的成本是什么，它的产出是什么，还学习了ROI的计算公式。</p><p>我们通过ROI的收益规律，不仅可以推导出自动化测试业界的已有共识，比如：“自动化是用来做回归测试”，“冒烟测试优先做自动化”……而且，我们还能挖掘出一些新的合理观点，比如：“ROI从高到低，来做自动化测试”。</p><p>这说明业界的实践已经有意或无意地践行ROI规律，因此可以说，<strong>ROI是一个自动化测试项目的隐式命脉</strong>。</p><p>同时，我们又详细介绍了ROI公式的因子n，测试案例的回归次数。在实践中，找到n来估算ROI，能帮你判断一个案例该不该做自动化。</p><p>ROI公式里，除了n还有其它因子。在后面的课程中，我们再一一介绍其它因子，像m维护成本，现在这个概念看起来还有点模糊，我还会帮你把它分解，直到可操作和可度量的粒度，让ROI的方法论更有效地指导你的工作。</p><h2>思考题</h2><p>学习ROI之后，你可以从开篇的三个问题里选择一个或多个，试着回答一下。</p><ul>\n<li>“产品要上线了，QA人手紧，能不能搞一下测试自动化，减少点人手?”</li>\n<li>“什么？你还要再增加2个自动化测试开发工程师来完成这个项目，怎么算出来的？”</li>\n<li>“听说你开发了个什么自动化脚本，它给公司带来了什么价值？用量化的数据给我讲一讲。”</li>\n</ul><p>欢迎你在留言区记录你的收获和思考。如果这一讲对你有启发，也可以推荐给身边更多同事、朋友，跟他一起学习进步。</p>',
        article_title: "01｜ROI价值内核：自动化测试的价值可以量化么？",
      },
      {
        title: "02｜3KU法则：如何找出最优自动化实施截面？",
        id: 497405,
        content:
          '<p>你好，我是柳胜。</p><p>上一讲我们提出了自动化测试ROI模型，在回归测试中的应用。回归测试是一个笼统的概念，单元测试、接口测试以及UI测试里都有回归测试，甚至性能测试也已经成为回归测试的一部分。</p><p>今天我们要关注一个具体场景，给你一个软件系统，作为自动化测试人员，你怎么找出测试截面，制定自动化测试方案？这些事可能你都做过，觉得并不稀奇，但既然我们已经学习了ROI思维，今天要再加上一个小目标，<strong>制定策略，能够让这个自动化测试设计获得尽可能大的ROI</strong>。换句话说，能干还不够，还要干得好，既要马儿跑，又要马儿少吃草。</p><p>有挑战不？那就跟我进入这一讲的学习，一起找到最佳策略吧。</p><h2>测试ROI金字塔</h2><p>在测试设计领域，经常提到的方法是分层。具体就是给定一个系统，结构上划分三个层级，单元在最小圈；服务包含多个单元，在中圈；而系统又包含多个服务，是外部的最大圈。结构图如下：</p><p><img src="https://static001.geekbang.org/resource/image/77/c3/7713a7081ac2723a2cfc35d3277b21c3.jpg?wh=1920x1050" alt="图片" title="软件结构圈图"></p><p>相应地，我们的测试结构是在代码层做单元测试，服务层做接口测试，系统层做UI功能测试。</p><p>在实践中，这三种测试该怎么组合安排呢？迈克·科恩在2009年他的新书《敏捷成功之道》中首次提出了测试金字塔模型。单元测试自动化在金字塔底部，接口测试自动化在中部，而UI测试自动化在金字塔顶部。</p><!-- [[[read_end]]] --><p><img src="https://static001.geekbang.org/resource/image/bd/68/bdyy34691cc7a36c8e50f13e3bbaca68.jpg?wh=1920x1050" alt="图片" title="分层测试金字塔"></p><p>迈克·科恩讲到自动化测试工作量配比时，认为应该按照层面积分配。也就是说，单元测试案例的数目应该多于接口测试案例数目，接口测试案例数目应该多于UI测试自动化测试案例数目。</p><p>后来，金字塔模型又被业界发展，赋予了不同的测试策略，比如自底向上执行速度减慢，自顶向下业务属性减弱，技术属性增强。</p><p>但迈克·科恩没有解释，为什么各层工作量配比要按照测试金字塔分布？按照软件结构图，系统在最大圈，测试案例应该最多，而到了自动化测试金字塔，UI自动化测试案例却最少；单元测试在小圈，测试案例应该最少，但到了自动化测试金字塔，单元测试案例却最多。</p><p>为什么是金字塔？要是不去理解规律背后这个“为什么”，你就用不好这个规律。上一讲我们知道了“ROI其实是自动化测试的隐式命脉”，现在我们就利用ROI思维，分析一下测试金字塔规律。</p><p><img src="https://static001.geekbang.org/resource/image/cd/00/cd34280bc70b3633e696a7ba16f9e300.jpg?wh=1920x868" alt="图片" title="ROI公式"></p><p>下面，我们分别看看每层的ROI。单元测试可以在开发人员每次code commit触发运行，回归频率高；接口测试在每轮集成测试运行，回归频率中；UI自动化测试在用户验收测试，回归频率低。</p><p>按照ROI模型，我们可以得出3种类型自动化测试的ROI排序，如下表：</p><p><img src="https://static001.geekbang.org/resource/image/71/08/713a743c26347d08d561d5a77ab27608.jpg?wh=3363x1379" alt=""></p><p>对照测试金字塔不难发现，实际上三类自动化测试的ROI是自底向上由高到低的。</p><p><img src="https://static001.geekbang.org/resource/image/7e/af/7ebe91f53e1fc7a84e53a26d68c4baaf.jpg?wh=1920x1050" alt="图片" title="分层测试ROI金字塔"></p><p>按照第一讲得出的规律“自动化测试顺序从ROI高到低”，我们优先投入精力做ROI最高的单元测试，再做ROI中的接口测试，最后完成UI测试。</p><p>现在就可以轻松解释迈克·科恩的金字塔了，因为ROI存在差异，所以按照高ROI大投入，中ROI中投入，低ROI小投入，工作量比例呈金字塔分布，底层面积最大，顶层面积最小。发现没？<strong>根源在于ROI，金字塔是表现出来的形态而已</strong>。</p><p>好，到这里，总结一下。各种软件理论学派，大致可以分为两种，一种是理论基础，讲的是做什么，比如软件测试定义、软件过程，另外一种是实践经验，讲的是该怎么做，比如金字塔模型。</p><p>实践和理论很大的不同就是在现实商业中，我们不可能完全按照理想来工作，而是要加入很多制约因素，其中最大的制约就是钱。明白这个道理，你就会知道为什么ROI是根源，你也会知道怎么能够在工作中做出业绩了，不是耍两个工具，忽悠一下领导就算成功，而是认认真真地去思考，踏踏实实地去提高ROI，直到边际效应ROI无法提高为止。</p><h2>寻找最优ROI策略</h2><p>刚才说了分层测试和各层ROI，业界也很认可这种分层理论，但实际落地时却存在问题：一批人做UI测试自动化，另外一批人去做接口测试，然后开发人员做单元测试。三路人马忙得不亦乐乎，都说自己贡献大，等到bug发生了泄漏到生产环境，又开始甩锅。</p><h3>分层测试为啥会“内卷”</h3><p>很明显，这是一个内卷的场景，让我们结合例子具体看看内卷发生在哪里？</p><p>以一个Web登录操作为例，用户在UI上输入用户名和密码，点击“登录”按钮。Selenium UI 自动化会这样实现：</p><pre><code class="language-plain">@Test\npublic void login() {\n  WebDriver driver=new ChromeDriver();\n  driver.manage().window().maximize();\n  //打开页面\n  driver.get("https://www.example.com/users/sign_in");\n  WebElement username=driver.findElement(By.id("user_email_Login"));\n  WebElement password=driver.findElement(By.id("user_password"));\n  WebElement login=driver.findElement(By.name("login"));\n  //输入用户名\n  username.sendKeys("liusheng@example.com");\n  //输入密码\n  password.sendKeys("123456");\n  //点击登录按钮\n  login.click();\n}\n</code></pre><p>上面UI的操作被Web服务转化成Rest请求，进入到API网关，是这样的：</p><pre><code class="language-plain">curl --location --request POST \'http://auth.example.com/auth/realms/Test/users\' \\\n--header \'Content-Type: application/x-www-form-urlencoded\' \\\n--header \'username=liusheng@example.com\' \\\n--header \'password=123456\'\n</code></pre><p>在单元上执行的则是这样的代码：</p><pre><code class="language-plain">public Future&lt;ResponseData&gt; login(String userName, String password) {\n    //入口参数检验\n    if (StringUtil.isBlank(userName)||StringUtil.isBlank(password)){\n      return new AsyncResult&lt;&gt;(ResponseData.error("账号密码不能为空"));\n    }\n    //查询用户是否存在\n    List&lt;User&gt; userList = baseMapper.getUserInfo(userName);\n    if (CollectionUtils.isEmpty(userList)){\n        return new AsyncResult&lt;&gt;(ResponseData.error("账号不存在"));\n    }\n    //验证账号密码是否正确\n    User user = userList.get(0);\n    String requestMd5 = SaltUtil.md5Encrypt(password, user.getSalt());\n    String dbMd5 = user.getPassword();\n    if (dbMd5 == null || !dbMd5.equalsIgnoreCase(requestMd5)) {\n        return new AsyncResult&lt;&gt;(ResponseData.error("账户密码不正确"));\n    }\n    //生成 access token，并返回\n    String token = JwtTokenUtil.generateToken(user);\n    return new (ResponseData.success(token));\n}\n</code></pre><p>可以看到，一个请求，从浏览器页面发起，进入API网关，再传递到服务里的Login函数，经过了UI测试、API测试和单元测试三个测试截面。</p><p><img src="https://static001.geekbang.org/resource/image/0a/ce/0a1af39ca343083b14fe1472c5610cce.jpg?wh=1920x1045" alt="图片" title="三个测试截面示意图"></p><p>三个测试截面测的是一个请求在不同层面上的形态，那么每一个截面都可以测试全部的案例，也可以测试部分的案例。就像3个人负责1个项目一样，如果没有经过事先的协调和安排，3个人可能做了重复的事情，造成浪费，也可能存在一件事3个人都没干，形成测试盲区。</p><h3>需求/策略矩阵</h3><p>这种“内卷”是不是一个问题？可能你会说没问题，各层独立测试能够加强质量保障。说这话的底气在于测试上的投入充足，不计内卷成本。实际上，在DevOps风行的今天，趋势是追求效果和效率。所以，在资源有限的条件下，我们需要在整体上看待分层测试的最优ROI。</p><p>咱们先看看测试需求是什么，用 <a href="https://zh.wikipedia.org/wiki/FURPS">FURPS模型</a>来理一下需求。FURPS是用5个维度来描述一个软件的功能需求，FURPS这个单词对应着每个需求的英文首字母：</p><ul>\n<li>F=Function 功能</li>\n<li>U=Usability 易用性</li>\n<li>R=Reliability 可靠性</li>\n<li>P=Performance 性能</li>\n<li>S=Supportability 可支持性</li>\n</ul><p>把测试需求和测试类型组合在一起，就整合了后面这个矩阵表格：</p><p><img src="https://static001.geekbang.org/resource/image/44/21/443b6845a599a19d27704a3f89b44b21.jpg?wh=4000x1410" alt="" title="3KU测试矩阵"></p><p>结合表格，可以看到UI测试、接口测试和单元测试每个截面的测试能力。</p><ul>\n<li>在UI层面上，功能性最强，所有测试需求都可以做。这个可以理解，因为软件本身就是满足用户需求，没有一个需求不可以从用户层面感受到。如果真的存在一个需求，用户却无法体验到，那根据<a href="https://zh.wikipedia.org/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80">奥卡姆剃须刀原理</a>，这种用户无法体验到的需求就是无效的。</li>\n<li>接口层面上，功能性减弱，技术性增强。</li>\n<li>单元层面上，技术性最强，功能性主要体现在数据的处理，算法逻辑上。</li>\n</ul><h3>3KU整体策略</h3><p>好，有了需求/策略矩阵后，结合上面讲到的自动化测试ROI金字塔，我们的整体最优ROI策略就呼之欲出了。什么是整体最优ROI呢？</p><p>有3个Key（关键因素）：</p><ul>\n<li><strong>U</strong>seful:  每个测试需求都是有效的；</li>\n<li><strong>U</strong>ltimate:  每个测试需求的验证都在优先寻找自动化ROI高的层面去实现，如果不可行，按照ROI高到低回退，直到UI层；</li>\n<li><strong>U</strong>nique: 每个层面上验证的测试需求都和别的层面都不是重复的。<br>\n这样分配的工作，既不重复，又没遗漏，还遵循了ROI的原则。我管它叫<strong>3KU原则。</strong></li>\n</ul><p><img src="https://static001.geekbang.org/resource/image/7e/af/7ebe91f53e1fc7a84e53a26d68c4baaf.jpg?wh=1920x1050" alt="图片" title="3KU测试金字塔"></p><p>3KU策略该怎么执行呢?按照3KU策略，我们把表格里的测试需求，对照下面这三个问题，按顺序检查一遍：</p><p>1.能在单元测试验证么？<br>\n2.能在接口测试验证么？<br>\n3.能在UI测试验证么？</p><p>这样检查以后，就能得出各个需求的自动化实现截面了。</p><p>UI测试关注功能场景测试，易用性测试和可执行性测试；而接口测试关注不同数据的循环，接口的性能和错误恢复能力；单元测试关注算法的正确性和性能。</p><p>恭喜你看到这里，最后就是我们收割成果的环节了。我们又得出了一个满足3KU原则的自动化测试实施金字塔，各层有自己的关注点，又在整体上实现了互相配合补偿。</p><p><img src="https://static001.geekbang.org/resource/image/95/a7/950bdb1892c70d0598cd0657e2ca92a7.jpg?wh=1920x1064" alt="图片" title="3KU测试金字塔"></p><p>在3KU测试金字塔下，每一个测试需求都会选择最大的ROI测试截面，通过这样的安排，实现了整体最优ROI的目标。对不对？</p><h2>小结</h2><p>这一讲，我们从ROI角度分析了一下分层测试的原理和在实践中的应用。先入为主地，分层理论上的分层测试的特性，必然会造成重叠和错失。这给测试从业者带来了挑战。但挑战也是机会，如何解决这个问题？</p><p>这就需要我们遵循回归到效益的原则，思考怎么用最少的资源干最多的事，能达到这个效果，就是好的实践。因此，我们提出了分层但协调实现整体最优ROI的解决方案，3KU测试矩阵和3KU测试金字塔。</p><p><img src="https://static001.geekbang.org/resource/image/44/21/443b6845a599a19d27704a3f89b44b21.jpg?wh=4000x1410" alt="" title="3KU测试矩阵"></p><p><img src="https://static001.geekbang.org/resource/image/95/a7/950bdb1892c70d0598cd0657e2ca92a7.jpg?wh=1920x1064" alt="图片" title="3KU测试金字塔"></p><p>沿着这个思路，各层做好自己具有优势能力的测试需求，比起全部需求系于端到端的测试上，更有效率和效益，<strong>分层是追求整体ROI的结果</strong>。之后的课程里我们还会反复提到ROI，最后你也会不由感叹，ROI是背后无形的大手，大道无形，无处不在。</p><h2>思考题</h2><p>1 软件大师马丁·福勒曾经说过：“在微服务时代，分层测试不再呈现金字塔形状。”这是为什么？试着用ROI来解释一下。</p><p>2 学完今天的内容，如果你是测试主管，你希望你的团队是全栈（一个人负责一个模块的所有层面测试），还是精细分工（一个人负责所有模块的一个层面测试）？有什么优劣?</p><p>欢迎你在留言区跟我交流互动，如果这一讲对你有启发，也推荐你分享给身边更多同事和朋友。</p>',
        article_title: "02｜3KU法则：如何找出最优自动化实施截面？",
      },
      {
        title: "03｜工具选择：什么工具框架值得用？",
        id: 498458,
        content:
          '<p>你好，我是柳胜。</p><p>工具选型评选会你应该不陌生，无论你是作为评审者，还是方案建议人。不过常常出现的场景就是，方案建议人讲了一通新工具A如何优秀强大，从问题分析到方案解决一应俱全。但参会专家并不是全都熟悉这个新工具，就会问出一堆类似“为什么你不用工具B”的问题。</p><p>结果也可想而知，懂A的不懂B，懂B的不懂C，懂C的不懂A，最后评审会咋决策？只好陷入一个依靠个人影响力来决策的模式。要破除这种死循环，就要找到一个量化模型。在我看来，量化数据才是团队有效交流的手段，也是团队达成共识的基础。</p><p>有了这样的模型，好处多多。评审阶段，可以更科学地预估某个工具的能力和风险；工具投入使用后，模型依旧能帮你持续观测，检验这个工具是否带来了预期价值。</p><p>今天我会带你一起推演出这个模型。学会推演方法，远比套用“模型”更重要。</p><h2>自动化测试案例的成本</h2><p>在开始量化评估之前，我们先回顾一下前面学过的ROI模型。</p><p><img src="https://static001.geekbang.org/resource/image/cd/00/cd34280bc70b3633e696a7ba16f9e300.jpg?wh=1920x868" alt="图片"></p><p>通过这个模型，我们得到一个重要结论：<strong>一个自动化测试案例的开发工作量，在给定条件下，什么经验的工程师用什么工具，需要多长时间完成，这是可以估算的定值。但维护工作量包含了多种可变因素，是自动化测试项目的风险所在。</strong></p><p>今天我们聚焦公式里的分母，也就是开发成本d和维护成本m。</p><!-- [[[read_end]]] --><p>先说开发成本。在软件开发中，估算开发规模的传统方法有功能点和代码行，前沿的方法也有用AST抽象语法树。那如何估算开发一个自动化案例需要多大工作量呢？</p><p>首先我们要看一下自动化测试案例是如何产生的，目前在业界，主要有5种方式。</p><h3>方法一：录制和回放方法</h3><p>第一代的自动化测试工具大多基于录制回放，像最早的WinRunner就是录制桌面UI应用的。目前代表工具就是Selenium IDE。</p><p>要生成测试代码很简单，开启浏览器Selenium的插件，打开测试的网页，比如http://www.baidu.com，输入关键字“极客时间”，点击搜索，就会自动生成测试脚本了，如下图。</p><p><img src="https://static001.geekbang.org/resource/image/ae/39/aec0fcf088f853f9a1b684476052bc39.jpg?wh=1920x1364" alt="图片" title="自动生成测试脚本演示"></p><p>通过录制产生自动化脚本的这种方法，优点是速度快、零编码，对测试人员技术要求低。缺点是规模一旦扩大，维护工作量几乎无法承受，比如和CICD集成、自定制报告、多环境支持等等。</p><h3>方法二：关键字驱动</h3><p>不过，录制回放产生的脚本，还是面向过程的一个个函数，还需要测试人员有一定代码基础，才能扩展和维护这些函数。</p><p>那么，有没有办法，让没有代码经验的人也能编辑、维护脚本呢？关键字驱动方式应运而生了，它增加了页面控件对象的概念，调用对象的方法就是操作对象运行，在这种机制下，对象、对象的行为、输入的数据和描述信息，这些内容都能用一个表格的形式呈现。业务人员只需要编辑表格，就能修改运行逻辑了，这就叫做<strong>关键字驱动</strong>。</p><p>下面是一张关键字驱动表格，编程就是编辑表格里的关键字和对象。关键字是一组预定义好的指令，编辑完表格后，框架会驱动这个表格，执行设定好的命令，来完成自动化测试。</p><p><img src="https://static001.geekbang.org/resource/image/4b/9c/4bbfd55d324e056f7e78d064526a509c.jpg?wh=3552x932" alt="" title="关键字驱动表格示例"></p><p>相比录制回放，关键字驱动框架的优势在于降低了测试开发人员的技术要求。而且测试开发人员对代码还有了更多的逻辑控制能力，比如增加循环结构、wait time、log输出，只要框架提供足够丰富的关键字就行。</p><p>但你也不难看出，编辑表格的人和维护关键字仓库的人，并不是同一拨人。前者是对业务了解的测试人员，后者是技术能力强的开发人员，这样开发维护起来会增加难度。</p><h3>方法三：模块库开发</h3><p>随着软件技术的发展，自动化测试人员的技术水平也在提高，要解决的问题也更加复杂。比如自动化测试的代码怎么能够有效地复用，有没有好的扩展能力等等。这个扩展能力是二维的，分为水平功能扩展和垂直层级扩展。</p><p>水平功能扩展指的是测试功能增多，自动化测试代码就借鉴了软件的模块设计思维，一个应用的测试场景可以切分成多个功能模块。比如订餐的流程可以分成登录模块、下单模块、快递模块，模块之间通过调用关系连接起来，组成测试场景。</p><p><img src="https://static001.geekbang.org/resource/image/4c/60/4cd575d922bca8d498574d76b1824a60.jpg?wh=1920x396" alt="图片" title="订餐流程模块示意图"></p><p>而在技术层面上，又可以垂直切分出功能案例库和通用库。比如页面的组件可以形成复用库、page对象、button对象、link对象等等，把和开发技术耦合的技术层封装在复用库里，而和测试相关的业务功能实现在功能案例库里。</p><p><img src="https://static001.geekbang.org/resource/image/74/01/74b3b5bc5f60fd5bc37c58c73bfb1501.jpg?wh=1920x811" alt="图片" title="订餐流程垂直切分示意图"></p><p>这样的设计，遵循了高内聚低耦合的软件设计思想，未来自动化测试规模扩展时也很方便。比方说增加一个支付功能，就可以把支付页面的对象写到复用库里，新创建一个支付测试案例，前面和下单模块衔接，后面和快递模块对接，就能跑起来了。</p><p><img src="https://static001.geekbang.org/resource/image/0e/96/0ed618bbb3ae23123c4a449eae470196.jpg?wh=1920x592" alt="图片" title="模块扩展示意图"></p><p>模块库开发的优点是可扩展、可复用，困难是需要架构工作和代码工作，对自动化测试开发人员的代码能力要求也比较高，接近开发工程师。</p><h3>方法四：BDD混合框架</h3><p>还有一种方法是BDD混合框架。BDD全称是Behavior Drive Development，行为驱动开发，它通过Gherkin语法定义测试场景。</p><p>Gherkin语法包含一套类自然语言的关键字：when、given、then，given描述条件，when描述行为，then描述结果。这样一个场景的3要素：上下文、动作和结果就说明白了。</p><p>所以，Gherkin语法描述出来的测试场景，能够同时被非技术和技术人员理解。客户、需求人员、开发人员和测试人员从BDD案例各取所需，需求人员得到用户手册，开发人员得到Use Case，测试人员得到测试案例。这些都有BDD框架支持生成代码，比如Cucumber。</p><p><img src="https://static001.geekbang.org/resource/image/6b/64/6bf0e210588aeae67b9a59a2714c1064.jpg?wh=1920x1051" alt="图片" title="BDD方法示意图"></p><p>BDD和关键字驱动框架的优缺点基本一样，不同的是，BDD不局限于测试框架，能够和软件流程集成在一起，也有相应的开发IDE插件，比如Eclipse plugin。</p><h3>方法五：更高ROI的探索，自动化前沿技术</h3><p>最后，我要说一下目前比较火，听起来也很酷的自动化前沿技术。</p><p>AI测试曾被寄予厚望，我们期待由它发展出一套自动化测试全栈解决方案，可以自动生成测试案例和代码，而且维护工作量为零。不能说这些全都是镜花水月，我相信目前AI只在一小部分测试领域里落地，比如图像识别的Applitools，可以用作图片验证；游戏领域里的监督学习，用来行为克隆等等。</p><p>我也曾看过一些AI根据规则自动生成测试案例的演示，但演示只是演示，它演示的方案需要的很多条件，现实还不具备，比如基于非常理想的数据模型等等。所以，我认为AI“落地”的定义是，它的形式是产品，而不是个人业余的项目或者一段开源代码。</p><p>相比AI测试，我更看好另外一种自动化生成测试的思路，就是基于规则化或可以模式化的业务场景，把案例的生成和代码生成一并自动化，形成一种可以量化的案例发现方案。我会在第5讲带你了解这个思路如何实现。</p><p>记住，<strong>测试工作是要能证明软件功能的成败，其方法论基石是确定论，而不是未知论</strong>。说得通俗一点，测试是在编网，虽然网会漏鱼，但我很确信只要投入人手和时间，就能把网编到什么程度，网住什么鱼。 而不是今天我捉到一条鱼，明天不知道鱼在哪里。这是我不认为AI能完全替代手工测试工作的原因。</p><p>好，业界已知的生成自动化测试方法，我们做了归类了解，接下来再分析不同类型的自动化测试开发成本和维护成本。</p><p>我给这个表格起一个名字，叫做<strong>案例DM分析表</strong>。D代表Development，M代表Mantainence。</p><p><img src="https://static001.geekbang.org/resource/image/9d/40/9d9a670b5db7b775b9990a4cae48fb40.jpg?wh=4000x2490" alt="" title="案例DM分析表"></p><h2>工具的成本</h2><p>前面探讨的给定了类型工具的情况下，案例的开发、维护成本如何衡量。但别忘了，成本计算时，还有个不小的成本：工具和框架的成本。这个在选型阶段没有考虑的话，会给后面埋下很多隐患，带来不少让人头疼的问题，比如下面这些。</p><p>1.当你的团队开始上手案例开发时，发现框架只支持JavaScript，Perl，但你的团队都是熟悉Python和Java。在这种情况下，是培训已有团队还是招聘新的人才，还是弃用方案而选择新的框架？</p><p>2.当你需要升级框架时，高版本对低版本的兼容性。它有可能让你的原有测试案例不能工作，最糟糕的是，会出现一些奇奇怪怪的问题，每一个问题的诊断过程是一场对你毅力和耐心的考验。</p><p>3.当你的案例在运行的时候，遇到一个框架抛出来的exception，网上搜不到解决方案，去社区论坛提问，也没人响应，自己去看源代码又陷入浩若烟海的context中去，那种无力感蔓延开来，直让你怀疑人生。</p><p>4.当你的案例规模扩展，新的API案例需要调用PATCH原语，但你已使用了一年的API框架不支持PATCH，更悲催的是，你发现这个API框架已经停止更新，凋零的社区、隐身的支持人员、破败的代码，都是对你的毒打。</p><p>进坑容易出坑难。我见证过一个自动化测试团队选型工具草率，导致在2年内更换了4个工具。每次换工具，都会重写一遍自动化测试案例，人收获了教训离开公司另谋高就，但公司浪费了2年的时间和资源，之后还要换一拨人乐此不疲地重复这样的故事。</p><p>可以说，选型合适的框架是自动化测试架构设计中一个重要的选择，它通过开发成本和维护成本两个因子影响自动化测试ROI，ROI低于1的时候，这个项目就要over了。</p><p>那什么是ROI好的框架呢？</p><p>首先，框架要<strong>满足我们的测试需求</strong>。比如，UI框架能有对象识别能力，API框架能有http原语封装，对xml和Json的支持，单元测试框架能有mock能力。</p><p>其次，框架应该有<strong>广泛的同行用户、持续的更新、成熟的社区和积极的客户响应</strong>，这些也能帮我们降低维护框架的成本，获得更好的ROI。</p><p>把这些因素量化，就能得到一个工具四维成熟度表，你可以把它作为原始模型，用到你的工作里。</p><p><img src="https://static001.geekbang.org/resource/image/28/fd/28d25d4a9a860947983ed3b853ab2bfd.jpg?wh=3563x2011" alt="" title="工具四维成熟度表"></p><h2>小结</h2><p>今天这一讲，我们从开发成本和维护成本的角度系统梳理了工具和框架的优劣势。根据脚本的生成方式的不同，可以划分出录制回放工具、关键字驱动工具、模块库开发工具、BDD混合工具和AI工具，针对自动化的不同类型和规模，脚本的开发和维护成本也会发生变化。</p><p>框架本身也会有维护成本，这里我们优先选择成熟主流的框架，会降低维护的成本。这里“成熟主流”，我们使用用户的数量、更新的频率、社区成熟度、开发语言与团队的适配度四个指标来对比度量。</p><p>我并没有给出一个精准计算工具框架ROI的公式，而是给出几个维度来帮你厘清工具和框架的选择思路。</p><p>记住，这里有两大原则：</p><p>1.按照团队的<strong>技术能力、项目的预期长短、将来扩展的规模大小</strong>，选择ROI最大的工具和框架；</p><p>2.当工具和框架带来的ROI无法升高时，就考虑按照原则1 <strong>重新评估</strong>，选择ROI更好的工具和框架。</p><p>所以，工具和框架的评估不是一劳永逸，而是在整个自动化测试生命周期内实时观测，如果有变要及时止损，让ROI持续提升。</p><h2>思考题</h2><p>在工作中，你的团队非常熟悉Python，所以选择某个支持Python框架。基于这样的原因做选择是不是遵循ROI原则？这样的选择会带来什么样的好处和坏处？</p><p>欢迎你在留言区跟我交流互动，也推荐你把这一讲分享给更多同事和朋友，说不定就能帮他通过下一次的工具选型评审会。</p>',
        article_title: "03｜工具选择：什么工具框架值得用？",
      },
      {
        title: "04｜脚本复用：什么样的代码才值得写？",
        id: 499382,
        content:
          '<p>你好，我是柳胜。</p><p>开发和测试团队我都带过，现在测试人员的代码能力越来越强了，已经接近开发人员，我看过一些测试牛人设计的测试模块和代码：MVC实现测试控制台、分布式多测试节点管理、Proxy对测试Interface默认实现……这些用到的技术栈和开发不相上下。</p><p>聊下来，很多的反馈是“能做起来，很庆幸有一个对测试技术很支持的领导”。这就是一个让人困惑的问题，为了开发自动化测试案例，你写了那么多代码，那每一行代码就应该存在它的价值，这个价值是客观的，而不是依赖主观的某个人的认知。不是么？</p><p>所以这一讲要关注的问题是，你写的每一行代码都有自动化测试的价值么？你能把它说出来，说清楚么？想清楚这些，你自然也会明白给定一个自动化测试的项目，哪些工作是overwork（过度工作），哪些是underwork（工作得还不够）。</p><h2>哪些代码值得写？</h2><p>在开始之前，我们再回顾一下自动化测试ROI模型。</p><p><img src="https://static001.geekbang.org/resource/image/cd/00/cd34280bc70b3633e696a7ba16f9e300.jpg?wh=1920x868" alt="图片"></p><p>一个案例转化成自动化测试后，我们的目标是它的投资回报率越高越好，在ROI公式里，回报也就是分子越高越好，成本也就是分母越低越好。</p><p>在第一讲我讲到过，n是自动化测试案例运行的次数，在回归测试里，n是回归迭代的次数，回归次数越高，n也就越大，这是从时间的角度上来看n。在这一讲，我们换个角度，从空间来看，也就是代码的复用率，我们有没有办法让代码的复用率升高？</p><!-- [[[read_end]]] --><h3>初始版本</h3><p>为了让你更容易理解，我们结合一段登录的脚本，一起探索一下怎样提高一个自动化测试案例的复用率。</p><p>脚本代码如下：</p><pre><code class="language-java">@Test\npublic void login() {\n  WebDriver driver=new ChromeDriver();\n  driver.manage().window().maximize();\n  //打开页面\n  driver.get("https://www.example.com/users/sign_in");\n  WebElement username=driver.findElement(By.id("user_name"));\n  WebElement password=driver.findElement(By.id("user_password"));\n  WebElement login=driver.findElement(By.text("登录"));\n  //输入用户名\n  username.sendKeys("liusheng@example.com");\n  //输入密码\n  password.sendKeys("123456");\n  //点击登录按钮\n  login.click();\n}\n</code></pre><p>这段脚本实现的功能很简单，启动chrome浏览器，打开一个登录链接，在页面上输入用户名liushing@example.com，密码123456，点击“登录”按钮，完成登录。此处我省去了assert检查点。</p><p>现在，这段脚本每运行一次，就测试一次登录。它的n现在就等于1。我们想一下，这个脚本还能怎么提高它的复用率呢？</p><h3>提高复用率：一份代码，多浏览器运行</h3><p>可以看到，脚本运行的测试案例只在chrome上，但作为一个web应用，一般是要支持市面上主流的浏览器，看一下<a href="https://help.aliyun.com/document_detail/211434.html">阿里云网站</a>支持12种浏览器，列表如下：</p><p><img src="https://static001.geekbang.org/resource/image/32/5a/32647ecb58ae59f29f1e6aec994f6f5a.jpg?wh=1920x1130" alt="图片"></p><p>那么，有没有办法让我们的脚本能够一下子测试12种浏览器呢？此时我们需要修改脚本，支持调用多个浏览器driver：</p><pre><code class="language-java">@Test\n@Iteration(Driver=ChromeDriver,FireFoxDriver.....)\npublic void login() {\n  //此处是伪代码，代表从Iteration数组里拿到的driver元素\n  WebDriver driver=new Iteration("driver");\n  driver.manage().window().maximize();\n  //打开页面\n  driver.get("https://www.example.com/users/sign_in");\n  WebElement username=driver.findElement(By.id("user_name"));\n  WebElement password=driver.findElement(By.id("user_password"));\n  WebElement login=driver.findElement(By.text("登录"));\n  //输入用户名\n  username.sendKeys("liusheng@example.com");\n  //输入密码\n  password.sendKeys("123456");\n  //点击登录按钮\n  login.click();\n}\n</code></pre><p>上面是伪代码，代表Test会重复运行Iteration数组，driver的数目有多少个，就运行多少次，每次运行从iteration数组里取得driver的名字，交给脚本去启动相应的浏览器。</p><p>现在dirver有12个，我们就可以让一份脚本测试12个浏览器，获得了n1=12。</p><p>总结一下，最佳实践：一份代码，兼容多个浏览器。</p><h3>提高复用率：一份代码，多数据运行</h3><p>刚才已经迈出了第一步，不错，我们再继续看脚本，还有没有可以改进的地方。现在，我们的脚本只能测试一组用户数据，用户名liusheng，密码是123456。在测试方法论中，一个测试案例应该有多组测试数据，那合法的用户名的数据格式不止这么多，按照字符类型划分等价类，至少有5组：</p><p>1.ASCII字符<br>\n2.数字<br>\n3.特殊字符<br>\n4.拉丁文字符<br>\n5.中文字符<br>\n你如果有兴趣想知道为什么这5种字符是等价类，可以去研究一下字符集原理。</p><p>密码一般是数字，ASCII字符加特殊字符3种。我们至少可以开发出5*3=15种合法的用户名密码组合，作为测试用例。</p><pre><code class="language-java">@Test\n@Iteration(UserPassword={xxxx,123456},{测试用户，Welcome1}....)\n@Iteration(Driver=ChromeDriver,FireFoxDriver.....)\npublic void login() {\n  //此处是伪代码，代表从Iteration数组里拿到的driver元素\n  WebDriver driver=new Iteration("driver");\n  driver.manage().window().maximize();\n  //打开页面\n  driver.get("https://www.example.com/users/sign_in");\n  WebElement username=driver.findElement(By.id("user_name"));\n  WebElement password=driver.findElement(By.id("user_password"));\n  WebElement login=driver.findElement(By.text("登录"));\n  //输入用户名\n  username.sendKeys(UserPassword[0]);\n  //输入密码\n  password.sendKeys(UserPassword[1]);\n  //点击登录按钮\n  login.click();\n}\n</code></pre><p>上面的代码是伪代码，UserPassword数组有多少个元素，测试案例就会运行多少次。每次运行会从interation里取得数组的一个元素，一个元素就是一种用户名密码组合。</p><p>上面的UserPassword数组有15个元素，我们的测试案例就运行15次，现在n2=15，加上浏览器的12次，n=n1+n2=15+12=27次。</p><p>最佳实践：一份代码，多组测试数据。</p><h3>提高复用率：一份代码，多环境运行</h3><p>现在我们已经摸着道了，提高ROI，那就是让一份自动化测试程序，尽可能多复用在不同的测试场景中。这些测试场景本来就是有效的测试需求，转换成自动化也是一劳多得。</p><p>还有没有其他场景呢？当然有，举个例子，在我们的产品发布pipeline里，贯穿了从开发环境、测试环境、准生产环境到生产环境，由低向高的交付过程。</p><p>那你的测试脚本需要兼容每一个环境，在所有需要运行它的环境里都可以直接跑，不需要做任何修改。一份脚本，运行在dev，test，stage，productin 4种环境下，我们的n3=4, n=n1+n2+n3=15+12+4=31次</p><p>你可能会说，这个有难度呀，环境不同，不光是脚本url不同，里面的测试数据也不一样，测试配置也不一样，甚至timeout要求也不一样等等，不是那么容易实现的。那你可以想想，这种问题，是不是开发也会遇到，他们需要把服务部署运行在不同的环境下。开发是怎么做到的？</p><p>以SpringBoot为例，它提供了多profiles配置的功能，application.yml文件配置默认参数，application-dev.yml里放dev环境的配置参数，application-test.yml放test环境的配置参数，application-prod.yml里放production环境的配置参数。</p><p>当spring boot application启动时，会自动根据输入环境参数，加载相应的环境yml配置文件。这就实现了一份代码，多环境部署的场景。</p><p>我们的自动化测试也可以实现类似的机制。聪明的你，可以考虑自开发一个测试配置文件加载模块，代码不需要多，但会直接增加ROI。</p><p>最佳实践：一份代码，兼容多环境运行</p><h3>提高复用率：一份代码，多语言运行</h3><p>另外，如果你的产品支持多国语言，那么<strong>一份代码跑多国语言版本</strong>，也是一个会显著增加自动化测试ROI的好主意。</p><p>像上面的代码，当前只支持中文页面。假设我们的产品要求支持9种语言，那可以让页面控件加载不同语言的label text。</p><p>伪代码如下：</p><pre><code class="language-java">@Test\n@Iteration(UserPassword={xxxx,123456},{测试用户，Welcome1}....)\n@Iteration(Driver=ChromeDriver,FireFoxDriver.....)\n@Iteration(Profiles=auto-dev.yml,auto-test.yml,auto-prod.yml....)\n@Iteration(Language=en,zh_CN,zh_TW, FR....)\npublic void login() {\n  //此处是伪代码，代表从Iteration数组里拿到的driver元素\n  WebDriver driver=new Iteration("driver");\n  driver.manage().window().maximize();\n  //打开页面\n  driver.get(profile.getUrl());\n  WebElement username=driver.findElement(By.id("user_name"));\n  WebElement password=driver.findElement(By.id("user_password"));\n  WebElement login=driver.findElement(By.text(Label.getLoginText(language)));\n  //输入用户名\n  username.sendKeys(UserPassword[0]);\n  //输入密码\n  password.sendKeys(UserPassword[1]);\n  //点击登录按钮\n  login.click();\n}\n</code></pre><p>现在一份脚本经过了多浏览器、多数据、多环境和多语言4轮打磨，运行的次数n=n1+n2+n3+n4=12+15+4+9=40次。如果各个场景有关联关系，比如页面的语言和测试数据有耦合，英文页面的encoding和数据的charset有关联，那么两个场景的次数就是完全组合，采用乘法，15*9=135次。</p><p>而且，从脚本的变化可以看到，脚本第一版本里的hard code也一个个被消除了，取而代之的是数据驱动。<strong>消除hard code是提升ROI的结果</strong>。</p><p>当然，上面的代码都是伪代码，实际上为了支持多场景运行，付出的努力不止是增加循环那么简单。比如，支持多少种浏览器取决于框架，而不是脚本。像现在有一些新的基于JavaScript的测试框架，只支持chrome浏览器，开发人员很喜欢用它来验证功能，但从自动化测试角度来看，它的ROI就受限了，这些局限都应该框架选型时考虑进去。</p><h2>还有哪些工作值得做？</h2><p>第一讲提出ROI模型的时候，我就提过，成本里的维护工作量是一个不确定的风险。根据ROI金字塔模型，维护的工作量也是自底向上增加，不确定性增加。</p><p><img src="https://static001.geekbang.org/resource/image/07/f6/07aaf08df0b9a44987ed9a38faa412f6.jpg?wh=1920x1228" alt="图片"></p><p>维护工作量的不确定性是自动化测试的一个重要风险，所以我们有必要看一下维护的工作量都花在哪里了。</p><p>1.被测截面发生变化带来的维护工作量。比如UI自动化测试的产品页面发生了变化，API自动化测试的接口做了重构。</p><p>2.诊断自动化测试的工作量，如果把自动化测试结果分为真阳，假阳，真阴，假阴。那假阳和假阴都是需要诊断的。</p><p>诊断是要花费时间的，有这么几块：</p><p>1.从错误实际发生，到我们知道错误发生，这有一个<strong>通知</strong>的时间；<br>\n2.从开始诊断错误，到定位出错误，这要花费一个<strong>诊断</strong>的时间；<br>\n3.修复错误和验证修复方案，这也要时间，即<strong>修复</strong>时间；<br>\n4.修复上线后，跑出第一轮测试结果，证明完全恢复，这叫<strong>确认</strong>时间。</p><p><img src="https://static001.geekbang.org/resource/image/e8/f4/e85a5b985324f48fdbeef5de0d9178f4.jpg?wh=1920x459" alt="图片"></p><p>怎样能提高诊断的速度呢？从上面的分析，可以看到：</p><p>1.缩小通知时间，目标做到<strong>实时</strong>通知。一旦有错误出现，应该立刻有责任人被通知到，进入到诊断环节。</p><p>2.诊断越快越好，一旦确定为自动化测试脚本的问题，应该立即对团队做出说明，并将错误案例下线，避免持续出现相同错误，引起误解。</p><p>3.修复要彻底，一个案例持续不能给人信任的结果，将会打击团队的信心。我见过有的公司，自动化测试跑完一遍后，还要手工再去验证一遍，这样的自动化测试就失去了价值。</p><p>4.确认后，自动化测试快速恢复上线，开始使用。</p><p>你在这里，可以发挥技术能力，按照上面的方向努力，去降低自动化测试的维护成本，比如：</p><p>1.Log规范+ELK+Grafana实现告警实时传达。<br>\n2.检查点+日志+屏幕截图甚至视频，提高诊断效率。<br>\n3.高内聚低耦合的模块化设计，能够实现隔离错误，缩小影响范围，快速修复的效果。<br>\n4.自动化测试上下线的标准和流程的建立。</p><p><img src="https://static001.geekbang.org/resource/image/3f/26/3ffdb78yy842c96f530158b22e06d026.jpg?wh=1920x591" alt="图片"></p><h2>小结</h2><p>今天我最想和你传达的观点是：<strong>在提高收益的方向上，我们付出的每一份努力和尝试，都是值得的。</strong></p><p>其实自动化测试有个特点，它并没有一个显式的可验收交付目标。我们既可以写几行脚本就自动化一个案例，也可以实现一个支持控制台、多代理、持久化等功能的复杂系统。</p><p>但是别忘了自动化测试的本质，它是一个有业务需求的软件实现。这个业务需求以前没有人去讲清楚，学过这一讲，你就应该明白了，业务需求就是自动化测试ROI，想办法提高它是这个软件的唯一目的。</p><p>我讲到了提高代码ROI的通常的四种思路，一份代码，多浏览器运行，多数据运行，多环境运行，多语言运行，并用例子向你展示了，这个提供ROI的过程，也是消除代码Hard code，优化代码结构的过程。</p><p>另外，降低维护成本，也是提高ROI的一个非常有效的办法。我们分解了自动化测试的诊断时间，分为通知、定位、修复和确认四块时间，针对每一块时间，都有相应的办法去提高效率，这里我列出了一些常见办法，帮你在工作中找到更精准的目标，你可以保存下来做个参考。</p><p>总之，任何能够提高ROI的代码都是有价值的，反之，就是overwork。作为自动化测试架构师的你，在头脑里应该存在一个优先级从高到低的工作列表，先做哪块，再做哪块，按照ROI从高到低的顺序来安排。</p><p>你也应该能明白，在一个十几人的团队里，去做一个大规模的自动化测试项目，回报是追不回投入的，这样的项目即使能立项，最后也是死掉。反过来，如果你的领导愿意支持你去做一个复杂的系统，那他要么有一个推广提升的配套计划，要么是一个技术fans，像曾经的我一样，不尊重自动化测试的本质，也会败在ROI的规律手下。</p><h2>思考题</h2><p>回到这讲开篇的问题，思考一下你目前负责的自动化测试项目，是overwork还是underwork？</p><p>欢迎你在留言区和我交流互动，也推荐你把这讲内容推荐给身边的测试同学，一起精进技术。</p>',
        article_title: "04｜脚本复用：什么样的代码才值得写？",
      },
      {
        title: "05｜Auto Gen Auto：所有测试工作即代码",
        id: 499339,
        content:
          '<p>你好，我是柳胜。</p><p>我们前面用了4讲篇幅，讨论ROI模型和由此衍生出来的一套实践原则，从分层测试、选型思路和具体代码多个角度探索提升ROI的方法。</p><p>这些方法还都是基于常规的自动化测试开发流程，先有测试需求，再设计测试案例，然后做自动化。以登录测试为例，我画了一张流程图做说明。</p><p><img src="https://static001.geekbang.org/resource/image/e5/82/e524642fdd13d88e63de2900325f5e82.jpg?wh=1920x462" alt="图片"></p><p>自动化测试的开发成本，就是把测试需求转变成自动化测试代码这个过程花费的时间。在我们的图里，它是从左向右，所以我管它叫做<strong>水平开发成本</strong>。</p><p><img src="https://static001.geekbang.org/resource/image/5f/98/5fcyy4827fff8970ef6dc39aeb0ca598.jpg?wh=1920x709" alt="图片"></p><p>当登录功能测试需求发生变化时，就会重新走一遍这个流程，出现了多个版本的测试需求，也会带来多个版本的自动化测试案例。从下图可见，这个版本是自上向下增加，所以我管它叫做<strong>垂直维护成本</strong>。</p><p><img src="https://static001.geekbang.org/resource/image/ab/e4/ab257d846526c1e731da9812c9cd08e4.jpg?wh=1920x781" alt="图片"></p><p>我们现在可以直观地看到开发成本和维护成本了。好，问题来了，有没有办法<strong>从流程上动手术，来降低这两个成本呢</strong>？</p><p>这就是我们今天要讲的Automation Generate Automation，也叫自动化产生自动化测试代码，为了方便起见，下面的篇幅用缩写Auto Gen Auto来指代。</p><h2>Auto Gen Auto 技术</h2><p>常规的自动化测试，是指用代码实现设计好的TestCase，而Auto Gen Auto的目的是让Test Case生成也自动化，如下图所示。</p><!-- [[[read_end]]] --><p><img src="https://static001.geekbang.org/resource/image/b9/b0/b9650d372e55704a31431faa8f4cb6b0.jpg?wh=1920x770" alt="图片"></p><p>因为从测试需求到自动化测试案例是完全自动化的，每次需求改变的时候，只需运行一次Auto Gen Auto即可生成新的自动化案例，垂直维护成本为零。所以Auto Gen Auto技术如果能落地，ROI就会大大提高。</p><h3>从何处下手</h3><p>那Auto Gen Auto用在哪性价比更高呢？</p><p>业界熟知的测试方法是黑盒测试和白盒测试。白盒测试从测试案例设计开始，需要我们先了解代码逻辑结果，一个函数里有几个判断分支，处理那些数据。基于这些了解，再设计案例验证函数输出和达成代码覆盖率。</p><p>在白盒测试里，Auto Gen Auto不是啥稀奇事，XUnit框架都提供了不少开发IDE的plugin，可以扫描一个class的函数，直接产生test方法。开发人员只需补充少量代码，test方法就可以运转起来了。</p><p>与之对应的是黑盒测试，测试案例设计不基于产品代码，而是用户规格说明。比如，用户在订餐系统上完成一个订单，用户该怎么操作，下单成功后应该收到物流单号等等，设计这些测试案例的目的是验证业务能够完成，不需要去看代码。</p><p>今天，我们要关注的是<strong>在黑盒测试领域的Auto Gen Auto</strong>，这个更有挑战性，也更有探索价值。因为，作为测试人员花了大量时间来设计黑盒测试案例，而且还要手工维护这些测试案例的变化，这个过程要是都能自动化了，就会省去很大的重复又枯燥的工作量。</p><h3>如何实现</h3><p>怎么做到Auto Gen Auto呢？用代码生成代码，前提是测试需求得有一定的规则或模式，然后代码才能解析规则，根据规则生成最终的测试代码。</p><p>这个实现思路，在开发中是很常用的，比如Maven Archetype使用模版自动生成项目代码，Soap使用WSDL来生成调用桩等等，原理图如下。</p><p><img src="https://static001.geekbang.org/resource/image/0f/cd/0f556ba335e4fef6286140819d804acd.jpg?wh=1920x901" alt="图片"></p><p>所以，要做Auto Gen Auto，我们的目标是先要找出测试需求里的这些规则，并把它们表达出来，放在一个规则文件里。我们看看下面的例子。</p><h2>测试等价类的规则</h2><p>远在天边，近在眼前，我们在测试案例设计中经常用到的等价类和边价值方法，就可以作为Auto Gen Auto的规则。</p><p>等价类是指某个输入域的子集合，在同一个子集合里的所有元素对于测试的效果都是等价的。</p><p>我们要测试一个订餐系统的用户名，首先要了解用户名上的约束。从长度上来看，假设用户名最大长度是255个字节，根据这个约束，至少能产生2个测试等价类：有效等价类是小于255字节的用户名，无效等价类是大于255字节的用户名。测试用户注册功能时，就可以用到这2个等价类了。</p><p>用同样的思路看用户名的另外一个约束，那就是字符类型的限制，假设用户名只能由英文字母和数字组成，根据这个约束，又可以产生多个等价类，中文字符、ASCII字符、数字、High ASCII等等。</p><p>看到没有？其实我们用等价类方法设计测试案例时，遵循的是<strong>等价类划分规则，设计出来的测试案例也与等价类一一对应</strong>。但手工做这些，工作量会很大，因为整理约束时会有遗漏，改变约束的时候，也容易忘了维护测试案例。</p><p>如果能让测试案例和等价类自动对应，然后依据规则动态产生测试案例，这些问题就会迎刃而解。不过，我们得先把这些约束规则外化表达出来，在这里，我用一个user-rule.yaml文件来表达这些规则。</p><pre><code class="language-yaml">name: user name rules\n  appliedTestCase: register, login\n  rules:\n    lengthRule:\n      express: &lt;=255 chars\n    characterRule:\n      express: value&gt;=97 and value&lt;=122\n      express: value&gt;=48 and value&lt;=57\n</code></pre><p>为了让这个YAML文件能对代码友好，我把express表达式部分做了技术处理，ASCII值从97到122之间是a～z的字符，48到57是数字0～9。</p><p>然后，我们写一段代码，从这个YAML文件中直接把规则加载进来，在内存中形成一个分类树。</p><p><img src="https://static001.geekbang.org/resource/image/dd/9a/dd045b1924fd30754b50c7c51f90d69a.jpg?wh=6675x2935" alt=""></p><p>1个用户名，有2个约束，每种约束都取1次不同的等价类，那测试案例的组合总共有2 * 5= 10个测试案例。</p><p>如果对每一个等价类再加上权值，我们还可以根据权值，过滤掉部分权值偏小的测试案例。基于YAML可以生成以下测试案例，从案例名字，你可以看出用户名的取值规则：</p><p>TestUserNameLengthLessThan255<br>\nTestUserNameLengthBigThan255<br>\nTestUserNameAsciiValueLessThan48<br>\nTestUserNameAsciiValueBetween48And57<br>\nTestUserNameAsciiValueBetween57And97<br>\nTestUserNameAsciiValueBetween97And122<br>\nTestUserNameAsciiValueBigThan122</p><p>好，这里看到成果是很明显的。因为测试案例的生成是自动化的，所以，以后需求变化时，比如允许用户名出现中文，那就在user-rule.yaml里增加一条rule，测试案例也会自动被修改，测试案例维护工作量等于0。</p><p>到这里，我再画个图总结一下这个方案的实现思路。</p><p><img src="https://static001.geekbang.org/resource/image/19/3d/19146e8321dc45e65cedd9052661cf3d.jpg?wh=1920x889" alt="图片"></p><h2>业务的逻辑规则</h2><p>用等价类的规则表达小试牛刀后，我们尝到了甜头。看来，只要能把规则表达出来，生成测试案例这个工作就可以交给代码去做。我们再找一个更加实用的场景，来看看怎么落地。</p><p>在做API测试的时候，restAPI的接口一般是通过Open API规范来描述。在设计阶段，开发先定义要实现的API接口，Client要发送什么样的Request，Server要返回什么样的Response。</p><p>比如下面的user-restapi.yaml文件，就是遵循Open API规范，定义了一个根据name查询User的RestAPI。</p><pre><code class="language-yaml">/api/users:\n    get:\n      description: 通过name查询用户.\n      parameters:\n        - username\n          type: string\n          description: 用户name\n      responses:\n        \'200\':\n          description: 成功返回符合查询条件的用户列表.\n          schema:\n            type: array\n            items:\n              $ref: \'#/definitions/User\'\n</code></pre><p>这个接口很简单，但它也声明了一个简单的契约，Client要想查询User，它需要向server发送一个http get请求，发送的url格式如下：</p><p>http://{host}:{port}/api/users?username=liusheng</p><p>而server如果查询到了User，它应该返回这样一个http status code为200的response，内容如下：</p><pre><code class="language-yaml">{\n        "items": [\n          {\n            "ID": "123456",\n            "name": "liusheng",\n            "age": 18\n          }\n          ]\n}\n</code></pre><p>YAML文件里定义接口所用到的关键字，像get、description、parameters等等，它们都是Open API里定义好的，含义也是明确的，那么YAML表达出来的规则内容也是可以解析出来的。因此，我们同样可以根据规则内容，直接生成测试代码。</p><p>实际上，业界已经有了现成的工具，有Spring Clond Contract，也有<a href="https://github.com/OpenAPITools/openapi-generator">OpenAPI generator</a>。</p><p>我们这就借用这个工具跑一下，把它下载到本地，运行如下命令行：</p><pre><code class="language-yaml">java -jar openapi-generator-cli.jar generate\n&gt;&nbsp; &nbsp;-i user-restapi.yaml \\\n&gt;&nbsp; &nbsp;-g java \\\n&gt;&nbsp; &nbsp;--library rest-assured\n</code></pre><p>运行后就会生成一个基于RestAssure的测试项目。这个自动生成的项目里包含了API测试运行所需要的Client、Config、Model、API所有代码。</p><p><img src="https://static001.geekbang.org/resource/image/f0/d6/f0bd34e107d3bd7594fbea0bcda010d6.png?wh=582x522" alt="图片"></p><p>对照上图，UserApi.java里的testGetUserByName函数，就是根据YAML文件的API定义自动生成的测试代码，可以直接运行。</p><pre><code class="language-java">@ApiOperation(value = "Get user by user name",\n        notes = "通过name查询用户")\n@ApiResponses(value = { \n        @ApiResponse(code = 200, message = "成功返回符合查询条件的用户列表") })\npublic GetUserByNameOper testGetUserByName() {\n    return new GetUserByNameOper(createReqSpec());\n}\n</code></pre><p>是不是很酷？一份契约就这样变成了可执行的测试代码，完全不需要任何开发工作量。</p><p>在解放生产力这件事上，优秀的工程师从不满足。上面只生成了一个测试案例，能不能生成多个测试案例，做更多的测试覆盖，让这个好点子物尽其用呢？</p><p>当然可以，按照等价类规则的思路，多个测试案例来自于多个约束，那我们可以在YAML文件中，加入username更多的约束描述。在user-restAPI.yaml文件里，username加两行属性，minLength是5，maxLength是255，代表用户名最小长度是5个字符，最大长度是255个字符。</p><pre><code class="language-yaml">/api/users:\n    get:\n      description: 通过name查询用户\n      parameters:\n        - username\n          type: string\n          minLength: 5\n          maxLength: 255\n          description: 用户name\n         .............\n</code></pre><p>现在，我们就可以用等价类规则转变成测试案例的思路，解析YAML文件，把testGetUserByName分裂生成多个测试方法了：</p><p>testGetUserByNameLengthLessThan5<br>\ntestGetUserByNameLengthBetween5And255<br>\ntestGetUserByNameLengthBigThan255</p><p>OpenAPI generator这个开源工具就说到这，你可以根据具体需求灵活修改它，加入对YAML文件任何属性的解析，赋予它测试上的意义，使之成为强大的Auto Gen Auto工具，为你所用。</p><p>到这里，我们回顾一下，想要做好API测试0代码，自动生成的测试案例够多，有2个隐含的前提条件要满足：</p><p>1.API设计先行。在API<strong>设计阶段</strong>就要理清接口规则并把它表达出来。</p><p>2.在API接口的规则文件里，规则描述得越详细，可自动生成的测试案例就会越多。</p><p>在实践中，我看到很多公司忽视了API设计先行原则，开发团队写完代码，再生成YAML接口文件，然后交给测试人员开发API测试代码，这把流程恰好搞颠倒了。本来应该是根据接口设计文档来开发代码，开发和测试都能依据设计并行展开工作，这个做法也会促进团队在设计阶段考虑好设计。</p><p>但是，先写代码再产生接口文档，实际就会默许甚至鼓励开发人员先信马由缰写代码，写出来什么接口都算数。从API测试角度来看，测试需求就处在一个不稳定的状态，会带<strong>来高昂的自动化测试垂直维护成本</strong>。在第二模块里，你也会看到，设计先行对于开发人员内部协作也至关重要。</p><p>另外，有了一份定义完备详细的接口设计文档，Auto Gen Auto解决方案才可能实现。它不仅能够生成API test，还可以生成performance test等等。</p><p>有兴趣你可以自己研究一下这块的工具（相关工具有兴趣你可以点<a href="https://github.com/sheng-geek-zhuanlan/awesome-test-automation">这里</a>了解），OpenAPI是其中的一个，我们在后面的课程还会提到Spring Cloud Contract，也是类似的解决方案。</p><h2>小结</h2><p>今天，我们一起学习了如何通过Auto Gen Auto技术，进一步降低我们的开发、维护成本。白盒测试中实现自动生成并不稀奇，所以我们把重心放在了更有挑战的黑盒测试领域。</p><p>想要自动生成测试案例，需要我们先洞察业务场景里的规则，并把它表达出来，形成文档，在团队里达成共识，作为<strong>开发和测试的契约</strong>。</p><p>我们先从黑盒测试里最熟悉的等价类案例设计方法开始，把用户名的命名规则整理清楚，并且把它表达在一个YAML文件里，将这个规则作为我们Auto Gen Auto的输入。然后经过加载，解析，最后输出测试案例。在这个过程中，我们关注的是实现思路，没有给出具体的实现方案，有兴趣你可以自己尝试一下。</p><p>在第二个例子里，我们着重看业界经验，以OpenAPI为例，它对RestAPI接口设计不仅有设计规范，还提供了一套工具集，我们使用了它的Generator生产了一个查询user的测试案例代码，你能直观感受到它的便利。而且，像OpenAPI generator代码都是开源的，你完全可以改造它，做适合自己项目的定制化扩展。</p><p>做Auto Gen Auto这样的项目，带来的ROI是非常高的，一次性开发工作量，不需要代码维护工作量。重要的话再说一遍：<strong>任何提高ROI的努力，都是值得去尝试的。</strong></p><h2>牛刀小试</h2><p>访问<a href="https://github.com/OpenAPITools/openapi-generator">https://github.com/OpenAPITools/openapi-generator</a>，按照指令，运行generator命令，在Python，JavaScript，Java，Go四种语言里选一种生成代码。</p><p>欢迎你在留言区和我交流互动，也推荐你把这讲内容推荐给身边的测试同学，一起精进技术，提升效率。</p>',
        article_title: "05｜Auto Gen Auto：所有测试工作即代码",
      },
      {
        title: "06｜左移&右移：测试如何在Dev和Ops领域大展身手？",
        id: 501526,
        content:
          '<p>你好，我是柳胜。</p><p>前面的几讲，你已经学习了ROI模型，它开始于一颗带有ROI DNA的种子，不断生长，直到长成一棵大树。从树根到枝干、从规律到原则，它贯穿了一个自动化测试项目，从生到死的完整生命周期：设立目标，制定策略，选择框架到代码的实现，上线的度量，再到衰竭退出。</p><p>我把价值篇讲过的内容加以整理，得到了下面的树结构。上面的绿色部分是收益，下面的红色部分是成本。ROI模型树从左到右，是从根到枝干，从ROI理论到实践的延伸和具象化。</p><p><img src="https://static001.geekbang.org/resource/image/be/e2/bebf2e6673b64e11a0ff32703f7be0e2.jpg?wh=1920x1346" alt="图片" title="ROI模型树"></p><p>ROI模型展开的这棵大树，告诉了我们健康的自动化测试项目长什么样子。但是还有一个现实的问题，我们怎么从这里到那里？换句话说，咱们怎么把自动化测试项目的节奏带起来，让它进入到一个不断提升ROI的轨道上去。</p><p>这里有一个很朴素的道理，好马是跑出来的，好钢是炼出来的。首先，要让自动化测试跑起来，增加它的运行次数，这是前提条件。在这个过程中，再修复它的问题，调整它的集合，提高它的可诊断性，整个项目就激活了。</p><p>所以，你要找到更多的土壤让自动化测试落地生长。如果你想在工作中推广自动化测试，哪些落地场景更容易出业绩呢？除了之前说过的回归测试领域，我们不妨把眼光从测试工作放宽到更多的领域，Dev和Ops领域，自动化测试在这些领域里一样可以发挥价值，我叫它自动化测试左移和自动化测试右移。</p><!-- [[[read_end]]] --><h2>自动化测试左移</h2><p>如果把软件的生命周期的一个个阶段，软件需求分析、软件设计、软件开发、单元测试、集成测试、系统测试，从左向右排列，开发活动在左侧，测试在后面也就是右侧。如下图：</p><p><img src="https://static001.geekbang.org/resource/image/dd/7e/dd3a0yy1cf966aa256381d98c874eb7e.jpg?wh=1920x596" alt="图片"></p><p>测试左移，就是说本来在生命周期后期的测试活动提前，在软件开发阶段就参与进来，能让软件质量内建到开发阶段，而不是在后期通过软件测试去发现。比如在需求分析阶段参与需求评审和规范制定，在软件设计阶段就开始测试案例设计。形象地看，是测试活动从右侧向左侧移动，即测试左移。</p><p><img src="https://static001.geekbang.org/resource/image/2d/98/2d6ac663a3887698a082bec930e03698.jpg?wh=1920x761" alt="图片"></p><p>测试左移后，当然也会带动自动化测试的变化。在传统模式下，按照软件生命周期顺序，自动化测试是这么安排的：编码完成之后运行单元测试，集成阶段运行接口测试，系统阶段运行UI自动化测试。</p><p><img src="https://static001.geekbang.org/resource/image/dd/b4/dd932dfef516dc7cd67faf0d94cf42b4.jpg?wh=1920x744" alt="图片"></p><p>这种流水线做法只能说中规中矩，那还有优化提升空间么？从图上看到，我们如果在编码阶段引入了bug，影响接口的bug要等到集成测试阶段才能发现，影响UI的bug要等到系统阶段才能发现。我们既然已经有了接口和UI自动化测试，可不可以把它们利用起来，尽早测试呢？</p><p>现在我提出一个新概念，自动化测试左移，在构建阶段建立一个冒烟测试集合的概念，包括单元测试和部分接口测试，甚至部分UI自动化测试，它们一起运行，来验证版本的每一次构建甚至代码的每一次提交。只要这个冒烟测试集合足够快和稳定，就可以被开发人员接受。</p><p><img src="https://static001.geekbang.org/resource/image/01/ee/0130fa2b9b66a43832a522dc39d528ee.jpg?wh=4563x1975" alt=""></p><p>自动化测试左移都有哪些好处呢？</p><p>最直观的好处是提早确认代码的变更，满足最终需求，尽早发现回归bug。软件测试领域有一个理论，叫做<strong>验证</strong>和<strong>确认，</strong>在每个软件阶段，都要做两种测试工作：第一是验证当前阶段做好了本阶段要求的事情。比如，编码阶段要把详细设计实现；第二是确认当前阶段实现的功能，可以满足最终的用户需求。</p><p>应用到具体场景里，在编码阶段做单元测试这叫验证，在编码阶段运行接口测试和UI自动化测试则是确认，都是有价值的测试活动。</p><p>此外，自动化测试就像一辆赛车，需要运行调试、持续保养维护，才能调整到最佳状态。</p><p>我见过一些团队，只在软件产品发布的时候，才把开发出来的UI自动化测试作为验收测试运行一次。这样UI自动化测试大概率会失败，测试人员不得不花时间一一解决。不难猜到，在整个发布周期里，UI功能都变化了很多，相应的漏洞更是不可胜数。久而久之，测试人员就对自动化测试产生了厌烦，把它看成摆设、负担，又重归手工测试的状态。</p><p>而自动化测试左移到开发的日常活动中，开发人员每天做一次code commit，做一次版本构建就会触发自动化测试，运行频率随之提高。一旦自动化测试运行失败，要么是发现了回归bug，要么是自动化测试需要维护了，问题发现得越早，修复越快，自动化测试就越健康，越稳定可用。在磨合调试的动态过程里，自动化测试越跑越稳定高效，团队也能实实在在体会到它的用处。</p><p>所以，自动化测试左移在结果上提高了ROI，丰富了运行场景，也锻炼了自动化测试项目和人马。火炼真金，大浪淘沙，方能走向成功。</p><h2>自动化测试右移</h2><p>既然有左移，那也存在右移。测试的右移是什么？测试阶段结束，产品就会上线，也就进入了线上运维阶段。所以测试右移是指<strong>测试活动介入线上运维，用户画像等工作</strong>。这里我说的自动化测试右移，意思是自动化测试也可以在生产环境里运行，起到一个自动检查监测的作用。</p><p>你可能会问，线上观测已经有了一套Ops流程和工具了，比如Newrelic和Splunk等，都能监测Web服务、API网关，数据库等全栈环境了。自动化测试线上运行的价值在哪里？</p><p>这是一个很好的问题。如果你想到了这一层面，说明离我们的右移的落地场景很近了。我们不可能把所有的自动化测试都搬到生产环境里，这样会造成和Ops团队的重叠浪费。</p><h3>部署后验证测试</h3><p>Ops工具看似很强大，能输出一堆软件服务的各种度量指标，告诉我们软件服务在生产环境里是健康运行的，但是有一个关键的事情，我们无法从Ops那里得知：那就是<strong>服务是不是按照客户的期望运行的，这对产品价值非常重要，但只有运行测试才能知道</strong>。</p><p>结合具体场景，我们分析一下这个问题是怎么产生和解决的。</p><p>线上升级常用的做法是红绿部署（也叫蓝绿部署）。红绿部署的机制是这样的，当准备升级软件服务时，保持原有的服务红色环境不变，部署一套新的服务绿色环境。在路由层面，把流量切换到绿色环境，完成软件的升级。这样做的好处是，软件升级对用户影响微小，风险也可控。</p><p><img src="https://static001.geekbang.org/resource/image/24/19/2436efdc7754257459ea9eaa5f787319.jpg?wh=2755x1288" alt=""></p><p>在这个红绿部署机制里，红环境代表是即将退役环境，绿色环境是健康即将上线环境，那么一个关键问题是，怎么确定环境是红的还是绿的？</p><p>环境是绿的，意味着对于用户来说一切正常。这个“正常”的标准，有2个含义，一是Ops的服务健康指标都正常，二是测试的结果也正常，这个测试集合在业内英文名叫Post Deployment Test，中文叫部署后验证测试。意思是在生产环境完成部署或升级后，需要验证业务功能正常运行。</p><p>通过Post Deployment Test的通过与否，来设定环境是绿色还是红色。像下图：</p><p><img src="https://static001.geekbang.org/resource/image/9a/75/9a48f91415e62509044f7fae175de575.jpg?wh=1920x1129" alt="图片"></p><p>这样，Post Deployment Test结合部署的红绿机制，可以形成一个发布升级，环境切换的决策流程。我们又一次丰富了自动化测试运行的场景，让它变得“有用”。</p><h3>生产环境定时监测</h3><p>部署升级后，生产环境就开始运行了，直到下一次升级为止。在这段线上运行的时间里，是不是就不再需要测试了呢？</p><p>按照传统测试理论，测试的生命周期到正式发布为止，也有的到Beta测试为止，而部署到生产环境后，就进入了运维阶段，就是Ops工程师的事了，测试人员就不需要关注了。</p><p>但在云时代情况发生了变化。软件开发方不仅交付软件服务，而且也控制着服务器的运行环境。因此测试人员的责任从“在软件发布之前发现bug”变成了“在客户之前发现bug”。</p><p>有很多bug，在测试环境里是发现不了的，只有生产环境才能暴露。这些跟客户的行为、生产环境的数据、特定的错误扩散模式都有关系。只要我们在客户遇到bug之前发现它，测试工作仍然是有价值的。</p><p>这时我们可以建立一个机制，通过自动化测试来定时监测生产环境。每天定时触发自动化测试任务的运行，去检测生产环境的业务功能是否正常，然后生成测试报告。</p><p><img src="https://static001.geekbang.org/resource/image/1a/35/1a82912b949edf4e5dc180fffbf2f835.jpg?wh=1920x1174" alt="图片"></p><p>对于自动化测试生成的结果报告，我们还可以把它集成到Ops的Oncall流程里去。当自动化测试任务出了错误，触发Event时，就会进入到Oncall系统。Oncall系统会找出值守的测试人员，发送通知，让测试人员来处理测试错误，判断是不是线上出了bug。</p><p><img src="https://static001.geekbang.org/resource/image/b7/00/b7419b7a9e3f49934065061f3e644600.jpg?wh=1920x1114" alt="图片"></p><p>这个机制一旦建立起来，会大大锻炼你的测试人员队伍，因为你每天会收到各种告警，需要去处理，直到你真的把自动化测试的健壮性和稳定性，提升到一个“可信”的程度。</p><h2>小结</h2><p>这一讲，我们一起总结了自动化测试的ROI模型树，还有种种可以提高自动化测试收益的落地场景。从业界来说，有左移和右移这两个大领域，使得测试的工作不再局限于原先的那个圈圈里，而是向Dev和Ops方向延伸，并和它们融合。</p><p><img src="https://static001.geekbang.org/resource/image/be/e2/bebf2e6673b64e11a0ff32703f7be0e2.jpg?wh=1920x1346" alt="图片" title="ROI模型树"></p><p>这个左移和右移已经不是在理念阶段了，而是业界正在发生的事情，参看<a href="https://lp.katalon.com/hubfs/download-content/report/The-State-of-Quality-2022.pdf">2022世界软件质量报告</a>，有38%的公司已经在Ops领域开展测试了，而且这个数字还在增长。但是，要完成左移和右移并不容易。据我了解，很多公司还没有做好准备，一个重要的方面是意识上还没有转变。</p><p>今天，你学习了本模块的ROI模型之后，知道ROI是我们自动化测试工作成败的命脉，那你不妨换个思维角度，像做销售一样，向团队向公司积极布道你的自动化测试成果，让更多的角色来使用你的服务。</p><p>这块不局限于Dev和Ops团队，甚至可以是Product Manager团队，自动化测试代码调用是一个非常好的服务模式，一旦他们开始使用，就相当于你的服务有了客户，可以通过客户的反馈，持续打磨你的服务，<strong>这个服务的最后结果就是自动化测试持续输出“有用”和“可信”的结果</strong>。</p><p>在“有用”和“可信”基础上，如果再加上一个要素的话，我认为应该是“快速”，自动化测试服务的输出是当前的被测系统是否OK，没有人愿意忍受等几十分钟才能获得服务的结果。在Devops理念横行的今天，人们的耐心越来越低，你应该让自动化测试运行得精准、快速、高效。这给自动化测试提出了更大的挑战。</p><p>如何应对挑战，我们后续课程还会提出更有针对性的解决方案。是不是很期待下面的内容？那就准备好进入下一模块吧。</p><h2>思考题</h2><p>今天留两个题目，你可以任选一个有兴趣的聊聊想法。</p><p>1.什么是蓝绿部署？蓝代表什么？什么条件下变成绿？</p><p>2.学完这讲内容，你觉得自己手里负责的工作有没有左移或右移的空间呢，具体你想怎么做？</p><p>期待你在留言区跟我交流互动，如果这一讲对你有启发，也推荐你把它转发给更多同事、朋友。</p>',
        article_title: "06｜左移&右移：测试如何在Dev和Ops领域大展身手？",
      },
    ],
  },
  {
    chapterTitle: "大开也能大合 - 策略篇",
    children: [
      {
        title: "07｜需求提炼（一）：单体应用要测什么？",
        id: 502863,
        content:
          '<p>你好，我是柳胜。</p><p>通过第一模块价值篇的学习，我们已经掌握了自动化测试效益的量化思维。理解思路还不够，我们在设计篇这个新模块，会把自动化测试里的各种类型、策略和实现技术都梳理一遍，把上个模块学到的知识应用起来，通过科学设计达到测试效益整体最优的目标。</p><p>为了让学习过程更接地气，尽可能贴近你日常的工作应用，我们这个模块会围绕一个具体的订餐系统项目，逐一分析它的需求、接口、用户场景，然后制定相应的自动化测试方案。掌握了这套推演逻辑，对单元测试、接口测试和系统测试，哪个层面的测试应该做什么、工作量分配比例是多少，你都能胸有成竹。</p><p>今天这一讲，我们的目标是整理出清晰、完整的测试需求，这是所有测试工作开始的第一步。有了这个基础，后面才能制定计划、设计自动化测试用例，完成测试代码开发。</p><h2>FoodCome的单体系统</h2><p>我们现在有一个名为FoodCome的应用。它刚开发出来的时候是一个单体系统。</p><p>这里要解释一下，什么是单体系统。一般的理解是，单体系统是一个整体，用一种语言开发，一次构建所有代码，产生一个部署实体，在运行态下是一个进程。比如常见的Web应用，就是一个war包。</p><p>这个FoodCome就是一个Web应用，它为用户提供点餐功能。用户可以通过手机下单点餐，订单生成后，餐馆可以接单，厨房制作完成，转给物流交付给用户。</p><!-- [[[read_end]]] --><p>为了分析测试需求，我们用六边形架构图方法来理清系统内外的交互接口。六边形架构法是把服务画成一个嵌套的六边形，最外层的大六边形是适配器层，代表了本系统和对外的所有交互。里层的六边形是领域业务层。适配器层负责对外交互，这个和业务关系不大，一般是通用的技术，主要是驱动、协议和基础设施，而领域层是业务逻辑的组织和实现。如果你对六边形架构不太熟悉，还可以参考<a href="https://www.jianshu.com/p/c2a361c2406c">这里</a>了解。</p><p>为了简化，这里我只画出顾客下单和餐馆接单两个交互。</p><p><img src="https://static001.geekbang.org/resource/image/fa/d0/fac704c6fdf992540968669e1a468bd0.jpg?wh=1920x1326" alt="图片"></p><p>FoodCome是一个单体系统，它运行起来后，外层六边形上的接口有这么2种：</p><p>1.用户接口，用户有2种类型，一个是食客顾客，一个是餐馆业主。顾客通过手机下单，进入到FoodCome系统，而餐馆通过FoodCome的Web客户端可以查看和接受订单。</p><p>2.适配器接口，和第三方系统的集成接口。FoodCome集成了物流系统、通知系统和支付系统。顾客的订单通过支付系统完成支付后，餐馆开始加工，加工完毕后，食品通过物流系统快递给顾客。整个工作流，都会有状态的变更通知发送给用户。</p><p>2种接口明确了，我们再具体分析下测试需求都有哪些。</p><h2>用户接口的测试需求</h2><p>想定义测试需求，先要明确功能需求。功能需求是描述软件的功能，听着是不是像循环定义？想描述清楚软件的功能并不容易，这里我们借用迈克·凯恩提出的方法，一个软件软件功能需求要回答这三个问题：<strong>第一，这个功能存在的价值是什么？第二，软件是怎么实现这个价值的？第三，这个功能能给谁带来价值？</strong></p><h3>用户故事User Story</h3><p>刚才说的这三个问题，到后来就成了User Story的表达3要素，WHY为什么、WHAT是什么和WHO为谁，把这三个要素说明白了，这个功能也就表达出来了。</p><p>我们用FoodCome举个例子。“用户下单买食物”这么简单一句话，算不算一条功能需求呢？算，因为它包含了那3个基本要素，目的（WHY）、行为（WHAT）和人物（WHO）。用户是主体人物。他做了什么呢？下单。下单有什么价值呢？能得到食物。所以这就是一个最精简的功能需求表达。</p><p>细节是魔鬼，我们再来看个反例。相比来说，我相信不少人都会看到这样的需求：“用户使用username，password来登录FoodCome。”这是不是一条功能需求呢？</p><p>这句话里好像也包含了目的、行为和人物，但它并不是一个合格的功能需求。“使用username，password”和“登录FoodCome”这两个都是登录的行为，还是在重复WHAT，并没有说明登录的价值。</p><p>所以它的正确描述，应该是“用户登录FoodCome来购买食物”，或者“用户登录FoodCome来获得优惠券”，“购买食物”和“获得优惠券”是受登录保护的功能，也是能给用户带来价值的事情。</p><p>这个细微的差别，迈克·凯恩曾经这样说“A user story is a way of remembering that a piece of work why need to be done, without committing to actually doing it, or diving into the details too soon”。意思是，功能需求的主要目的是描述功能的商业价值逻辑，而不是刻画实现的细节。</p><p>如果我们用一个语句范式来组织前面三个要素，就是下面这样：</p><pre><code class="language-java">As a&nbsp;&lt;type of user&gt;\nI want&nbsp;&lt;capability&gt;\nso that&nbsp;&lt;business value&gt;\n</code></pre><p>用了这样一组关键字，as a说明用户的角色，I want to后面是描述用户的行为，so that是获得的商业价值。<br>\nFoodCome的下单功能描述就变成了这样：</p><pre><code class="language-plain">As a customer of foodcome,  \nI want to place an oder for food\nso that the food arrive in 30 minutes \n</code></pre><p>作为顾客，我希望能在FoodCome上下一个单，然后食物在30分钟内就来到我眼前，这就是FoodCome下单给我带来的价值。</p><p>用户下单之后，餐馆就会接单。FoodCome的接单功能描述如下：</p><pre><code class="language-plain">As a restaurant of foodcome,  \nI want to accept an order from customer\nso that I can be paid after deliver the food \n</code></pre><p>那你可能会说，这个需求很笼统啊，作为开发人员不知道怎么实现，作为测试人员也不知道怎么测？好，这时就要进入BDD feature阶段了。</p><h3>测试需求BDD Feature</h3><p>BDD的全称叫做Behavior Drive Development，<strong>行为驱动开发模式</strong>。想达到驱动开发的程度，这个Behavior行为的定义就要足够细化，开发人员知道怎么去实现了，同样，测试人员也知道该怎么测试了。</p><p>BDD是怎么做的呢？它把User Story细化成一个或多个feature，每一个feature都是一个可测试的场景。</p><p>这个feature的文件书写也是有格式要求的，通过一个叫做Gherkins的语法关键字模版来写feature文件。</p><p>Gherkins提供的常见关键字有：</p><p><strong>Given:</strong>  用户场景的前提条件，可以是时间条件，也可以是另外一个用户场景的输出结果。</p><p><strong>When</strong>:  用户在这个场景里做的行为操作</p><p><strong>Then</strong>:   行为的输出结果</p><p><strong>And</strong>:  连接多个关键字</p><p>Gherkins还提供了更多其他关键字，你可以参看<a href="https://cucumber.io/docs/gherkin/reference">这里</a>了解更多。</p><p>使用Gherkins语法，描述下单的Feature，是下面这样的：</p><pre><code class="language-plain">Given a consumer\n  And a restaurant\n  And a delivery address/time that can be served by that restaurant\n  And an order total that meets the restaurant\'s order minimum\nWhen the consumer places an order for the restaurant\nThen consumer\'s credit card is authorized\n  And an order is created in the PENDING_ACCEPTANCE state\n  And the order is associated with the consumer\n</code></pre><p>我们可以看到，在Given、When、Then这些关键字的组合下，BDD feature比User Story丰满多了：一个用户下单的条件是什么，有地址的约束、信用卡的付款授权，下单之后的结果是什么，订单在系统里被创建，状态是Pending_Acceptance。</p><p>同样的，餐馆接单的feature文件如下：</p><pre><code class="language-java">Given an order that is in the PENDING_ACCEPTANCE state\nWhen a restaurant accepts an order with a promise to prepare by a particular\n&nbsp; &nbsp; &nbsp;time\nThen the state of the order is changed to ACCEPTED\n&nbsp; And the order\'s promiseByTime is updated to the promised time\n</code></pre><p>Given、And、When、Then这些关键字，和编程语言里的If，else，then相似，所以Gherkins描述方法从自然语言向编程语言迈进了一步，更加详细精准，也更符合软件技术人员的习惯。</p><p>到这里，我们就通过BDD把可测试需求表达出来了。这个Feature要细化到什么程度呢？从测试角度来看，要达到可测试的程度，也就是说要能够通过feature来验收User Story，所以，feature在敏捷开发里又叫Accept Criteria，在传统测试里叫做验收标准。</p><p>我画了一张图，User Story和Feature的关系，你会看得更清楚一些</p><p><img src="https://static001.geekbang.org/resource/image/0b/68/0bdf40d5dcb13050bd3232e2b2580468.jpg?wh=1920x1185" alt="图片"></p><p>既然有了测试需求，建立了验收标准，后面再做验收测试就很轻松了，这个怎么做验收测试的问号，我先卖个关子，留到第16讲为你揭开答案。</p><h2>适配器接口的测试需求</h2><p>说完了功能需求如何表达，我们再来看看适配器接口。</p><p>FoodCome和3个外部服务有集成，分别是物流系统、通知系统和支付系统。和用户接口的强业务属性不同的是，适配器接口的技术属性强，因为适配器层走的都是协议和数据，这里我们的难点是，每个适配器接口用到的协议是不一样的，比如物联网用的MQTT，同步调用用restAPI，异步调用用Message Queue等等，那怎么把他们的测试需求梳理出来呢？</p><p>像使用Gherkins语法来表达功能需求一样，我们也可以通过一个契约的概念，理清集成点的内容。</p><p>一份契约的形成，包含以下几个要素：</p><ul>\n<li><strong>服务提供者</strong>：提供服务的一方</li>\n<li><strong>服务的消费者:</strong>调用服务的一方</li>\n<li><strong>交互风格</strong>: 双方交互的类型</li>\n<li><strong>契约的实现方式</strong>:  交互用到的具体协议和方法</li>\n<li><strong>契约内容</strong>： 交互的数据<br>\n在软件设计阶段，就应该定义契约，用什么服务、基于什么协议、消费者需要发送什么request，以及服务提供者返回什么response等等；在软件开发阶段，开发人员需要按照契约来实现代码；到了测试阶段，我们的任务就是验证双方是否按照之前定义的契约进行交互。</li>\n</ul><p>按照契约格式，可以整理出FoodCome的集成点，结果你可以参考下表：</p><p><img src="https://static001.geekbang.org/resource/image/e1/81/e18114d6163ec3b7a096a2d46b618d81.jpg?wh=1920x850" alt="图片"></p><p>在实际工作中，你可以把这张表扩展和细化，加上版本信息，项目计划等等，让这个表更具有可操作性。</p><p>好，到这里，收割一下成果，对于单体系统，我们用六边形法找到了系统对外的交互点。这些交互点上，有不同类型的需求。根据测试点类型，我们采用不同方法来表达这些测试需求。</p><p>1.功能需求用gherkins语法表达出user story。</p><p>2.把第三方服务的集成点整理成契约。</p><p>其实测试需求不仅是功能需求和第三方服务集成这两种，还有安全性、兼容性、易用性和性能等方面的需求。不过我们这个专栏关注的是自动化测试，所以其他需求不做讨论。</p><h2>小结</h2><p>这一讲我们学了3种方法：六边形架构法、User Story三要素，Gherkins feature表达方法和接口契约。在订餐单体测试需求分析中，这些方法是如何应用的呢？我们一起回顾一下。</p><p>我们先用六边形架构法来从概要层面上观察系统的对外交互方式，也就是我们的测试点。然后根据测试点的不同类型提炼需求：对于功能性需求，用Gherkins表达方法来表达成用户故事；而接口性需求，用契约要素来厘清双方的“权利”和“义务”。</p><p>在实践中，这些测试需求不会那么理想，在设计阶段定义清楚了，就会一直不变，我们这里重点关注的是需求表达的格式化和文档化，做到这些，可以入库进行变更管理流程，作为我们下一步自动化测试设计和实现的基础。</p><p>另外，从这个过程中，你能感受到，想要把测试需求整理得清楚、完备，测试人员应该尽早尽多地参与到软件需求分析、软件设计等活动中去。这些能帮助我们更全面地理解“测什么”。</p><p>今天我们研究的还是一个单体应用，下一讲这个单体应用会演变成服务集群，测试需求的复杂度会加大，我们还要使用更多的方法来应对挑战，敬请期待。</p><h2>思考题</h2><p>今天我留两个思考题，你可以选择自己喜欢的题目说说看法。</p><p>1.思考一下你工作的软件系统，它们的测试需求在哪里？是怎么被表达的？怎么存储和变更的？</p><p>2.你遇到过什么奇葩的测试需求，如果换你来提交需求文档，你会如何改进它？</p><p>欢迎你在留言区跟我交流讨论，也推荐你把这一讲分享给身边的同事、朋友，说不定就能帮他解决需求整理的困惑。</p>',
        article_title: "07｜需求提炼（一）：单体应用要测什么？",
      },
      {
        title: "08｜需求提炼（二）：微服务集群要测什么？",
        id: 503214,
        content:
          '<p>你好，我是柳胜。</p><p>随着互联网发展和软件场景普及，单体应用逐渐暴露出致命缺陷，比如过于庞大，大大增加系统的复杂度、交付速度变慢，协作困难、错误难以隔离、维护成本巨大等等。</p><p>同时，软件技术也在发展，出现了VMware、Docker和Kubernetes等轻量化部署方式，这使得拆分的困难变小，部署的成本降低。微服务架构诞生后，一个系统拆分成多个独立开发和运行的服务，这个服务不管大小，业界都管它叫微服务。它们也有一套服务治理的技术规范，用来保证部署和运行的可靠性和扩展性。</p><p>微服务集群的开发方式确实方便了用户需求快速实现和交付，但今天我们的关注点是，从测试角度看，微服务相比单体应用有什么不一样？有没有新的测试点？</p><p>这一讲我们将继续延续FoodCome的例子，看看它从单体应用变成微服务架构之后，给测试工作带来的变化和挑战。</p><h2>微服务架构下的FoodCome</h2><p>在上一讲，单体应用的FoodCome是这样的：<img src="https://static001.geekbang.org/resource/image/bd/a3/bddb6ed5729850bb7340033b437775a3.jpg?wh=1920x1369" alt="图片" title="FoodCome单体架构图"></p><p>随着业务规模的扩大，开发人手增加，FoodCome被拆分成5个微服务，具体如下：</p><ul>\n<li>订单服务：处理用户下的订单；</li>\n<li>物流服务：Foodcome内部的物流管理，与外部物流对接；</li>\n<li>餐馆服务：管理餐馆的信息，参与订单的工作流；</li>\n<li>账户服务：管理订单里的顾客信息，和外部的支付系统对接。</li>\n<li>通知服务：产生消息通知用户，和外部的邮件系统对接。</li>\n</ul><!-- [[[read_end]]] --><p>由此组成的FoodCome的微服务架构如下图：</p><p><img src="https://static001.geekbang.org/resource/image/b1/21/b1e740b327ea837f1278f1a44e754321.jpg?wh=1920x1030" alt="图片" title="FoodCome微服务架构图"></p><p>在这个架构下，原先单体应用的对外接口保持不变，但是单体应用内部被5个独立的微服务取代。用户的订单请求先通过API网关到达订单服务，完成支付后，餐馆接单，再通过物流系统交付订单。</p><p>每个微服务实现自治，独立开发和发布部署，加快发布速度。而且增加新功能也很方便，比如登录鉴权，在这个图中再增加一个认证服务就可以，这是给客户带来的好处。</p><p>现在的问题是，这给测试带来哪些变化呢？分拆后，FoodCome系统变成了微服务集群，就像一部巨大机器，由多个零件组成，互相咬合，一起工作。作为测试人员，不但要验证每个零件是合格的，还要有办法预测它们组装起来的机器也能正常工作。</p><p>这里的测试难点是，微服务的数量增加，服务间的交互量也会剧增，相比单体系统，集成测试在微服务集群架构下更加关键。</p><p>要做集成测试，我们就先搞明白微服务间是怎么交互的。在微服务架构下，交互可以有多种风格，比如RPC远程过程调用、REST风格、Message Queue消息队列等等。根据交互的方法和风格，我把它们整理出一个表格，方便你理解。</p><p><img src="https://static001.geekbang.org/resource/image/6c/02/6cd53f0b8988bc03e77a996106f13302.jpg?wh=3323x1052" alt=""><br>\n在FoodCome采用了两种交互方式，RestAPI和Message Queue。</p><p>RestAPI用来处理实时性强的服务间交互，比如前端通过API网关调用订单服务来下订单。</p><p><img src="https://static001.geekbang.org/resource/image/d2/57/d231ac53f77f707c09f15d872af69d57.jpg?wh=1920x711" alt="图片"></p><p>Message Queue用来处理异步的交互，订单服务和通知服务之间通过Message Queue来交换信息.</p><p><img src="https://static001.geekbang.org/resource/image/2d/98/2d4c9f4fa823ab4cb0b877161a6f8f98.jpg?wh=1920x855" alt="图片"></p><p>下面我们来看一下这两种交互方式的具体实现，然后找出测试点。</p><h2>REST</h2><p>我们需要先知道Rest接口是怎么设计的，才能找出后面都要测什么。</p><h3>什么是REST</h3><p>REST是Representational State Transfer的缩写，叫做表现层状态转换。听起来挺拗口，但我一说你就能懂，它其实是一组松散的规范，不是严格的协议，也不是强制的标准。这个规范的目的就是让API的设计更加简单易懂。</p><p>它包含以下几个基本原则：</p><p>1.REST是基于HTTP协议的；<br>\n2.通过HTTP的URL暴露Resource资源；<br>\n3.通过HTTP的操作原语，提供对Resource的操作，GET、 POST、PUT、DELETE对应着增删改查的操作。</p><p>只要开发人员懂HTTP协议，按照上面的规则用REST风格表达他的API是很容易的。同样，另外一个开发人员看到REST API，也很快就能知道这些API是干什么用的，几乎不用看难懂的文档。</p><p>这是REST的优点，REST风格下设计的AP，学习成本非常低，所以互联网上有很多服务都是通过REST方式对外提供API，比如亚马逊的AWS云服务、Google的Document服务等等。</p><p>当然，现实中的REST，从2000年概念诞生到现在发展了20年，在上面的基本规范上又增加了很多内容，让REST接口具备自解释、可发现等优势，有兴趣你可以看RichardSon提出的 <a href="https://martinfowler.com/articles/richardsonMaturityModel.html">REST四级成熟度模型</a>。</p><h3>Order Service的REST API设计</h3><p>遵循REST规范，Order Service的接口设计可以按照“名词-动词”的思路来捋清。</p><p>首先寻找名词，Order，它对应REST上的一个Resource资源：</p><pre><code class="language-plain">http://api.foodcome.com/api/v1/orders\n</code></pre><p>再找到动词“下单”，它对应HTTP协议上的POST原语，对Orders资源发送POST请求就是下单：</p><pre><code class="language-plain">POST http://api.foodcome.com/api/v1/orders\n</code></pre><p>之后将“查询订单”这个动词，转成HTTP协议上的GET原语，查询条件orderID以参数形式加在URL里：</p><pre><code class="language-plain">GET http://api.foodcome.com/api/v1/orders?orderID=123456\n</code></pre><p>同样，修改订单使用PUT原语，删除订单使用DELETE原语。</p><p>我们再用同样的方法来把其他名词“顾客”和“餐馆”，转成Resource和操作：</p><pre><code class="language-plain">http://api.foodcome.com/api/v1/customers\nhttp://api.foodcome.com/api/v1/restaurants\n</code></pre><h3>Order service的RestAPI规格定义</h3><p>不成熟的开发团队，经常是一边写代码，一边设计API，这样做的结果不难推测，一千个开发人员会写出一千个Order Service API，虽然他们都声称遵循了REST规范。</p><p>所以，好的实践是，开发团队需要先设计RestAPI，并把它表达出来，然后团队就可以进行评审，达成理解一致。</p><p>那表达的载体是什么呢？这里就要提到Interface Definition Language这个概念了，顾名思义，<strong>IDL是接口定义语言，它通过一种独立于编程语言的语法规则来描述API。</strong>不同类型的API，它的IDL是不一样的。</p><p>我们用REST主流的IDL，也就是OpenAPI的语法规范，来描述下订单的这个接口的参数，把请求和响应写在一个YAML文件里。</p><pre><code class="language-yaml">"/api/v1/orders":\n&nbsp; &nbsp; post:\n&nbsp; &nbsp; &nbsp; consumes:\n&nbsp; &nbsp; &nbsp; - application/json\n&nbsp; &nbsp; &nbsp; produces:\n&nbsp; &nbsp; &nbsp; - application/json\n&nbsp; &nbsp; &nbsp; parameters:\n&nbsp; &nbsp; &nbsp; - in: body\n&nbsp; &nbsp; &nbsp; &nbsp; name: body\n&nbsp; &nbsp; &nbsp; &nbsp; description: order placed for Food \n&nbsp; &nbsp; &nbsp; &nbsp; required: true\n&nbsp; &nbsp; &nbsp; &nbsp; properties:\n          foodId:\n            type: integer\n          shipDate:\n            type: Date\n          status:\n            type: String\n            enum:\n            - placed\n            - accepted\n            - delivered\n&nbsp; &nbsp; &nbsp; responses:\n&nbsp; &nbsp; &nbsp; &nbsp; \'200\':\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; description: successful operation\n&nbsp; &nbsp; &nbsp; &nbsp; \'400\':\n          description: invalid order\n</code></pre><p>到这里，FoodCome服务间的REST接口规格说明书就生成了！</p><p>这个规格说明书定义了客户端和服务端之间的契约，顾客要下单的话，客户端应该向服务端"api/v1/orders"发送一个请求，里面包含了食品的代码、日期等等，而服务端成功则返回一个HTTP 200的响应，失败返回一个HTTP 400的响应。</p><h2>异步消息</h2><p>说完了同步常用的REST，我们再分析一下异步消息。</p><p>什么是异步消息呢？消息就是客户端和服务端交换的数据，而异步指的是调用的方式，客户端不用等到服务端处理完消息，就可以返回。等服务端处理完，再通知客户端。</p><p>异步消息在微服务集群的架构里，能够起到削峰、解耦的作用。比如FoodCome在订餐高峰时段，先把订单收下来，放到消息队列，排好队，等待餐馆一个个处理。所以异步消息是现在业界很常用的一种服务交互方式，它的技术原理是消息队列，技术实现是消息代理，有Kafka、RabbitMQ等等。</p><p>而开发人员在设计微服务时，首先要设计异步消息接口，定义好我的微服务什么时候往消息队列里放消息，放什么样的消息。同样，也要定义好取消息的时机和方法。</p><h3>异步消息接口设计</h3><p>好，那我们就来看一下订单服务是怎么设计它的异步消息接口的。</p><p>首先，要定义消息体，订单服务会向外发出三种消息OrderCreated、OrderUpdated、OrderCancelled。消息里包含了order ID、order items、order Status这些字段。</p><p>其次，还要说明这个消息发送到哪个channel里。Channel就是消息的队列，一个消息代理里可以有多个channel，每个channel有不同的功能。</p><p>因为order的消息有严格的时序，比如，OrderCancelled和OrderCreated这两个消息的顺序反了的话，会引起程序处理的混乱。所以，我们把这三种消息都发送到一个叫order的channel里。</p><p>如下图：</p><p><img src="https://static001.geekbang.org/resource/image/f3/d9/f3f7b68948f2f64acc82c53ed833bfd9.jpg?wh=1920x1021" alt="图片"></p><h3>异步消息接口规格说明书</h3><p>好，下面就到关键环节了，对于测试人员来说，我们最关心的就是<strong>接口规格说明书</strong>，跟REST一样，消息队列也需要找到IDL来描述接口上的信息。</p><p>RestAPI的主流IDL是OpenAPI，相对应地，MessageAPI的IDL是 AsyncAPI。上面的Order消息接口，用AsyncAPI规范来定义，会是下面这个样子：</p><pre><code class="language-yaml">asyncapi: 2.2.0\ninfo:\n&nbsp; title: 订单服务\n&nbsp; version: 0.1.0\nchannels:\n&nbsp; order:\n&nbsp; &nbsp; subscribe:\n&nbsp; &nbsp; &nbsp; message:\n&nbsp; &nbsp; &nbsp; &nbsp; description: Order created.\n&nbsp; &nbsp; &nbsp; &nbsp; payload:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: object\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; properties:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; orderID:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: Integer\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; orderStatus:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: string\n</code></pre><p>这段代码描述的是，订单服务在运行时会向Order channel输出OrderCreated消息，这个OrderCreated消息包含了2个字段，order的ID和order的状态。</p><h2>在设计阶段测试要做什么？</h2><p>刚刚我们花了不少篇幅分析API设计，如果你之前一直只做测试，也许会疑惑：“这些看起来是开发领域的知识啊，是不是跑题了？”其实我想说的是，API领域是开发、测试共同关注的。测试应该主动参与到这些领域的活动，才能让测试更加有效。</p><p>我曾经看到过两个微服务团队各自开发都很快，但是微服务一上线，就发现问题了，有的是接口就对不上，有的是数据类型不一致等等千奇百怪的问题，这些问题花了大把诊断时间不说，甚至会给客户带来损失。</p><p>单体应用基本没这些问题，它们是微服务集群的典型问题，那微服务集群的测试，该怎么避免这些问题呢？</p><p>有两个比较好的实践，推荐你尝试一下。</p><p>第一，测试设计先行原则。</p><p>测试设计先行，需要的是开发设计先行。开发不做设计，测试干着急也没法设计。怎么督促开发设计先行呢？一个关键指标是，它在设计阶段是否输出了接口规格说明书。<strong>对于开发工作来说，是需要去代码实现的开发需求。对于测试工作来说，它就是测试需求，需要根据它写测试案例。</strong></p><p>第二，找到合适的IDL来表达接口设计。</p><p>一份周密、高质量的测试需求，会是成功测试的开始。所以这个接口规格说明书不仅要有，还得规范，能指导我们生成测试案例。</p><p>怎么做到呢？让开发人员写一份Word文档？一千个开发人员能写出一千个规格说明。这时，IDL的价值就显现出来了，它提供一套规范和语法，像一门专用语言，能精准描述接口。而且它与编程语言无关，可以根据IDL做Java的实现，也可以是C++, JavaScript，Python等等。</p><p>OpenAPI和AsyncAPI是IDL族群里的2种。我这里列出一个常见的IDL列表，你可以看看你领域里的IDL是什么。</p><p><img src="https://static001.geekbang.org/resource/image/7f/4d/7ffae5be80f21c28d878156fd5e3664d.jpg?wh=1920x623" alt="图片"><br>\n找到了IDL，你和团队就可以一起商量怎么践行设计先行原则，使用IDL设计接口了。有了规格说明书之后，之后我们还会讲到，在测试阶段怎么运用它们设计、开发测试案例，敬请期待。</p><h2>小结</h2><p>这一讲，我们先分析了FoodCome升级成为微服务集群架构后，发生了哪些变化。其中最主要就是服务间的交互量大幅增加。Foodcome采用了2种交互方式，一是RestAPI同步接口，用来接收用户的订单；二是Message Queue的异步接口，用来处理用户的订单。</p><p>这两种API在设计中用到了不同的IDL：OpenAPI和AsyncAPI，产生出来的接口规格说明书是<strong>YAML文件</strong>。这个YAML文件对开发很重要，可以保证他们开发出来的微服务在集成时，能咬合在一起；对于测试来说也很重要，这是后续测试的测试需求。在后面的测试阶段，我们需要去验证，服务是不是遵循了接口。</p><p>当然微服务架构还有一些其他变化，比如服务的治理模式，分布式事务，可靠性的实现等等。我们本专栏关注和自动化相关的测试需求，其他变化可能需要开一个新专栏才能详细讨论。</p><p><img src="https://static001.geekbang.org/resource/image/08/61/0853ba4b25a66d1e21ebd2556a62bd61.jpg?wh=1990x1520" alt=""></p><h2>思考题</h2><p>在你的项目组里，能不能推行设计先行，你预想会遇到什么困难，要怎么应对呢？</p><p>欢迎你在留言区和我交流互动，也推荐你把这一讲分享给更多同事、朋友。</p>',
        article_title: "08｜需求提炼（二）：微服务集群要测什么？",
      },
      {
        title: "09｜3KU法则：为一个订餐系统设计全栈测试方案",
        id: 504644,
        content:
          '<p>你好，我是柳胜。</p><p>上一讲，我们找出了FoodCome订餐系统各截面的测试需求，今天我们就根据这些需求，完成测试设计，给这个订餐系统设计一个全栈的测试方案。我们前面讲到的很多思路和原则，都能在今天的课程里得以应用。</p><p>这个测试方案非常关键，它能回答自动化测试设计中的四大基本问题：做不做自动化？在哪里做、怎么做、怎么运行。这四个基本问题梳理清楚了，自动化测试项目就相当于有了骨架。</p><h2>FoodCome的订餐需求</h2><p>我们先列出前几讲提炼的测试需求，每项需求都过一遍上面的问题清单。让我们头脑中的测试方案，形成一个文档化的列表。</p><p>结合FoodCome订餐系统的例子，我们把测试需求整理如下：</p><p><img src="https://static001.geekbang.org/resource/image/63/6f/63508b5588b2d7ed2bd06ef5d4efd46f.jpg?wh=1920x657" alt="图片" title="测试需求表1.0"></p><p>订餐系统还有很多其他的测试需求，比如兼容性、安全性等等，因为本专栏的关注点是自动化测试，我在这里就不再列出来了。</p><h2>做不做自动化测试？</h2><p>有了文档化的测试需求列表后，我们在设计自动化测试方案时，需要先想清楚，这些需求做不做自动化测试？</p><p><strong>测试四象限法则</strong>能帮我们有效完成这个思考过程。这个测试四象限，是布雷·麦瑞克提出来的方法模型：根据需求的性质和等级2个维度，对测试需求进行分类。</p><p>一个维度是<strong>测试需求的性质</strong>，是技术性还是业务性的？通俗来说就是，如果这个需求越靠近程序员的思维，比如算法、接口、事务等等，它的技术性就越强；而越靠近用户的思维，比如工作流，场景等等，就是业务性越强。</p><!-- [[[read_end]]] --><p>另一个维度是<strong>测试需求的等级</strong>，也就是需求属于关键性的还是精益性的？你可以这样理解，关键性的需求指的是，对于用户显式而重要的需求。比方说，一个系统必须能下单，才能成为订餐系统。而精益性的需求指的是用户隐式的需求，没有直接表达出来，但也可能很重要，比如性能、可靠性等等。</p><p>好，明白了性质和等级这2个维度后，我们现在用这两个维度把测试需求列表过一遍，把它们填到象限里。</p><p><img src="https://static001.geekbang.org/resource/image/33/e0/33a6ee6dc3056306eb7a9ec27d6f04e0.jpg?wh=1920x1430" alt="图片" title="测试四象限"></p><p>先看算法、接口、分布式事务测试，它们技术性强、也是关键需求，放在了第一象限，WebUI测试业务性强且属于关键需求，放在了第二象限，易用性测试放在第三象限，性能和可靠性放在第四象限。</p><p>针对每个象限，测试四象限法建议自动化测试实施策略如下：</p><ul>\n<li>第一象限里的测试需求是100%全部自动化；</li>\n<li>第二象限里的测试需求是自动化+手工；</li>\n<li>第三象限里的测试需求是手工测试；</li>\n<li>第四象限里的测试需求是通过工具和框架来执行，追求0代码。</li>\n</ul><p>四象限的策略你不必死记硬背，因为这些只是表象，底层逻辑还是ROI，学会了分析思路你自己也可以推导结论。</p><p>举例来说，第一象限里的算法和接口测试，因为它们验证的是关键功能，所以回归测试高，自动化测试收益就大。而技术性强，意味着这类测试不会因业务变化受太大影响，所以开发、维护的成本就低。因此，第一象限的测试需求可以100%自动化。至于其他象限的情况，你可以自己试着推演一下，同样符合ROI的规律。</p><p>好，到这里，通过四象限法则，我们已经有了一个自动化测试Yes or No的决定。更新一下表格，加入自动化测试Yes or No一列。</p><p><img src="https://static001.geekbang.org/resource/image/32/71/322a2848b6ed0fef4991f5f1c4694871.jpg?wh=1920x992" alt="图片" title="测试需求表2.0"></p><p>这张表是我们自动化测试方案迈出的第一步。现在，我们就能根据测试需求的性质和类型，判断它的测试方式是自动化测试还是手工测试了。</p><h2>在哪个层面做自动化测试？</h2><p>确定了测试方式，我们还要进一步考虑，这些测试需求的自动化测试是应该在哪个层面实现呢？在单元测试、接口测试还是UI自动化测试？</p><p>在专栏的<a href="https://time.geekbang.org/column/article/497405">第二讲</a>里，我们学习过3KU测试矩阵和3KU测试金字塔，那就可以把它们应用到FoodCome的自动化测试设计了。</p><p>排除掉前面表格里提到的手工测试项，我们把其余内容填入到3KU测试矩阵里。</p><p><img src="https://static001.geekbang.org/resource/image/c7/55/c71a9cf6753e805b3133e4be46285d55.jpg?wh=1860x678" alt="图片" title="3KU测试矩阵"></p><p>按照自动化测试寻求最大ROI实施层面原则，我们把上面的表格，转换成ROI自动化测试金字塔。</p><p><img src="https://static001.geekbang.org/resource/image/9c/10/9ce694440dc1802fe7cd68c96e26b110.jpg?wh=1920x1074" alt="图片" title="ROI自动化测试金字塔"></p><p>在ROI自动化测试金字塔里，我们又确定了两个信息。</p><p>第一，各个需求自动化测试实现的截面，单元测试截面上测试算法和分布式事务，接口测试层面来验证技术契约、服务接口和分布式事务，UI层面做用户下订单自动化测试和部分业务契约的验证。</p><p>第二，各部分自动化测试规模的配比，按照金字塔形状，单元测试案例最多，接口测试居中，UI自动化测试案例最少。</p><p>现在，我们再次更新表格，把在哪一层做自动化，还有工作量分配的比例加进去。</p><p><img src="https://static001.geekbang.org/resource/image/1a/4b/1a057d7fca983dd42707207115e0444b.jpg?wh=1920x837" alt="图片" title="测试需求表3.0"></p><p>好，到这里，这个表格里，我们针对每个测试需求，已经做出了自动化测试方案，包括做不做自动化测试，在什么层面做自动化测试，做多少自动化测试。</p><p>下面，我们继续完善，把这个方案想周全。</p><h2>用什么工具做自动化测试？</h2><p>选择对了工具和框架，会让自动化测试事半功倍。这个“选对”的意思，就是工具必须适合你的项目、你的团队。</p><p>在<a href="https://time.geekbang.org/column/article/498458">第三讲</a>“怎么选型自动化测试工具和框架”中，我已经和你分享了怎么选择工具的方法和原则。在工作量大的单元测试和接口测试，要选择成熟和支持模块化开发的工具，比如JUnit和Restassure；在工作量较小的UI测试，工具的稳定性最重要，其次追求效率。</p><p>在这里，我直接给结果，具体列出了FoodCome各个自动化测试技术和工具，你可以想想为什么选取它们。</p><p><img src="https://static001.geekbang.org/resource/image/00/fa/009d1455457c47ac454409217a92c0fa.jpg?wh=4131x1947" alt="" title="测试需求表4.0"></p><h2>怎么运行自动化测试？</h2><p>在自动化测试方案里，除了做不做自动化测试，以及在哪个层面做。我们还要考虑清楚另外一个事，就是自动化测试开发出来后，它们在什么时候运行。</p><p>在第一模块里，我们讲ROI的时候，经常提到一个自动化测试的收益，其重要因子之一就是它的运行次数。所以，设计ROI高的自动化测试的运行场景是很关键的，而软件部署管线Deployment Pipeline就是重要的自动化测试运行场景之一。</p><p>那Deployment Pipleline是怎么设计的呢？先从概念说起，在2010年，Jez Humble 出版了《持续交付》一书，这里提出了部署管线的概念：</p><blockquote>\n<p>“部署管线是代码从开发人员的个人电脑到生产环境的自动化过程”。</p>\n</blockquote><p>为什么会叫管线呢？因为部署管线由一系列测试的阶段组成，每个阶段首尾相接，这就形成了一条流水线一样的管道。</p><p>部署管线通常是这样的：</p><p><img src="https://static001.geekbang.org/resource/image/f8/ea/f86f5a0da0c071b2a183b96ed36f1aea.jpg?wh=1920x604" alt="图片"></p><p>我们把FoodCome的自动化测试任务，填充到部署管线的各个阶段里去，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/d1/d4/d1yy204a9c8d3d6682e19545a5434dd4.jpg?wh=1920x850" alt="图片"></p><p>沿着部署管线发布的方向，也就是从左向右，自动化测试的运行速度由快变慢，而ROI也是由高到低。<strong>越靠近代码，活动越频繁，ROI就越高</strong>，而每一个关卡都会有失败的，最后能成功到达可部署生产环境的会是很少一部分，十次代码变更能有二次到生产环境。</p><p>所以，后面测试阶段得到运行的次数比较少，相应ROI也比较低。</p><p>这样的规律对我们工作有啥帮助呢？其实不难想到，我们要尽量把自动化测试放在管线的开始端，只要它具备条件，而且够快，这也是我们在<a href="https://time.geekbang.org/column/article/501526">第六讲</a>里提到的自动化测试左移实践。</p><h2>小结</h2><p>今天，我们给FoodCome订餐系统整理了一套全栈自动化测试方案。这个方案里要回答自动化测试项目的四个问题，这些问题也是测试设计最基本的问题。那就是，给定一个测试需求，我们做不做自动化？具体在哪里做、怎么做、怎么运行。</p><p>1.要不要自动化？这里我们用到了测试需求2维度4象限法，帮助我们分析每个需求的性质和等级，遵循最佳实践来确定，它们需不需要自动化。</p><p>2.在哪个层面做自动化？分配多少工作量？这里我们用到了第一模块学到的3KU测试矩阵和3KU测试金字塔，从ROI的角度来回答这些问题。</p><p>3.用什么工具做自动化？每一个层面，我们都要使用工具来帮助我们做自动化。在这里，工具不选择最好的，但要根据团队和项目情况，选择最合适的、ROI产出最大的工具。</p><p>4.自动化测试怎么运行？应该物尽其用，我们投入工作量最大的单元测试和接口测试，它们应该在交付管线Pipeline里运行次数最频繁，这样才能收获好的ROI。</p><p><img src="https://static001.geekbang.org/resource/image/59/37/5993b6d561f18f16ee6eb24f8d691437.jpg?wh=1920x1080" alt="图片"></p><p>回答了这些基本问题后，我们自动化测试方案的骨架也就建立起来了。在实践中，你还可以结合团队的人手、项目的时间等等因素，来填充方案的血肉，比如设定任务的优先级等等。</p><p>接下来的课程里，我们还会进入到每一个测试点，看看怎么实现，敬请期待。</p><h2>思考题</h2><p>结合你的工作实践想一想，要怎么回答自动化测试设计中这四大问题？</p><p>欢迎你在留言区跟我交流，也推荐你把这一讲分享给更多同事、朋友，说不定就能帮Ta搞定下一次的测试方案设计。</p>',
        article_title: "09｜3KU法则：为一个订餐系统设计全栈测试方案",
      },
      {
        title: "10｜单元测试（一）：原来测试可以这么高效",
        id: 505695,
        content:
          '<p>你好，我是柳胜。</p><p>提到单元测试，你可能第一反应是，这个不是归开发做么？作为测试的你，为什么不但要懂UI、接口测试，还要了解单元测试呢？学完今天的内容，你会有自己的答案。</p><p>先从一个常见的业务场景说起，开发同学在实现Order服务的时候，需要代码化一些业务逻辑。比如处理一个订单，要计算总价、优惠扣减、库存查验等等。</p><p>现在Order服务的开发想要测试自己写的这些代码是否预期运转，他最先想到的办法可能是，把Order服务构建完运行起来，向它发送HTTP Request “POST /api/v1/orders”, 然后检查返回的Response内容，看是不是订单已经如期生成。</p><p>这个方法当然也能达到测试目标，但是你已经学习过了3KU原则，就可以问开发人员一个问题 “同样的验证目标，能不能在ROI更高的单元测试阶段实现？”</p><p>你看，测试人员和开发人员的单元测试工作联系起来了，它们之前在实践中一直是不太交流的两个领域，现在需要相互配合，服务于测试的整体目标。</p><p>这一讲会用一个FoodCome系统里的一个Order服务的代码作为例子，帮你捋清楚单元测试能做什么，怎么做。</p><h2>制定单元测试策略</h2><p>我们先来看一下Order服务的内部结构，我画了一张Class关系图来展现内部的逻辑结构。</p><!-- [[[read_end]]] --><p><img src="https://static001.geekbang.org/resource/image/a8/d5/a8b99e099953efc87cf3e34104d413d5.jpg?wh=1920x967" alt="图片"></p><p>我们先看图里的蓝色色块，通过这五个Class就能实现Order服务。</p><p>它们是这样分工的：<strong>OrderController</strong>接收Client发来的"POST /api/v1/orders" request,  交传给OrderService createOrder方法处理，再把生成的订单信息封装成Response返还给Client；</p><p><strong>OrderService</strong>是主要的业务逻辑类，它的createOrder完成了一个订单创建的所有工作，计算价格、优惠扣减，调用<strong>AccountClient</strong>做支付验证，调用<strong>RestaurantClient</strong>做餐馆库存查验。订单生成后，就交给OrderRepository去写DB生成订单记录。</p><p><strong>OrderRepository</strong>实现了和Order自带的数据库交互，读写操作。</p><p>知道了这些，还无法马上动工写单元测试代码，我们还需要考虑清楚后面这几件事。</p><h3>需要写多少个Test Class？</h3><p>这里我需要交代一个背景知识，那就是单元测试里的“单元”是什么？</p><p>如果你问不同的开发人员，可能会得到非常不一样的答案。在过程语言里，比如C、脚本语言，单元应该就是一个函数，单元测试就是调用这个函数，验证它的输出。而面向对象语言，C++或者Java，单元是一个Production Class。</p><p>FoodCome系统是Java面向对象语言开发的，包含5个Production Class，做单元测试，我们把规则设得简单一点，<strong>开发一个Test Class去测试一个Production Class，保持一对一的关系</strong>。</p><p>如下图所示，一个Test Class有多个Test Method。每个Method会Setup建立Production Class的上下文环境，Execute调用Production Class的Method，Assert验证输出，TearDown销毁上下文。</p><p><img src="https://static001.geekbang.org/resource/image/e2/77/e28060bbe8048fdc76ca6612d9915877.jpg?wh=1920x889" alt="图片"></p><h3>孤立型还是社交型？</h3><p>一个Test Class对应一个Production Class看起来简单明了，但理想虽然美好，现实却是复杂的。在实践中，很少有Production Class能独立运行。</p><p>我们拿出OrderSerevice这个Class的源代码看一下：</p><pre><code class="language-java">public class OrderService {\n  //依赖注入OrderRepository, AccountClient, RestaurantClient\n  @Autowired\n  private OrderRepository orderRepository;\n  @Autowired\n  private AccountClient accountClient;\n  @Autowired\n  private RestaurantClient restaurantClient;\n  @Autowired\n  private OrderDomainEventPublisher orderAggregateEventPublisher;\n  public Order createOrder(OrderDetails orderDetails) {\n  //调用restaurantClient验证餐馆是否存在\n  Restaurant restaurant = restaurantRepository.findById(orderDetails.getRestaurantID())\n            .orElseThrow(() \n            -&gt; new RestaurantNotFoundException(orderDetails.getRestaurantID()));\n  //调用AccountClient验证客户支付信息是否有效\n  .............\n  //统计订餐各个条目，根据优惠策略，得出订单价格\n  float finalPrice = determineFinalPrice(orderDetails.getLineItems());\n  //生成订单\n  Order order = new Order(finalPrice,orderDetails);\n  //写入数据库\n  orderRepository.save(order);\n  return order;\n  }\n}\n</code></pre><p>看完代码，我们发现问题了，createOrder运行时，需要调用AccountClient、RestaurantClient和OrderRepository三个Class，如果它们不工作的话，createOrder就没法测试。</p><p>在单元测试里，这3个Class叫做Order Class的Dependency，这3个Class还会有各自的依赖，以此递归。到最后你会发现，想测试Order Class，需要整个服务都要运转起来。</p><p>我打个比方，方便你理解。就像本来你只想请一个朋友来派对，结果朋友还带来了他的朋友，以此类推，你最后发现，现场坐满了你不认识的人，自己的心情完全被毁掉了。</p><p>为了解决这个问题，有两种应对方法。</p><p>第一种孤立型，我只关注我的测试目标Class，而Dependency Class一律用Mock来替代，Mock只是模仿简单的交互。相当于我给派对立下一个规矩：客人不能带客，如果需要，就带个机器人来。</p><p><img src="https://static001.geekbang.org/resource/image/33/14/33d80dc58f0bd430184c686413cda914.jpg?wh=1920x864" alt="图片"></p><p>另一种是社交型，我还是关注我的测试目标Class，但是Depdency Class用真实的、已经实现好的Class。这就好比，我告诉大家，你们先玩，等你们派对结束，我最后再开个只有我自己在的派对。</p><p><img src="https://static001.geekbang.org/resource/image/65/25/6561c6yy651cd072225d32ba42bf0c25.jpg?wh=1920x886" alt="图片"></p><p>社交型和独立型各有优缺点。</p><p><img src="https://static001.geekbang.org/resource/image/db/68/db7e538918edfae3fc78de89de85c768.jpg?wh=1920x639" alt="图片"></p><p>独立型的好处是确实独立，不受依赖影响，而且速度快，但是你要花费成本来开发Mock Class。</p><p>而社交型的好处是没有任何开发成本，但是有一个测试顺序的路径依赖，先测试依赖少的Class，最后才能测试依赖最多的那个Class。</p><p>在实践中，其实没有一定谁好的说法，就看怎么做，更加快捷方便。对于OrderService Class来说，我们两种策略都用。</p><p>我们用社交型处理Dependency OrderRepository，也就是先开发测试OrderRepository Class，再测试OrderService Class，为什么呢？OrderRepository和OrderService在同一个微服务内部，由同一个开发团队甚至同一个人开发，完全不用担心依赖会造成工作阻塞。</p><p>我们用孤立型处理Dependency AccountService和Restaurant Service，自己开发Mock service，因为这涉及到跨服务的依赖。等别的团队AccountService开发完，才能开始测自己的OrderService，这样的情况我们不能接受。</p><p>最后我们得出OrderService Class的测试策略图如下：</p><p><img src="https://static001.geekbang.org/resource/image/0c/44/0c4eaaece99bec7b2815ea7e4e3cfa44.jpg?wh=3370x1519" alt=""></p><p>到这里，我们已经大概捋清楚OrderService的单元测试要做哪些事了，可以分三步走。</p><p>1.开发一个OrderSerivceTest，来测试OrderService；<br>\n2.开发出来OrderRepository，作为OrderServiceTest的真实注入对象；<br>\n3.开发2个Mock Class：AccountClient和RestaurantClient，辅助OrderServiceTest运行。</p><p>“三步走”策略已定好，下面就撸起袖子加油干吧。</p><h2>OrderService的单元测试</h2><p>回到这一讲开头的那个问题 “同样的验证目标，能不能在ROI更高的单元测试阶段实现？”</p><h3>这个TestCase能不能在单元测试阶段做？</h3><p>OrderService是Order服务里业务逻辑最多的Class，因为它包办了创建订单的所有工作。所以测试创建订单可以粗略和测试OrderService划等号，那我们来研究一下OrderServiceTest怎么写。</p><p>我们需要创建一个名为OrderServiceTest的Class，在这个Test Class里，完成对OrderService对象的组装，它依赖的三个Class，通过构造函数的方式注入到OrderService对象里。</p><pre><code class="language-java">public class OrderServiceTest {\n  //声明test需要用到的对象\n  private OrderService orderService;\n  private OrderRepository orderRepository;\n  private AccountClient accountClient;\n  private RestaurantClient restaurantClient;\n  @Before\n  public void setup() {\n    orderRepository = new OrderRespistory();  \n    //mock restaurantClient对象                    \n    restaurantClient = mock(RestaurantClient.class);\n    //mock accountClient对象\n    accountClient = mock(AccountClient.class);\n    //组装被测orderSerivce对象\n    orderService = new OrderService(orderRepository, restaurantClient，accountClient);\n  }\n  @Test\n  public void shouldCreateOrder() {\n    //组装订单内容\n    OrderDetails orderDetails = OderDetails.builder()\n        .customerID(customerID)\n        .restaurantID(restaurantID)\n        .addItem(CHICKEN)\n        .addItem(BEEF)\n        .build();\n    Order order = orderService.createOrder(orderDetails);\n    //验证order是否在数据库里创建成功\n    verify(orderRepository).save(same(order));                             \n  }\n}\n</code></pre><p>上面的测试代码基于Junit规范实现，为了帮你理解测试的主要逻辑，省去了一些关联度不高的代码。</p><p>OrderServiceTest运行时，会创建一个OrderService对象。我们先构造出订单内容OrderDetails，把它作为参数传递到createOrder的方法里。createOrder方法运行结束之后，预期结果是在数据库里生成一条订单记录。</p><p>这个下订单的TestCase如果通过UI来测，你需要打开页面手工、登录、输入订单信息、点击下订单按钮。内容如下：</p><p><img src="https://static001.geekbang.org/resource/image/64/15/649baef02a7ed64ebd97c0534d607b15.jpg?wh=1920x1242" alt="图片"></p><p>下订单TestCase如果通过接口来测，你需要生成订单内容数据，然后发送一个POST请求到“/api/v1/orders”，内容如下：</p><p><img src="https://static001.geekbang.org/resource/image/df/eb/df1564daa38c7bf4b08c92c9bfd9f4eb.jpg?wh=1920x737" alt="图片"></p><p>那我们来对比一下，同一个TestCase，在单元、接口和UI上运行的效果如何？</p><p><img src="https://static001.geekbang.org/resource/image/82/65/8209e0d25a7c06711138dce735ff2265.jpg?wh=1920x758" alt="图片"></p><p>单元测试能覆盖下订单功能的大部分业务逻辑，而且又早又快，是非常理想的自动化测试实施截面。这再次验证了在<a href="https://time.geekbang.org/column/article/497405">第二讲</a>我们学过的3KU测试金字塔：“单元测试是ROI最高的自动化测试，自动化案例应该最多。”</p><h3>提高单元测试ROI</h3><p>既然单元测试又好又快，那么我们不妨把一些费力气的测试工作挪到这一层。哪些测试比较麻烦呢？</p><p>线上购物的场景就很典型，你在网购时一定用过优惠券，这些优惠券的使用条件十分复杂：要知道在什么时间、什么商品会有多大折扣，而且优惠券还存在叠加使用的情况，又有了各种规则，能把人搞晕。但用户可以晕，平台却不能晕，用了优惠券，最终结果还要非常精准地保证盈利，不能亏。</p><p>要是在UI层面测试优惠券，你需要重复运行大量的测试数据，来产生不同的优惠条件，这个代价是高昂的。</p><p>放在单元测试里，这个TestCase就好理解了。负责价格计算的是OrderService里的determineFinalPrice方法，在determineFinalPrice里需要考虑和计算各种优惠条件和规则，再输出一个最终价格。</p><p>因此，优惠券在单元测试里，就转换成了对determineFinalPrice方法的测试。</p><p>怎么测试这个方法呢？ 我们要构建多组OrderDetails数据，传到determineFinalPrice方法里去。这时，我们用JUnit测试框架里的DataProvider来完成这个工作：</p><pre><code class="language-java">@DataProvider\npublic static Object[][] OrderDetails() {\n   return new Object[][]{\n      {1111,2222,"佛跳墙"},\n      {1112,2223, "珍珠翡翠白玉汤"}\n   };\n}\n\n@DataProvider("OrderDetails")\n@Test\n  public void shouldCreateOrder(OrderDetails orderDetails) {\n    Order order = orderService.createOrder(orderDetails);\n    //验证order是否在数据库里创建成功\n    verify(orderRepository).save(same(order));                             \n  }\n</code></pre><p>对照代码可以看到，Test方法上加了一个注解@DataProvider，指定了Test方法的入口参数是来自于一个名为OrderDetails的数据源。OrderDetails是一个二维数组，存储了多条OrderDetails数据，有多少条数据，就会运行多少次Test方法。</p><p>这样，我们就不需要在UI上重复提交表单来做测试了，这个工作交给单元测试来做，在几毫秒内就完成上千条测试数据的测试了。Oh Yeah，原来单元测试可以这么Cool！</p><p>等从激动中缓过神来，你可能还发现了一个问题，不对？上面的Test方法好像没有验证输出的价格呀？</p><p>没错，这里有一个困难，determineFinalPrice方法实际上是实现了一个价格计算的算法，它会根据输入计算输出一个数值，算法怎么测？怎么验证它的输出是对的，还是错的？</p><p>这个领域业界的做法很不一样，有的会在测试代码里把算法又实现了一遍，然后得出一个数值作为预期值，跟开发代码算出来的数值做比对。</p><p>这种做法其实是错误的，<strong>因为测试代码里加入了被测单元的实现细节（算法逻辑）</strong>，你本来想验证产品线生产的产品A是不是合格，但你采用办法是让产品线再生产一个产品B，来比对A和B，这样验证没有意义，因为如果产品线本身就是有问题的，A和B都会是错的。</p><p>业界给这样的测试起了一个名，叫“领域知识泄漏”，你可以搜索一下“Domain Knowledge Leakage”，会发现各种各样的测试方法错误。</p><p>正确的做法是，你应该只关注产品A的合格标准，用标准来检查A就可以了。</p><p>在我们的情景里，很简单，把determineFinalPrice的输入参数和输出参数都写出来，作为常量。只要输入一个x1,x2,x3, 那就会得到y，然后就用x1,x2,x3,y这一组数据来测试determineFinalPrice方法就可以。</p><p>现在你可以思考一下，上面的代码应该怎么变动？相信你可以解决这个问题，也欢迎你在留言区晒一下你的“作业”。</p><h2><strong>小结</strong></h2><p>当今，业界一般都会把单元测试划到开发领域，接口测试和UI测试划到测试领域，这让两个领域很少交流。对于测试整体来说，这就存在着重叠和资源浪费。</p><p>做自动化测试的你，其实应该了解单元测试能做什么，都做了什么，甚至你应该设计好测试案例，让开发人员去实现。因为你是自动化测试的Owner和架构师，你应该对整体效益负责。</p><p>单元测试里很多内容：框架的接口、Mock的开发、Assert语句的使用等等，一本书都讲不完。今天我们通过FoodCome的代码里的一个OrderServiceTest的实现，学习了单元测试策略，以一个测试整体的视角来观察单元测试能做什么，在整个测试方案里的功能作用。</p><p>通过这一讲，你可以直观感受到，单元测试的ROI又高，速度又快。但在现实中，这是测试人员的一块短板，也是相对陌生的领域。所以，我<a href="https://time.geekbang.org/column/article/506638">下一讲</a>还会继续单元测试的话题，谈谈怎样推动单元测试的“可测试性”，敬请期待。</p><h2>思考题</h2><p>去了解一下你开发团队里有没有做单元测试，有的话都做了什么。</p><p>欢迎你在留言区和我交流互动，也推荐你把这一讲分享给更多同事、朋友，说不定就能通过单元测试来解放双手，提高工作效率啦。</p>',
        article_title: "10｜单元测试（一）：原来测试可以这么高效",
      },
      {
        title: "11｜单元测试（二）：四象限法让你的单测火力全开",
        id: 506638,
        content:
          '<p>你好，我是柳胜。</p><p>上一讲，我们写了OrderServiceTest测试类，来测试FoodCome的OrderService类。这样不管开发代码还是测试代码，都是简单清楚的。这是因为FoodCome的开发人员对代码有一个好的设计，实现了Controller、Service、Repository等Class的职能划分，OrderService类里专注订单管理，我们写出的OrderServiceTest才能集中火力测试。</p><p>但是好的设计不是天上掉下来的，有的团队在刚一开始写的代码结构性并不好，这有可能是项目的问题，需求不明确、赶进度，也有可能是开发人员的技术功底不扎实、抽象能力不够。所以，在软件生命周期内，需要持续重构，才能打磨出好的设计。</p><p>今天我们就用一个例子，来看看好的代码设计是怎么打磨出来的，而且，我们要从测试的角度来评估设计的效果，那就是单元测试容易写、覆盖率高、干净易懂，这又叫代码可测试性。</p><p>作为自动化测试架构师，你需要掌握观察和评估代码可测试性的能力，有能力推动你的开发团队做好代码设计，走向单元测试。</p><h2>从一个需求说起</h2><p>有一天，老板给FoodCome订餐系统提了一个需求，希望用户在页面上可以修改自己的邮箱地址。</p><!-- [[[read_end]]] --><p><img src="https://static001.geekbang.org/resource/image/7a/45/7aa7d008a286da48897364228a21cc45.jpg?wh=1920x1284" alt="图片"></p><p>这个修改行为后端实现起来似乎很简单，修改邮箱就是更新数据库里的用户信息。但在FoodCome平台上有一个业务逻辑，邮箱地址域名如果是@foodcome.com，这说明是平台上注册的餐馆商家，否则，就是普通顾客。</p><p>这样，我们就需要在用户修改邮箱的时候，加入一个判断，如果邮箱地址的修改是从普通域到@FoodCome域，商家在平台里的数量就+1，否则，就-1。</p><p>这个需求看起来很简单，是吧。但是我要告诉你，即使这么简单的逻辑，也需要做好设计，否则，写出来的代码可能完全无法单元测试，不信就来看看吧。</p><h2>版本V1</h2><p>既然老板提了需求，自然要赶紧完成。开发人员小胜同学立刻在下班前完成了一个版本，新建了一个User类，在User类里有一个changeEmail的方法，负责修改邮箱地址。这是第一版代码<strong>User.java</strong>下的内容：</p><pre><code class="language-java">public class User\n{\n    public int UserId { get; private set; }\n    public string Email { get; private set; }\n    public UserType Type { get; private set; }\n\n    public void ChangeEmail(int userId, string newEmail)\n    {\n        //查询出来用户的ID，email和type\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;object[]&nbsp;data&nbsp;=&nbsp;Database.GetUserById(userId);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n        UserId = userId;\n        Email = (string)data[1];\n        Type = (UserType)data[2];\n        //如果和修改前的email相同，直接返回\n        if (Email == newEmail)\n            return;\n        //从数据库里获得商家的数量\n        int numberOfRestaurtants = Database.GetRestaurant();\n        //判断用户要修改的类型是商家还是顾客\n        string emailDomain = newEmail.Split(\'@\')[1];\n        bool isEmailRestaurant = emailDomain == "foodcome.com";\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UserType&nbsp;newType&nbsp;=&nbsp;isEmailRestaurant&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;?&nbsp;UserType.Restaurant&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;UserType.Customer;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n        //如果是修改成为商家，那么商家数量+1，如果是修改为顾客，商家数量-1  \n        if (Type != newType)\n        {\n            int delta = newType == UserType.Restaurant ? 1 : -1;\n            int newNumber = numberOfRestaurtants + delta;\n            Database.SaveRestaurant(newNumber);   \n            MessageBus.SendEmailChangedMessage(UserId, newEmail);                     \n        }\n        //提交用户信息修改，入库\n        Database.SaveUser(this);                                  \n           \n    }\n}\npublic enum UserType\n{\n    Restaurant = 1,\n    Employee = 2\n}\n</code></pre><p>上面的代码并不复杂，主要功能是判断邮件地址是否为FoodCome，然后更新数据库，发送通知到消息总线上。</p><p>那它的可测试性怎么样呢？</p><p>我们引入一个代码复杂度四象限法则来完成这个评估，它的原理是，用以下2个维度来评估代码：</p><p>1.领域复杂度，代码的领域复杂度越高，里面的业务逻辑就越多。<br>\n2.对外依赖度，依赖度越高，说明代码和外部的Class交互点多。</p><p>每个维度都有高低，2个维度的高低组合在一起就成了四个象限。</p><p>1.业务复杂、依赖又少，是业务逻辑集中的代码。比如业务算法。<br>\n2.业务简单、依赖又少，是一些简单代码，比如构造函数，数据对象等。<br>\n3.业务复杂、依赖多，是复杂度高的代码，测试起来也会比较困难。<br>\n4.业务简单、依赖多，是管理依赖的代码。比如消息总线。</p><p><img src="https://static001.geekbang.org/resource/image/b8/00/b828cec1b566e1df1ff6640fe5f32900.jpg?wh=1920x1547" alt="图片"></p><p>我们要把开发的代码放到四个象限里，每个象限对应不同的测试策略。那小胜同学的User Class，应该放到哪个象限呢？</p><p>User Class里包含了changeEmail的业务逻辑，就是根据Email的地址决定如何变更Restaurant的数量。同时，User Class里还有2个外部依赖：Database和MessageBus，这个依赖还是隐式的，没有声明在成员变量里，你得看代码才能找到2个外部依赖是怎么使用的。</p><p>显然，User class属于领域和依赖混合的代码，应该归属于<strong>复杂代码</strong>象限。</p><p>那么在这种情况下，怎么测试User Class呢？</p><p>为了调用changeEmail方法，你可能会想到Mock Database和MessageBus两个对象，但难点是，根本没有办法把Mock对象传递changeEmail方法里去。</p><p>所以，现在我们是没有办法单元测试User Class的，它的可测试性为0。</p><p>因此，小胜同学需要重构代码，把<strong>复杂代码</strong>象限的代码分解到<strong>领域代码</strong>象限和<strong>依赖代码</strong>象限。</p><p><img src="https://static001.geekbang.org/resource/image/02/16/0257c4ff30f7be0e4fb0e3f14aa82e16.jpg?wh=1920x1571" alt="图片"></p><h2>版本V2</h2><p>下面来到第二个版本，小胜将业务逻辑和与外部依赖的交互分离，创建了一个新的UserController Class来专注管理外部依赖。</p><p><strong>UserController.java</strong>的代码如下：</p><pre><code class="language-java">public class UserController\n{\n    //在controller里声明两个外部依赖\n    private readonly Database _database = new Database();\n    private readonly MessageBus _messageBus = new MessageBus();\n    //changeEmail方法里调用依赖\n    public void ChangeEmail(int userId, string newEmail)\n    {\n        object[] data = _database.GetUserById(userId);\n        string email = (string)data[1];\n        UserType type = (UserType)data[2];\n        var user = new User(userId, email, type);\n\n        int numberOfRestaurants = _database.GetRestauruant();\n        string companyDomainName = "foodcome.com";\n        //调用User的changeEmail，返回变化的商家数量。\n        int newNumberOfRestaurants = user.ChangeEmail(\n            newEmail, companyDomainName, numberOfRestaurants);\n        //调用依赖，变更数据库和发布消息\n        if(newNumberOfRestaurants!=numberOfRestaurants){\n          _database.SaveCompany(newNumberOfRestaurants);\n          _database.SaveUser(user);\n          _messageBus.SendEmailChangedMessage(userId, newEmail);\n        }\n    }\n}\n</code></pre><p>同时我们要修改User Class，它不负责任何依赖，只关注changeEmail的业务逻辑，根据输入参数，算出来新的商家的数量。</p><p><strong>User.java</strong>的代码如下：</p><pre><code class="language-java">public class User\n{\n    public int ChangeEmail(string newEmail,\n    string companyDomainName, int numberOfRestaurants)\n   {\n    if (Email == newEmail)\n        return numberOfRestaurants;\n\n    string emailDomain = newEmail.Split(\'@\')[1];\n    bool isEmailCorporate = emailDomain == companyDomainName;\n    UserType newType = isEmailCorporate\n        ? UserType.Restaurant\n        : UserType.Customer;\n    if (Type != newType)\n    {\n        int delta = newType == UserType.Employee ? 1 : -1;\n        int newNumber = numberOfRestaurants + delta;\n        numberOfRestaurants = newNumber;\n    }\n    return numberOfRestaurants;\n&nbsp;&nbsp;}\n}\n</code></pre><p>我们发现，相比版本1 ，版本2有了进步，多了UserController Class来专门负责管理外部交互，隐式依赖的Database和MessageBus变成了显式成员变量。User class专门负责业务逻辑，判断为餐馆还是客户。</p><p>我们再用复杂度四象限来观察现在的代码，它的分布情况变为下图这样。</p><p>可以看到，复杂代码消失了，原先一个User.java文件里的逻辑被分散到了两个文件里，一个是UserController.java，它专注于管理依赖，位于依赖代码象限；还有修改后的User.java，专注于业务逻辑实现，位于领域代码象限。</p><p><img src="https://static001.geekbang.org/resource/image/18/86/181afae377e2d60f74916703810a8386.jpg?wh=1920x1526" alt="图片"></p><p>现在可以测试了！</p><p>User Class只有一个changeEmail的方法，方法里只是对邮件地址做判断，并计算新的餐馆数量，将新值返回，不会涉及到操作数据库和消息总线。User Class可以测试了，因为不需要做任何Mock，我叫它<strong>简单测试</strong>。</p><p>而2个外部依赖Database和MessageBus都被显式地封装在UserController Class里，我们可以通过构造函数来传递Mock对象，UserController也是可以测试的，我叫它<strong>Mock测试</strong>。</p><p>但是，版本2依旧不够清爽，还存在两个问题。</p><ol>\n<li>\n<p>UserController里实例化了User class，这包含了业务逻辑（如何构造一个User对象），而我们希望UserController更为纯粹，专注依赖管理；</p>\n</li>\n<li>\n<p>User class和Restaurant数据也存在耦合，通过User&nbsp;Class的ChangeEmail函数返回了Restaurant的newNumofRestaurant，这和User的行为模型毫无关系。</p>\n</li>\n</ol><p>好，撸起袖子加油干，我们来完成第三个版本，一次性解决上面提到的问题。</p><h2>版本V3</h2><p>首先，使用UserFactory模式封装User实例化逻辑，如下：</p><pre><code class="language-java">public class UserFactory\n{\n    public static User Create(object[] data)\n    {\n        Precondition.Requires(data.Length &gt;= 3);\n        int id = (int)data[0];\n        string email = (string)data[1];\n        UserType type = (UserType)data[2];\n\n        return new User(id, email, type);\n    }\n}\n</code></pre><p>可以看到UserFactory也是可以简单测试的✌️！这是阶段性胜利，可喜可贺。</p><p>然后，我们常见一个Restaurant Class用来封装关于Restaurant的业务逻辑，如下：</p><pre><code class="language-java">public class Restaurant\n{\n    public string DomainName { get; private set; }\n    public int NumberOfRestaurant { get; private set; }\n\n    public void ChangeNumberOfRestaurants(int delta)\n    {\n        Precondition.Requires(NumberOfRestaurants + delta &gt;= 0);\n        NumberOfRestaurants += delta;\n    }\n    public bool IsEmailCorporate(string email)\n    {\n        string emailDomain = email.Split(\'@\')[1];\n        return emailDomain == DomainName;\n    }\n}\n</code></pre><p>Restaurant Class也是可以简单测试的！</p><p>参考UserFactory的思路，再做一个RestaurantFactory，专门做Restaurant对象的构建，此处省略代码，实现起来其实并不复杂，有兴趣你可以自己写写看。</p><p>而UserController更关注与外部依赖的管理和交互，如下：</p><pre><code class="language-java">public class UserController\n{\n    private readonly Database _database = new Database();\n    private readonly MessageBus _messageBus = new MessageBus();\n\n    public void ChangeEmail(int userId, string newEmail)\n    {\n        object[] userData = _database.GetUserById(userId);\n        User user = UserFactory.Create(userData);\n\n        object[] restaurantData = _database.GetRestaurant();\n        Restaurant restaurant = RestaurantFactory.Create(restaurantData);\n        user.ChangeEmail(newEmail, restaurant);\n        \n        _database.SaveUser(user);\n        //如果restaurant数量有变化，就写数据库，发送通知信息\n        if(restaurant.numberChanged()){\n          _database.SaveRestaurant(restaurant);\n          _messageBus.SendEmailChangedMessage(userId, newEmail);\n         }\n    }\n}\n</code></pre><p>UserController Class里没有业务逻辑，只有Database和MessageBus的管理和操作。在单元测试时，只需要用Mock替代，就OK了！UserController是可以轻松Mock测试的！</p><p>经过前面的操作，User Class变化如下：</p><pre><code class="language-java">public class User\n{\n    public int UserId { get; private set; }\n    public string Email { get; private set; }\n    public UserType Type { get; private set; }\n\n    public void ChangeEmail(string newEmail, Restaurant restaurant)\n    {\n        if (Email == newEmail)\n            return;\n\n        UserType newType = company.IsEmailCorporate(newEmail)\n            ? UserType.Employee\n            : UserType.Customer;\n\n        if (Type != newType)\n        {\n            int delta = newType == UserType.Employee ? 1 : -1;\n            restaurant.ChangeNumberOfRestaurants(delta);\n        }\n    }\n}\n</code></pre><p>Oh Yeah, User Class是可以简单测试的！</p><p>现在我们再来看一下V3版本代码在复杂度四象限的位置，变成了这样：</p><p><img src="https://static001.geekbang.org/resource/image/8e/9b/8e678e078dd95b5ae0e2aa95f2ede29b.jpg?wh=1920x1521" alt="图片"></p><p>经过3个版本后，我们把代码重构完，复杂代码完全被消解掉了，分解到了其他3个象限。</p><p>现在，我们就可以为不同象限的代码，制定好单元测试策略和优先级了。我特意准备了一张总结表放在了后面。</p><p><img src="https://static001.geekbang.org/resource/image/8e/4e/8e17702d4ab6f9af4555cbc88837634e.jpg?wh=1920x889" alt="图片"></p><p>有了这张表，你就可以使用<a href="https://time.geekbang.org/column/article/505695">上一讲</a>提到的测试方法来做业务逻辑测试和Mock测试了！</p><h2>小结</h2><p>向着提高代码可测试性的目标，复杂代码经过一步步的重构，被分解到了依赖管理和业务逻辑两个领域，如果也算上数据库代码的话，正好和软件架构的MVC模式一致。这不是凑巧，这恰恰说明好的代码结构等同于单元测试高覆盖率。如果你的项目，单元测试做不下去，测试覆盖率提不上来，那应该重构代码了。</p><p>反之也一样，如果开发人员声称做了非常好的设计，那么我们通过单元测试，就应该能直观感受到这个好的设计。期待今天这讲内容成为你开启开发领域大门的一把钥匙。</p><p><img src="https://static001.geekbang.org/resource/image/35/6b/35ddf28fc9c17585e7ef43c40f574f6b.jpg?wh=1920x999" alt="图片"></p><p>另外，结合今天的三个版本的代码例子，你也应该发现了，单元测试并不是眉毛胡子一把抓。</p><p>首先，你应该关注业务逻辑能否在单元测试里充分测试，这是跟我们自动化测试高度关联的地方。而Mock的目标，则是辅助业务逻辑能够更早更快地测试。以后，当开发人员骄傲地跟你说：“代码行覆盖率达到80%”的时候，你应该和他一起检查下，他到底测了什么。</p><p>单元测试看起来已经是个完美的测试方案了，那在单元测试层面还有什么做不到的事么，下一讲我们就来揭晓答案。</p><h2>思考题</h2><p>制定单元测试覆盖率100%的目标有价值么？如果让你制定目标，你会怎么做？</p><p>欢迎你在留言区跟我交流互动，也推荐你把这讲内容分享给更多同事、朋友。</p>',
        article_title: "11｜单元测试（二）：四象限法让你的单测火力全开",
      },
      {
        title: "12｜集成测试（一）：一条Happy Path扫天下",
        id: 507443,
        content:
          '<p>你好，我是柳胜。</p><p>上一讲，我们学习了单元测试，在验证业务逻辑方面，它的优势在于速度又快，阶段又早。既然单元测试看起来是一个完美的自动化测试方案，那为什么还需要集成测试呢？</p><p>我在<a href="https://time.geekbang.org/column/article/497405">第二讲</a>的3KU原则说过，测试需求首先要找ROI最高的截面来验证。在金字塔模型里，ROI最高的就是单元测试，如果无法实现，才回退到ROI第二高的截面，一直到ROI最低的端到端测试。</p><p>那集成测试存在的价值，一定是做得了单元测试层面做不到的事，否则，集成测试这个概念就没必要存在。那这些事具体有哪些呢？你要是能找到这些事，就找到了集成测试省力又见效的窍门。今天咱们就一起寻找这个答案。</p><h2>集成测试和单元测试</h2><p>上一讲我们学过了代码四象限法则，产品的代码按照业务相关性和依赖程度，可以划分到下面四个象限里。</p><p><img src="https://static001.geekbang.org/resource/image/53/cb/538461c119ff8ac736750f27ea60a7cb.jpg?wh=1920x1501" alt="图片"></p><p>那集成测试和单元测试分别应该归到第几象限呢？</p><p>集成测试，顾名思义，是验证本服务代码和其他进程的服务能不能一起配合工作。在上面的四象限里，集成测试的活动领域就在“依赖代码”象限，而单元测试的活动领域是在“领域代码”象限。</p><p>我再用图解的方式划分一下地盘，你会看得更清楚。</p><p><img src="https://static001.geekbang.org/resource/image/3f/45/3f6fc585e1af8bc0a110c83776781045.jpg?wh=1920x1203" alt="图片"></p><p>这张图里的信息量很大，展示了单元测试和集成测试的各自战场，我来跟你细说一下。</p><p>单元测试掌管领域代码的测试，这些领域代码只是负责数据计算，并不会触及外部依赖。像上一讲的changeEmail方法，只是计算出一个新的餐馆数目，单元测试只需要验证这个计算逻辑是否正确就好了。</p><!-- [[[read_end]]] --><p>那什么是单元测试测不了的呢？ 那就是依赖代码。在FoodCome的代码设计里，这些外部的依赖管理交给一个独立的Controller Class去做，它负责读写数据库、发送消息等等。这块就是集成测试的领域。</p><p>看到这里，你脑袋里可能会冒出这样一个问题：不对呀！单元测试也可以测试外部依赖，我们在前面讲过可以Mock外部依赖，如果我把Database、MessageBus都Mock了，那不就也可以做单元测试了么？</p><p>你能想到这一层，说明你已经关注概念背后真正的事情了。是的，如果所有的外部服务都Mock了，集成测试就变成了单元测试，往另外一个方向，如果所有的外部服务都是真实的，集成测试又变成了端到端的测试。<strong>集成测试就是处在单元测试和端到端测试中间的一个状态。</strong></p><p><img src="https://static001.geekbang.org/resource/image/e0/cf/e06c78d1995fbba0af903da9001302cf.jpg?wh=1920x733" alt="图片"></p><p>在这里，我们要关注<strong>Mock和Real的优劣势，集成测试怎么能做得更聪明一些，用最少的工作量，获得最大的测试效果</strong>。下面我们就展开来说一说。</p><h2>集成测试测什么？</h2><p>相比单元测试，集成测试有2个特点。</p><p>第一，集成测试运行速度慢，这个时间主要花在2个地方，第一个是准备集成测试环境的时间，你要先把依赖的外部服务启动起来，让环境处在一个健康状态；第二个是运行集成测试的时间，因为集成测试不像单元测试是进程内工作，它是跨进程通讯，除了计算时间，还要加上网络通讯时间等等。</p><p>第二，执行集成测试，要运行的代码量比单元测试要多。因为它走过的路径更长，从网络请求，到处理请求，再到网络返回结果，中间需要经历过n个代码单元，还有框架代码，库代码等等。</p><p>这两个特征告诉我们，集成测试是有比较大的成本的，并且它测试的代码逻辑和单元测试是有重叠的。</p><p>本着追求整体最大ROI效益的目标，集成测试和单元测试需要协同作战，保持一个平衡，这个平衡的原则是：</p><p>1.在单元测试阶段验证尽可能多的业务逻辑，这样能让集成测试关注在外部依赖上。</p><p>2.集成测试至少覆盖一条长路径案例，叫“Happy Path”。</p><h3>怎么挑选Happy Path</h3><p>Happy Path是指一条正常业务的测试案例，走尽可能多的外部依赖服务。比如，一条案例，同时走了Database和MessageBus。</p><p>针对<a href="https://time.geekbang.org/column/article/506638">上一讲</a>提到的用户修改邮箱功能，我们有几个案例：</p><p>1.修改邮箱名从 a@foodcome.com到b@foodcome.com<br>\n2.修改邮箱名从 a@example.com到a@foodcome.com<br>\n3.修改邮箱名从 a@example.com到b@example.com</p><p>哪个案例是Happy Path呢？再回头看一下代码：</p><pre><code class="language-java">public class UserController\n{\n   .............\n    public void ChangeEmail(int userId, string newEmail)\n    {\n        .....................\n        user.ChangeEmail(newEmail, restaurant);\n        _database.SaveUser(user);\n        //如果restaurant数量有变化，就写数据库，发送通知信息\n        if(restaurant.numberChanged()){\n          _database.SaveRestaurant(restaurant);\n          _messageBus.SendEmailChangedMessage(userId, newEmail);\n         }\n    }\n}\n</code></pre><p>我们不难发现案例2符合Happy Path，因为它触发了多次与2个外部依赖的交互，更新了Databse的用户信息和餐馆信息，还触发了消息总线发送一条通知出去。</p><p>你可能还想到一个疑问，如果我们找不到一个能触发全部外部依赖交互点的Happy Path，那怎么办？很简单，那就再加一条Happy Path。</p><h2>集成测试用Mock还是Real测试？</h2><p>集成测试领域一个有争议的话题，就是外部依赖是用Mock还是用真实的实例。在前面我们讲单元测试是“孤立型”还是“社交型”的时候，提到了Mock和Real两种方法都有优劣，都有适用的场景（可以回看<a href="https://time.geekbang.org/column/article/505695">第十讲</a>）。</p><p>今天我们详细说说，选择Mock还是Real的方法。</p><p>首先要看外部依赖的特征，我把它划分成2种类型。</p><p>1.完全可控依赖<br>\n2.不可控依赖</p><p>什么是完全可控依赖呢？ 这个外部的服务被你的应用独享，你也能够控制它的开发和运维，那这个服务就是完全可控依赖的。一个典型的例子，就是数据库，在微服务模式下，每一个服务独享一个自己的数据库Schema。</p><p>那什么又是不可控依赖？与可控依赖相反，这个外部的服务不止你的应用调用，大家都得遵守一个协议或规范，和这个公共的外部服务交互。典型的例子，就是外部的支付系统，SMTP邮件通知服务等等。</p><p>与这两种类型相对应的Mock策略如下：</p><p><img src="https://static001.geekbang.org/resource/image/17/07/1766011df1c922a898004190c0681a07.jpg?wh=1920x654" alt="图片"></p><p>为什么是这样的？ 完全可控依赖的服务，虽然是在你的应用之外的一个进程，但你可以把跟它的交互当作是你开发的内部实现。你可以升级数据库版本、修改表格结构、增加数据库函数，只要跟着应用的代码一起修改即可。</p><p>这种情况下，你可以把这个数据库和你的应用当作一个整体，没必要花力气做Mock，如果你脑子一抽做了Mock，就还要维护Mock的变化，恭喜进坑。</p><p>而不可控依赖服务就不一样了，它是公共的，你控制不了它，而且你跟它的交互还要遵守一个规范的契约。在这种情况下，做Mock就划算了，原因有二：<strong>第一，基于契约的Mock的维护成本比较低；第二，使用Mock可以保证你的应用持续重构，向后兼容</strong>。</p><p>分析到这，我们就能梳理出FoodCome的Mock策略了。</p><p><img src="https://static001.geekbang.org/resource/image/26/98/26170c5b24f458f2ee3706f1a15a5f98.jpg?wh=1920x908" alt="图片"></p><h2>集成测试的实现</h2><p>找出了Happy Path，也定了Mock策略后，就可以动手写代码了。</p><p>根据2号案例，我们来创建一个测试方法，方法名为change_email_from_example_to_foodcome：</p><pre><code class="language-c#">[Fact]\npublic void Changing_email_from_example_to_foodcome()\n{\n    // Arrange\n    var db = new Database(ConnectionString);                          \n    User user = CreateUser(                                           \n        "a@example.com", UserType.customer, db);                                              \n    var messageBusMock = new Mock&lt;IMessageBus&gt;();                     \n    var sut = new UserController(db, messageBusMock.Object);\n    // 调用changeEmail方法\n    string result = sut.ChangeEmail(user.UserId, "b@foodcome.com");\n    // 校验返回\n    Assert.Equal("OK", result);\n    // 校验数据库里字段\n    object[] userData = db.GetUserById(user.UserId);                 \n    User userFromDb = UserFactory.Create(userData);                  \n    Assert.Equal("b@foodcome.com", userFromDb.Email);                 \n    Assert.Equal(UserType.Restaurant, userFromDb.Type);                \n        messageBusMock.Verify(                                           \n        x =&gt; x.SendEmailChangedMessage(                              \n            user.UserId, "b@foodcome.com"),                           \n        Times.Once);                                                 \n}\n</code></pre><p>上面的代码完成了以下步骤，我特意分点列出来，方便你看清楚每一步。</p><p>1.创建真实的数据库连接对象；<br>\n2.创建MessageBus的Mock对象；<br>\n3.把2个依赖注入到被测UserController class里，调用changeEmail方法；<br>\n4.检验数据库里的User状态；<br>\n5.检验Mock的MessageBus里的消息。</p><h2>小结</h2><p>今天我们学习了和外部服务的集成测试的方法，在动手之前，我们要想明白测什么，用什么测，Mock还是Real。</p><p>测什么，怎么测，这就是集成测试方案要回答的问题，而且，这个方案的制定遵循3KU原则，也就是尽量不做重复的事，把精力和时间花在有价值的地方。</p><p>单元测试需要做好业务逻辑的验证，集成测试主要是测试与外部依赖的集成，集成又有2种策略，采用Mock还是Real真实的依赖，应该遵循<strong>能Real就Real的原则，不能Real的再采用Mock</strong>，如果一股脑Mock所有依赖，你会发现集成测试没测到什么有用的逻辑，都在Mock上，而真正集成时还是会遇到问题。</p><p>在集成测试案例的设计上，我提出了<strong>Happy Path</strong>，让你能用最少的工作量做最有效果的事情，这对于集成测试刚起步的项目来说，十分关键。在Mock策略上，也是遵循同样的原则，尽量把开发和维护Mock的工作量花在最有价值的外部依赖上。</p><h2>思考题</h2><p>在实际工作中，你有多个测试案例，怎么找出那条Happy Path？除了看代码，还有别的方法么？</p><p>欢迎你在留言区跟我交流互动，也推荐你把这讲内容分享给更多同事、朋友。</p>',
        article_title: "12｜集成测试（一）：一条Happy Path扫天下",
      },
      {
        title: "13｜集成测试（二）：携手开发，集测省力又省心",
        id: 508574,
        content:
          '<p>你好，我是柳胜。</p><p>专栏里我一直强调这样一个观点，<strong>以全局ROI最高为导向，把各个测试类型综合考虑，而非割裂、独立地分析某一层的测试</strong>。不谋全局者，不足谋一域，测试领域如此，开发和测试领域协同也一样。比如前面咱们学过的单元测试，把单元测试做好，实际就能推动开发代码的结构优化。</p><p>集成测试也是一样，做好集成测试也需要开发的支持。在上一讲里，我提到了集成测试轻量化的想法：Mock服务和Happy Path。你学完了后，可能已经跃跃欲试，盘算着自己的项目该怎么做Mock，去哪里寻找那条Happy Path了。</p><p>但理论推演畅通无阻，现实挑战却障碍重重。很可能现实里你面临两难：做Mock成本高，需要修改很多开发代码，调用链条又长又复杂，根本理不出那条Happy Path。面临这样的困难，要么只能放弃ROI不高的集成测试，要么硬着头皮去设计和执行一些测试案例，而且这些案例你也不确定是否有效。</p><p>有没有第三种方法呢？有，这第三种方法不仅能让集成测试保持轻量和高效，而且还能让测试进入一个Bug越来越少的正反馈循环。但需要你主动介入代码世界，和开发人员一起推动集成测试的可测试性。后面的知识点不少，但只要你跟住我的思路，愿意跟着我思考，一定不虚此行。</p><!-- [[[read_end]]] --><h2>接口与Mock</h2><p>先从开发Mock说起，这是集成测试里一项必不可少的工作内容。怎么能又快又简单地开发Mock呢？带着这个问题，我们来看一下Mock的原理。</p><p>在面向对象语言里，Interface接口是个常被提及的概念。一个Interface接口定义了契约，而实现细节由继承类去完成。在代码里你经常会看到Interface-Class成对出现的情况：</p><pre><code class="language-c#">public interface IMessageBus\npublic class MessageBus : IMessageBus\n\npublic interface IUserRepository\npublic class UserRepository : IUserRepository\n</code></pre><p>从设计的角度这叫做解耦，目的是<strong>分离定义和实现</strong>，有一个Interface，可以对应多个实现Class。那从集成测试的角度来看，Mock和Real不就是一个Interface的两个实现么？</p><p>这么说你可能还没理解，做个对比你就更清晰了，这个场景就像图灵实验。</p><p><img src="https://static001.geekbang.org/resource/image/bb/42/bb9b4954748179217baa116fdcyy4a42.jpg?wh=1920x1260" alt="图片"></p><p>在图灵实验里，人类C隔着一堵墙，分别跟B和A交流。当他分辨不出来哪个是人，哪个是电脑的时候，我们就说，电脑A已经具备了和人类B一样的人工智能了。</p><p>在集成测试里，就变成了下图这样：</p><p><img src="https://static001.geekbang.org/resource/image/fb/0c/fbyy7bbe3e8e3e61a2c54e3bb59e150c.jpg?wh=1920x1272" alt="图片"></p><p>C通过Interface定义的规范和A、B打交道，而Mock和Real都是对Interface MessageBus的实现。所以，C不能分辨出哪个是A，哪个是B，因为它们都遵循Interface MessageBus。</p><p>在Java语言里，MessageBus的Interface定义如下：</p><pre><code class="language-java">public interface IMessageBus{\n    //发送消息\n\tpublic  void sendEmailChangeMessage(Srting userID,String changedEmail);\n\t//接收消息\n    public  Message fetchMessageById(Integer msgId);\n\t............................\n}\n</code></pre><p>有了Interface后，你可以借助工具生成Mock实现。</p><p>下面的例子是Mockito框架，直接通过Interface MessageBus生成Mock messageBus：</p><pre><code class="language-java">import org.mockito.Mock;\nimport org.mockito.MockitoAnnotations;\npublic class FoodComeTest{\n  @Mock\n  private IMessageBus mockMessageBus;\n  public class InterfaceMethodMockingUsingMockAnnotationTest {\n    ........\n     user.changeEmail(userID,changedEmail);\n     mockMessageBus.sendEmailChangeMessage(userID,changedEmail);\n     ........\n  }\n}\n</code></pre><p>通过这个例子，我们看得出Interface的存在对于集成测试十分有用，有很多Mock框架支持通过Inteface生成Mock Class，这就大大降低了Mock的成本。</p><p>现在，我们得出了一条<strong>可测试性实践原则</strong>：开发人员在实现对外部服务访问的时候，应该要设立并通过Interface来完成访问，哪怕是一个Interface只有一个实现Class，也需要有Interface的存在。</p><h2>高效Happy Path</h2><p>很好，现在Mock的成本降低的原则找到了，咱们再接再厉，再分析下集成测试的另外一项重要工作。</p><p>还记得上一讲，我们提到过的Happy Path么？它是一条代码执行路径，如果你能找到有效的Happy Path，集成测试可以做得简单而高效。</p><p>但是，有没有Happy Path，你又能不能找到它，这很大程度取决于代码的结构。有的项目代码写得混乱，调用链复杂，甚至还有回路死循环，这样的代码你想集成测试，恐怕是走入迷宫难回头。</p><p>因此，从集成测试的可测试性角度，代码要满足三条要求：</p><p>1.<strong>结构：</strong>领域逻辑和依赖管理分离，清楚可见；<br>\n2.<strong>层次：</strong>调用链简洁而短，减少无效代码；<br>\n3.<strong>调用关系：</strong>调用链单向，避免回路的产生。</p><p>这三条要求具体怎么实现，我们一一来看。</p><h3>领域逻辑和依赖管理的分离</h3><p>之前讲单元测试时，我们已经学习了通过代码四象限法则，把代码分解到各个功能象限里去，我们以FoodCome为例做了练习，分解后的结果就是，我们建立Controller专门管理依赖；建立User类、Restaurant类，专门做业务逻辑相关的操作。</p><p><img src="https://static001.geekbang.org/resource/image/8e/9b/8e678e078dd95b5ae0e2aa95f2ede29b.jpg?wh=1920x1521" alt="图片"></p><p>不过明确了分工思路还不够，今天我们就展开说说代码层面的实操细节。</p><p>领域逻辑和依赖管理的边界不能只存在开发人员脑子里，否则，项目开发了一段时间后，这个边界就模糊了，甚至埋下项目未来走向腐化的隐患。要让这个边界持续可维护，它应该是可见的。</p><p>怎么让这个边界可见呢？最直观的做法就是，把领域逻辑和依赖管理的代码放在一个项目的不同的package下。</p><p>FoodCome划分了如下几个package：</p><ul>\n<li>Controller: 用来存放Controller类，还有外部依赖的Interface；</li>\n<li>Service:  用来存放Service类，Controller类调用Service，在Service里实现领域逻辑计算；</li>\n<li>Dao: Service类调用Dao类，实现对数据的持久化。</li>\n</ul><p>这样，通过不同package组织的代码，开发人员在后面修改的时候，会自然遵循这些规律，把不同功能的代码添加到相应的package里去。</p><h3>调用链条短而简洁</h3><p>再结合例子说说调用链的问题，在FoodCome应用里，调用关系是这样的：</p><p><img src="https://static001.geekbang.org/resource/image/31/63/318d6700e73d7cbe77eff3c36757b363.jpg?wh=1920x768" alt="图片"></p><p>这个调用链非常简单有效，从Controller处理请求，到最后数据入库，就走了三个截面，分别是：Controller层，Service层和DAO层。</p><p>在很多项目实践中，调用链比这个复杂，有的刚开始简单，后来项目规模变大后，开发人员不断地往里“加货”。比如，有的开发人员特别喜欢加抽象层，加Interface，而且还会引用一堆软件的理论，说得有理有据，认为Interface可以增加将来的可扩展性。</p><p>这些理论没错，但这里我想提醒你，添加抽象层这件事需要保持一个度。在极限编程里还有一个YAGNI理论，YAGNI是英文“You aren’t gonna need it” 的缩写，YAGNI 原则指出，程序员应该在面临确凿的需求时，才要实现相应功能。</p><h3>调用链条单向，避免回路产生</h3><p>单向指的是，我们从Controler调Service，从Service调DAO，这是调用链的方向，而不能反着来。</p><p><img src="https://static001.geekbang.org/resource/image/b3/ff/b3d8ce1c50ce1657078e363b0e1777ff.jpg?wh=1920x709" alt="图片"></p><p>回路指的是，存在两个或以上的Class，它们在调用时互相依赖。</p><p>比方说我们开发FoodCome，遇到这样的问题：在结账时需要检查详细列表，而产生详细列表时又需要先结账，这就成了一个死循环。</p><p>示例代码如下，实际调用路径比这个绕了好几道圈。</p><pre><code class="language-java">public class CheckOutService\n{\n&nbsp; &nbsp; public void CheckOut(int orderId)\n&nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; var service = new ReportGenerationService();\n&nbsp; &nbsp; &nbsp; &nbsp; service.GenerateReport(orderId, this);\n&nbsp; &nbsp; &nbsp; &nbsp; /* other code */\n&nbsp; &nbsp; }\n}\n\npublic class ReportGenerationService\n{\n&nbsp; &nbsp; public void GenerateReport(\n&nbsp; &nbsp; &nbsp; &nbsp; int orderId,\n&nbsp; &nbsp; &nbsp; &nbsp; CheckOutService checkOutService)\n&nbsp; &nbsp; {\n&nbsp; &nbsp; &nbsp; &nbsp; /* calls checkOutService when generation is completed */\n&nbsp; &nbsp; }\n}\n</code></pre><p>解决这样的问题，我们就需要理清工作流，从业务逻辑上彻底解除这样的回路依赖关系。</p><h2>集成测试神器</h2><p>前面，我们从查看代码的角度来寻找Happy Path，对代码的结构、层次和调用关系提出了一系列要求。</p><p>现在，我们再换个思路，能不能从<strong>结果</strong>上观测Happy Path呢？也就是说，我们有没有办法直观地看到这个调用链条呢？</p><h3>Happy Path探测神器</h3><p>你可以在头脑中想象这样一个场景：客户端向系统发起一个请求，就相当于客户要求物流公司把一个货物送到目的地，物流公司先把货物运送到A站点，然后A站点再运到B站点，以此类推，经过多个站点后，最后到达目的地仓库。</p><p>这个场景里，物流公司就是软件系统，货物经过的A站点、B站点就是一个个软件服务，而货物走过的ABCD路径，就是服务的调用链。</p><p>要想追溯物流的派送路径，那就得问物流公司的负责人，要想知道服务的调用链，我们就得问系统的管理员。在现实中，这个系统的管理员往往是生产环境的运维人员，它们可以<strong>借用各种运维工具，来观测和追踪生产环境的负载</strong>。</p><p>能做链路观测和追踪的运维工具有很多，有Zipkin、Dapper、Skywalking等。这里我们以SkyWalking为例，来看一下分布式追踪是怎么做的。</p><p>SkyWalking是Apache基金项目下的一个开源项目，用来做可观测性分析，提供分布式跟踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。</p><p>在Skywalking <a href="https://skywalking.apache.org">官方网站</a>，你可以看到它的架构图：</p><p><img src="https://static001.geekbang.org/resource/image/47/7a/478582b42e61489f844e47b716c2c27a.jpg?wh=1920x949" alt="图片"></p><p>安装配置SkyWalking，你参照<a href="https://skywalking.apache.org/docs/skywalking-showcase/latest/readme">这个文档</a>就能自学。这里我重点说说Skywalking是怎么工作的呢？</p><p>Skywalking需要在每一个服务上启用Skywalking的Agent，也就是图的左上方Tracing部分。</p><p>每当服务处理Inbound和Outbound请求时，Agent就把这些信息发送到SkyWalking的OAP服务器上去，OAP服务将这些信息经过链接、聚合、分析后，用户就能通过左下方的UI来查看这些调用信息组织形成的调用链条了。</p><p>SkyWalking UI上的功能很多，寻找Happy Path，我们可以使用下面这2个功能。</p><p>先看Topology功能下的服务拓扑图，通过拓扑图，可以看到所有的服务和它们的调用关系。</p><p><img src="https://static001.geekbang.org/resource/image/ba/55/bacb1aec464202821141yyaaa18d0355.jpg?wh=1920x845" alt="图片"></p><p>如果我们想观测一个特定的请求，看它走过了哪些路径，可以看Skywalking UI上的Trace Tree。</p><p><img src="https://static001.geekbang.org/resource/image/ca/39/cac202a1035e73554d8b0588968eff39.jpg?wh=1920x830" alt="图片"></p><p>Trace图里，左边导航栏里是一个个的请求，右边的Tree视图里展现了每个请求走过的调用链。这张页面截图主要是让你大概了解。清晰的调用关系，你可以参看下面这张逻辑图。</p><p><img src="https://static001.geekbang.org/resource/image/65/b4/65f226413ec1381b6564e8784506c7b4.png?wh=1872x706" alt="图片"></p><p>有了调用Tree后，我们就可以运行两个测试案例A和B，使用白盒测试的路径覆盖法则，查看哪个测试案例能覆盖更多的路径，哪个就是Happy Path了！</p><p>如果你对白盒测试的路径覆盖方法不太熟悉，可以通过<a href="https://www.jianshu.com/p/8814362ea125">这个资料</a>，了解一下白盒测试的基本理论。</p><h3>Docker构建随时可测的数据库</h3><p>上一讲，我们提到直接用真实的数据库实例来做集成测试。不过这个在实践中，你可能会遇到一系列问题，这个真实的数据库实例是生产环境么？如果不能用生产环境数据库，自己搭建数据库怎么能够保证真实模拟的测试的效果？</p><p>这些问题解决不了，集成测试的成本也会很高，甚至导致在实践中，集成测试无法开展。</p><p>应该怎么办呢？我先抛出开展集成测试的三个关键目标。</p><p>第一，集成测试的环境应该是独立的，和生产环境分离；</p><p>第二，集成测试的数据库上的数据库对象应该和生产环境保持同步；</p><p>第三，集成测试数据库实例的生成应该是快速的。</p><p>要实现第一条和第三条，我们可以采用Docker的方式来准备集成测试环境。Docker比较轻量，速度也快。但是要做到第二个目标，通过Docker构建一个和生产环境同样对象版本的环境，这就需要开发人员对数据库的对象、脚本的维护都能进行版本化管理。</p><p>这里我说说我的实践经验，希望你能灵活应用，帮助DBA和开发人员管理好数据库。</p><p>第一，<strong>版本化管理</strong>。所有的数据库对象、脚本、数据都要和应用代码一起进行版本化管理。结合自己的实践验证，我特意给你梳理了后面的自检清单。</p><p><img src="https://static001.geekbang.org/resource/image/0a/66/0a29abbd1b644cbf92f766699f458e66.jpg?wh=1920x1006" alt="图片"></p><p>这项工作的完成标准，就是你随时可以从版本库里，拉出来一个版本的应用代码和数据库脚本，部署成一个可运行的应用+数据库。</p><p>第二，跟应用代码升级一样，数据库的变更也要通过版本化的脚本来完成。</p><p>一些开发人员有一个不好的习惯，直接用Console等工具变更数据库，比如给表加一个字段、修改一个字段的长度等等。这些变更没有记录，之后数据库的维护、回滚、重建都会遇到困难。</p><p>正确的姿势是，开发人员应该写脚本来完成数据库的变更。如果变更数据库schema，那就写一段ALTER SQL，在开发环境测试通过后，把它提交到版本库里，<strong>和提交、合并应用代码是一样的流程</strong>。然后Ops通过部署，把应用代码和数据库变更，一起更新到生产环境。</p><p>好，如果你的开发人员和DBA完成了这些工作，那就可以享受集成测试的方便和敏捷了，你可以写一个Dockerfile，来描述Mysql数据库的生成步骤，比如这样：</p><pre><code class="language-dockerfile">FROM mysql:5.6\nENV MYSQL_ROOT_PASSWORD liusheng12345\nCOPY sql/my_install.sql /tmp/\n# https://hub.docker.com/_/mysql \nCOPY sql/seed_data.sh /docker-entrypoint-initdb.d/\nCOPY cnf/my.cnf /etc/mysql/\n</code></pre><p>然后，你再运行一个Docker 命令：</p><pre><code class="language-json">Docker build -t "myintegration:1.0" .\n</code></pre><p>这样一来，你的数据库实例就启动了，可以测试了！</p><h3>集成测试环境搭建神器</h3><p>通过前面的学习，我们发现Docker具有快速、轻量、低成本的特点，是我们搭建集成测试环境的理想技术方案。沿着这个方向，你可以学习Kubernetes、Helm、Docker Compose这些Docker部署技术，把它们应用在集成测试里，但这个学习过程也是个耗时又耗脑细胞的过程。</p><p>那有没有一种方案，能封装这些技术，让测试人员不用懂Docker，也能管理集成测试环境呢？</p><p>有痛点，就一定会有人去做解决方案。所以测试容器化应运而生，有Testcontainers、Arquillian等工具。我们这就来看一下Testcontainers是怎么做的。</p><p>Testcontainer实际就是一组Java Library，自动化测试开发人员通过调用Java代码，来生成Docker容器实例。</p><pre><code class="language-java">public class OrderTest{\n  @Container\n  PostgreSQLContainer&lt;?&gt; postgreSQLContainer = new PostgreSQLContainer&lt;&gt;("postgres:latest");\n \n  @Before\n  public void setup(){\n    String jdbcURL = postgreSQLContainer.getJdbcUrl();\n    String username =  postgreSQLContainer.getUsername();\n    String password = postgreSQLContainer.getPassword();\n    //使用刚创建的数据库容器作为测试数据库\n    OrderRepository.initializeDB(jdbcUrl,username,password);  \n  }\n  public void testCreateOrder(){\n    //创建订单\n    .........createOrder............\n    //从数据库容器获得订单数据，验证创建成功\n    ........ fetch order from containerized postgreSQL............\n  }\n}\n</code></pre><p>上面的Java代码，在new PostgreSQLContainer对象的时候，实际上创建并启动了一个用Postgres作为镜像的Docker容器，用这个Docker容器作为Order数据库，这样，创建的订单会被保存在容器里。</p><p>容器对象建好以后，在后面的Test方法，我们就可以连上这个容器对象，来验证里面的订单数据了。是不是很简单？甚至你根本不需要懂Docker是怎么启动的，就可以集成测试了。</p><p>利用容器代码化这个便捷方法，你还可以创建错误数据的数据库，做异常测试。</p><pre><code class="language-java">@Container\npublic PostgreSQLContainer&lt;?&gt; goodPostgreSQLContainer = new PostgreSQLContainer&lt;&gt;("postgres:alpine")\n            .withInitScript("db_init.sql")\n            .waitingFor(Wait.forLogMessage("good database startup", 1));\n@Container\npublic PostgreSQLContainer&lt;?&gt; badPostgreSQLContainer = new PostgreSQLContainer&lt;&gt;("postgres:alpine")\n            .withInitScript("db_wrong.sql")\n            .waitingFor(Wait.forLogMessage("bad database startup", 1));\n</code></pre><p>TestContainer的解决方案不限于数据库，还有RabbitMQ、Kafaka消息中间件，Elastic search服务实例、Azure云服务等等。更多同类的解决方案，你还可以到<a href="https://www.testcontainers.org">这个网站</a>上去看一下模块列表。</p><p><img src="https://static001.geekbang.org/resource/image/26/28/260cff883d213be85ca940b51a192d28.jpg?wh=1507x1050" alt="图片"></p><h2>小结</h2><p>一口气学到这里不容易，给坚持学习的你点赞。今天围绕集成测试的可测试性这个主题，我们一起学习了不少开发知识。</p><p>开发需要定义Interface，这样测试程序就可以通过Interface快速生成可用的Mock对象。简单高效的Happy Path，实际要依赖<strong>设计合理、边界清楚、调用简捷的代码</strong>。</p><p>除了代码规范，我还介绍了一些链路观测、追踪工具。有了这些神器加持，你就能直观看到某个请求的调用路径，从结果上寻找Happy Path。</p><p>结合实践经验来看，搭建集成测试环境这项工作也不容忽视。想要快速搭建集成测试环境，还需要开发人员和DBA有效管理好数据库对象，所有的数据库对象、脚本、数据都要和应用代码一起进行版本化管理。</p><p>此外，测试环境Docker容器化也是一个必然的趋势，我们需要学会怎么利用Docker来容器化集成测试所需的外部实例，甚至我们的测试环境也可以被容器化，达到开箱即用的效果。</p><p>说句题外话，<a href="https://time.geekbang.org/column/article/506638">第十一讲</a>和这一讲，是第二模块我认为最有价值的两篇内容，它们的出发点都是<strong>从测试推动开发</strong>。</p><p>也许现在的你，并没有决定未来选择什么方向发展，但我希望你可以掌握全栈知识，看到更多立足测试思维去解决问题的可能性，自由穿梭于测试和开发之间，这样你的工作前景也会越来越宽广。</p><h2>思考题</h2><p>分享一下你有哪些好办法来搭建集成测试环境？</p><p>欢迎你在留言区和我交流互动，也推荐你把今天这一讲分享给你的同事、朋友。</p>',
        article_title: "13｜集成测试（二）：携手开发，集测省力又省心",
      },
      {
        title: "14｜集成测试（三）：护航微服务集群迭代升级",
        id: 509551,
        content:
          '<p>你好，我是柳胜。</p><p>从第七讲开始，我们的FoodCome系统一步步演变。可以看到，当FoodCome从一个单体应用发展成一个服务集群的时候，它的内部服务，按功能可以划分出前端和后端、上游和下游等等</p><p>这就像传统社会走向现代化，开始分出第一产业、第二产业和第三产业，接着逐渐出现精细分工，产生了各种专业岗位，共同协作来完成整个社会的运转。这么复杂的社会，是靠什么协调不同的职业呢？靠的是大家都遵守法律和契约。</p><p>而在微服务集群的世界，也是一样的道理。各个服务之间通过契约来交互协作，整个系统就能运转起来。所以，契约就是微服务世界里一个重要的概念。契约是怎么用起来的呢？</p><p>这就绕不开两个关键问题，<strong>第一，契约的内容是什么？第二，谁来保障，怎么保障契约的履行？</strong>今天我们就带着这两个问题来学习服务的契约，学完这一讲之后，你就知道怎么做微服务的集成测试了。</p><h2>契约的内容</h2><p>在“微服务测什么”一讲中（<a href="https://time.geekbang.org/column/article/503214">第八讲</a>），我们已经整理出来了订单服务的契约。我带你复习一下当时我们整理出来的两个接口规范，我把它们贴到了后面。</p><p>一个是RestAPI，完成用户下单的功能，OpenAPI接口定义如下：</p><pre><code class="language-yaml">"/api/v1/orders":\n&nbsp; &nbsp; post:\n&nbsp; &nbsp; &nbsp; consumes:\n&nbsp; &nbsp; &nbsp; - application/json\n&nbsp; &nbsp; &nbsp; produces:\n&nbsp; &nbsp; &nbsp; - application/json\n&nbsp; &nbsp; &nbsp; parameters:\n&nbsp; &nbsp; &nbsp; - in: body\n&nbsp; &nbsp; &nbsp; &nbsp; name: body\n&nbsp; &nbsp; &nbsp; &nbsp; description: order placed for Food \n&nbsp; &nbsp; &nbsp; &nbsp; required: true\n&nbsp; &nbsp; &nbsp; &nbsp; properties:\n          foodId:\n            type: integer\n          shipDate:\n            type: Date\n          status:\n            type: String\n            enum:\n            - placed\n            - accepted\n            - delivered\n&nbsp; &nbsp; &nbsp; responses:\n&nbsp; &nbsp; &nbsp; &nbsp; \'200\':\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; description: successful operation\n&nbsp; &nbsp; &nbsp; &nbsp; \'400\':\n          description: invalid order\n</code></pre><!-- [[[read_end]]] --><p>还有一个是消息接口，它在处理完订单后，还要往消息队列的Order Channel里发布这样的消息，这样别的服务就能从Order Channel取到这个订单，再进行后续的处理。</p><p>AsyncAPI接口定义如下：</p><pre><code class="language-yaml">asyncapi: 2.2.0\ninfo:\n&nbsp; title: 订单服务\n&nbsp; version: 0.1.0\nchannels:\n&nbsp; order:\n&nbsp; &nbsp; subscribe:\n&nbsp; &nbsp; &nbsp; message:\n&nbsp; &nbsp; &nbsp; &nbsp; description: Order created.\n&nbsp; &nbsp; &nbsp; &nbsp; payload:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: object\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; properties:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; orderID:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: Integer\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; orderStatus:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; type: string\n</code></pre><p>这两份契约的服务提供者是订单服务，消费者有两个，一个RestAPI契约的消费者，一个是消息契约的消费者。我画了一张图，你会看得更清楚些。</p><p><img src="https://static001.geekbang.org/resource/image/f0/d6/f03ace81d9081d8d61efa475b0cc19d6.jpg?wh=1920x1183" alt="图片"></p><h2>契约的游戏规则</h2><p>有了契约后，微服务的开发协作，就基于契约运转起来了，怎么运行呢，分成契约的<strong>建立、实现、验证</strong>三个阶段。</p><p>1.契约建立。契约双方，也就是服务提供者和消费者“坐在一起”，签订了一个契约，大家都同意遵守这个规则来做自己的开发。</p><p>2.契约的实现。订单服务按照契约来实现自己的服务接口，同时，API网关和通知服务、餐馆服务，它们都按照契约来实现自己的调用接口。</p><p>3.契约的验证，契约双方完成自己的工作后，然后再“坐在一起”完成集成，看看是不是履行了契约。</p><p>这个协作模型，跟我们现实里常见的债务合同很相似。合同签订的内容是，订单服务欠下了一笔债，到开发周期结束后，订单服务要按照合同约定的方式向调用者偿还这笔债。</p><p>但这还是个模型，想要真正落地实践，有两个问题需要考虑清楚。</p><p>第一个问题是监督机制。在契约建立日到履行日之间的这段时间里，有没有办法设置检查点来检查契约履行的进度和正确性，万一订单服务跑偏了，可以提前纠正。</p><p>第二个问题是检查办法，也就是如果要做检查，谁负责检查？</p><p>显然，这个检查的手段就是测试，那么谁来做这个测试呢？让服务者自测？</p><p>这个不太靠谱，最合适的办法，是让消费者去做测试，这就像在债务合同里，法律规定债权人要定时追讨债务，不履行追讨权超过一定时间，最终法院可能会不支持诉讼。这样做的目的是保证契约机制运转高效。</p><p>欠债还钱的现实世界，债权人推动着合同如期履行。按时交付的技术领域，消费者驱动着契约测试，那这个过程具体是怎么操作的呢？</p><h2>消费者驱动契约测试</h2><p>消费者驱动契约测试的玩法是这样的：消费者来主动去定义契约，开发测试脚本，然后把这个测试脚本交给服务者去跑，服务者要确定自己开发的代码能测试通过。这个过程相当于消费者完成了验收测试。</p><p>对于FoodCome来说，API网关负责编写RestAPI测试案例，通知服务和餐馆服务负责编写Message测试案例，如下图：</p><p><img src="https://static001.geekbang.org/resource/image/e5/be/e58fc28844c2950c627c5aa114615abe.jpg?wh=1920x1356" alt="图片"></p><h2>RestAPI的契约测试</h2><p>先来看一下RestAPI的契约测试怎么做。</p><p>首先你要明白，我们这种契约测试的场景处于<strong>开发阶段</strong>，契约测试案例的工具需要持续而快速地维护和验证契约。</p><p>所以，这个工具应该有高效的自动化能力，具体要满足这两个条件，首先要能解析契约，其次还能根据契约生成Test Class和Stub方便测试。</p><p>符合这两个条件的工具有不少，其中Pact和SpringCloud比较主流。今天我们就以Spring Cloud为例来看一下RestAPI契约测试怎么做的。</p><p>第一步，Spring Cloud先要加载契约，代码示例如下：</p><pre><code class="language-groovy">org.springframework.cloud.contract.spec.Contract.make {\n    request {\n        method \'POST\'\n        url \'/api/v1/orders\'\n    }\n    response {\n        status 200\n        headers {\n            header(\'Content-Type\': \'application/json;charset=UTF-8\')\n        }\n        body(\'\'\'{"orderId" : "1223232", "state" : "APPROVAL_PENDING"}\'\'\')\n    }\n}\n</code></pre><p>第二步，根据契约，Build分别生成Stub和Test Class，其中Test Class给服务提供者，Stub给消费者，因为它们是同一份契约产生的，所以只要运行成功，就等同于双方都遵守了契约。</p><p>原理图是这样的，在订单服务项目下，运行Spring Cloud Contract Build，会在target/generated-test-sources目录下，自动产生一份ContractVerifierTest代码，供订单服务（也就是服务提供者）来测试自己的服务接口，也就是下图的右侧区域。</p><p>同时，SpringCloud Contract还提供一个sub-runner的Jar包，供消费者做集成测试的stub，这里对应着下图的左侧区域。</p><p><img src="https://static001.geekbang.org/resource/image/75/97/753792656271befa2f074eebyy042897.jpg?wh=1920x1082" alt="图片"></p><p>服务者侧的集成测试代码示例如下：</p><pre><code class="language-java">public abstract class ContractVerifierTest {\n  private StandaloneMockMvcBuilder controllers(Object... controllers) {\n    ...\n    return MockMvcBuilders.standaloneSetup(controllers)\n                     .setMessageConverters(...);\n  }\n  @Before\n  public void setup() {\n    //在开发阶段，Service和Repository还是用mock\n    OrderService orderService = mock(OrderService.class);                    ❶\n    OrderRepository orderRepository = mock(OrderRepository.class);\n    OrderController orderController =\n              new OrderController(orderService, orderRepository);\n  }\n  @Test\n  public void testOrder(){\n    when(orderRepository.findById(1223232L))                                 ❷\n            .thenReturn(Optional.of(OrderDetailsMother.CHICKEN_VINDALOO_ORDER));\n    ...\n    RestAssuredMockMvc.standaloneSetup(controllers(orderController));        ❸\n  }\n}\n</code></pre><p>这段代码的意思是，开发人员先写好OrderController代码，把接口代码写好，负责业务逻辑的OrderService和OrderRepository暂时用Mock来替代。而自动生成的ContractVerifierTest是来测试和验证OrderController的接口，不管将来OrderService和OrderRepository怎么实现和变化，只要保证OrderController接口不变，就可以。</p><p>消费者这一侧，这是在本地启动一个HTTP的Stub服务，在真实的订单服务没有完成之前，消费者可以和Stub做集成测试。具体代码如下：</p><pre><code class="language-java">@RunWith(SpringRunner.class)\n@SpringBootTest(classes=TestConfiguration.class,\n        webEnvironment= SpringBootTest.WebEnvironment.NONE)\n@AutoConfigureStubRunner(ids =                                            \n         {"com.foodcome.contracts"},\n        workOffline = false)\n@DirtiesContext\npublic class OrderServiceProxyIntegrationTest {\n  @Value("${stubrunner.runningstubs.foodcome-order-service-contracts.port}")  \n  private int port;\n  private OrderDestinations orderDestinations;\n  private OrderServiceProxy orderService;\n  @Before\n  public void setUp() throws Exception {\n    orderDestinations = new OrderDestinations();\n    String orderServiceUrl = "http://localhost:" + port;\n    orderDestinations.setOrderServiceUrl(orderServiceUrl);\n    orderService = new OrderServiceProxy(orderDestinations,               \n                                          WebClient.create());\n  }\n  @Test\n  public void shouldVerifyExistingCustomer() {\n    OrderInfo result = orderService.findOrderById("1223232").block();\n    assertEquals("1223232", result.getOrderId());\n    assertEquals("APPROVAL_PENDING", result.getState());\n  }\n  @Test(expected = OrderNotFoundException.class)\n  public void shouldFailToFindMissingOrder() {\n    orderService.findOrderById("555").block();\n  }\n}\n</code></pre><p>可以看到，只要契约不变，生成的服务端测试代码也是不变的。如果有一天，服务端在迭代开发中没有遵守契约，那么测试案例就会失败。</p><p>测试案例失败之后，服务端面临两个选择，要么修改自己的代码让契约测试通过，要么去修改契约，但是修改了契约后，消费者的测试又会失败。这样，我们就能以<strong>测试结果</strong>为准绳，让消费者和服务者始终保持同步。</p><h2>Message的契约测试</h2><p>Spring Cloud Contract也支持基于Message的契约，它和RestAPI的契约实现方法比较像，直接上原理图，你理解起来更直观。</p><p><img src="https://static001.geekbang.org/resource/image/0d/b8/0d0329a375100e55ab572082b4dff6b8.jpg?wh=1920x1292" alt="图片"></p><p>这里我画了一张图片，为你解读餐馆服务和订单服务通过契约做集成测试的内部原理。</p><p>还是同样的配方，熟悉的味道，一份契约产生服务者端集成测试代码和消费者集成测试代码。跟OpenAPI的原理类似，这里我同样把示例代码贴出来，供你参考。</p><p>服务端的集成测试代码如下：</p><pre><code class="language-java">@RunWith(SpringRunner.class)\n@SpringBootTest(classes = MessagingBase.TestConfiguration.class,\n                webEnvironment = SpringBootTest.WebEnvironment.NONE)\n@AutoConfigureMessageVerifier\npublic abstract class MessagingBase {\n  @Configuration\n  @EnableAutoConfiguration\n  @Import({EventuateContractVerifierConfiguration.class,\n           TramEventsPublisherConfiguration.class,\n           TramInMemoryConfiguration.class})\n  public static class TestConfiguration {\n    @Bean\n    public OrderDomainEventPublisher\n            OrderDomainEventPublisher(DomainEventPublisher eventPublisher) {\n      return new OrderDomainEventPublisher(eventPublisher);\n    }\n  }\n\n  @Autowired\n  private OrderDomainEventPublisher OrderDomainEventPublisher;\n  protected void orderCreated() {                                   \n     OrderDomainEventPublisher.publish(CHICKEN_VINDALOO_ORDER,\n          singletonList(new OrderCreatedEvent(CHICKEN_VINDALOO_ORDER_DETAILS)));\n  }\n}\n</code></pre><p>消费者端集成测试代码如下：</p><pre><code class="language-java">@RunWith(SpringRunner.class)\n@SpringBootTest(classes= RestaurantEventHandlersTest.TestConfiguration.class,\n        webEnvironment= SpringBootTest.WebEnvironment.NONE)\n@AutoConfigureStubRunner(ids =\n        {"foodcome-order-service-contracts"},\n        workOffline = false)\n@DirtiesContext\npublic class RestaurantEventHandlersTest {\n  @Configuration\n  @EnableAutoConfiguration\n  @Import({RestaurantServiceMessagingConfiguration.class,\n          TramCommandProducerConfiguration.class,\n          TramInMemoryConfiguration.class,\n          EventuateContractVerifierConfiguration.class})\n  public static class TestConfiguration {\n    @Bean\n    public RestaurantDao restaurantDao() {\n      return mock(RestaurantDao.class);                                    \n     }\n  }\n  @Test\n  public void shouldHandleOrderCreatedEvent() throws ... {\n    stubFinder.trigger("orderCreatedEvent");                                 \n     eventually(() -&gt; {                                                      \n       verify(restaurantDao).addOrder(any(Order.class), any(Optional.class));\n    });\n  }\n</code></pre><p>使用Pact也可以达到同样的效果，如果感兴趣，你可以研究一下。</p><h2>小结</h2><p>今天我们主要讲了微服务群内部之间的集成测试。</p><p>跟外部的服务集成测试不同，内部服务经常处在一个迭代开发的状态，可能一个服务变动了，就会导致别的服务不能工作。</p><p>为了解决这种问题，我们引入了<strong>消费者驱动契约测试</strong>的方法论。这个契约测试的特点是消费者把自己需要的东西写入契约，这样一份契约产生两份测试代码，分别集成到契约的服务端和消费端，服务端有任何违背契约的代码变更，会第一时间以测试失败的形式抛出。</p><p>为了让你深入理解契约测试的思想，学会怎样把这个方法论真正落地。我还带你一起实现了Spring Cloud的在RestAPI和Message两个方面的契约示例。有了这个基础，你可以结合自己面对的实际情况做调整，实现更契合自己项目的一套契约，集成测试做起来也会更得心应手。</p><p>当然了，Sping Cloud Contract还有更多的扩展使用，比如和OpenAPI的转换、Cotract的中央存储和签发等等，你有兴趣可以在这个领域继续深挖，也期待你通过留言区晒出自己的心得。</p><h2>牛刀小试</h2><p>这一讲中的契约是Groovy方式书写的，我们之前总结的契约是以YAML方式表现的，你可以在Spring Cloud Contract和Pact中任选其一，实现对yaml契约的加载。</p><p>欢迎你和我多多交流讨论，也推荐你把今天的内容分享给身边的朋友，和他共同进步。</p>',
        article_title: "14｜集成测试（三）：护航微服务集群迭代升级",
      },
      {
        title: "15｜UI测试：如何让UI测试更轻快便捷？",
        id: 510620,
        content:
          '<p>你好，我是柳胜。</p><p>恭喜你坚持到这里，我们顺着测试金字塔底层的单元测试一步步向上，现在终于到了金字塔顶部。按照我们的整体设计，其实脏活累活已经在底层干得差不多了。</p><p>爬上塔顶不容易，应该是一身轻松，纵览风光了。可以想象，如果没有前面的整体设计，没有单元测试来夯实基础，把测试工作全都压到端到端测试，它必然会垮掉。</p><p>不过，既然需要金字塔顶部这个UI测试层，一定是它不可替代，做得了其他层力所不能及的事儿。今天咱们就来梳理下UI测试要做什么，怎么做才能收割更高的ROI。</p><p>UI全名叫做User Interface，在当下，User这个概念已经被扩展，甚至被滥用，我倒觉得，UI叫做PI（People Interface）更为准确，专指和人格用户交互的界面。</p><p>从UI这个角度，主要有三个测试点需要去关注：第一，用户的行为；第二，UI的布局；第三是用户的易用性。当然，根据具体业务的需求，还有其他的点，比如Globalization全球化、Accessibility亲和力等等。</p><h2>用户行为测试</h2><p>用户的行为，指的是用户通过操作UI，获得他想要的功能。在FoodCome里，用户通过WebUI填好订单信息，然后点击“下订单”按钮，就能完成下单功能。</p><!-- [[[read_end]]] --><p><img src="https://static001.geekbang.org/resource/image/d7/81/d7cf1716877d300d129f26578a050181.png?wh=681x411" alt="图片"></p><p>分析一下就能知道，在这个过程里，有两部分代码逻辑参与了下单，一个是前端逻辑，就是HTML+JavaScript代码；另外一个就是后端逻辑，也就是我们前面讲过的RestAPI和DB。</p><p>既然后端逻辑我们在单元测试就测过了，而前后端集成我们也用契约测试测过了，那么UI测试的关键点，就在于前端逻辑有没有，又有多少？</p><p>这里要分两种情况。第一种，前端没有业务逻辑，就是简单的发送请求，接收响应并展现。这些工作都是通过浏览器的内嵌功能来完成的。比如FoodCome可以用一个HTML form来完成订单的提交过程：</p><pre><code class="language-xml">&lt;form method="POST" enctype="application/x-www-form-urlencoded" action="/html/codes/html_form_handler.cfm"&gt;\n&lt;p&gt;\n&lt;label&gt;餐馆名字\n&lt;input type="text" name="restaurant_name" required&gt;\n&lt;/label&gt;&nbsp;\n&lt;/p&gt;\n\n&lt;fieldset&gt;\n&lt;legend&gt;菜单&lt;/legend&gt;\n&lt;p&gt;&lt;label&gt; &lt;input type="checkbox" value="no1"&gt; 宫保鸡丁 &lt;/label&gt;&lt;/p&gt;\n&lt;p&gt;&lt;label&gt; &lt;input type="checkbox" value="no2"&gt; 佛跳墙 &lt;/label&gt;&lt;/p&gt;\n&lt;p&gt;&lt;label&gt; &lt;input type="checkbox" value="no3"&gt; 珍珠翡翠白玉汤 &lt;/label&gt;&lt;/p&gt;\n&lt;/fieldset&gt;\n&lt;p&gt;&lt;button&gt;下订单&lt;/button&gt;&lt;/p&gt;\n\n&lt;/form&gt;\n</code></pre><p>这也是业界提到过的Thin Client瘦客户端，客户端里没有或只有很少的业务逻辑。</p><p>瘦客户端怎么测？我的答案是，在单元测试和集成测试已经充分的情况下，瘦客户端只需找两三个典型业务场景测一下，甚至都不需要考虑UI自动化。因为主要的逻辑和路径都已经测过了嘛，你没必要再花时间重复。</p><p>与瘦客户端相对应的是胖客户端，也叫Rich Client，当然胖客户端里是嵌入了大量的业务逻辑。当今业界，胖客户端更加普遍，比如WebUI里嵌入了JavaScript来聚合后端的数据、画图、表格、排序等等，从这个角度，你也可以把Desktop客户端直接当作胖客户端来对待。</p><p>胖客户端该怎么测？ 要回答这个问题，我们需要首先思考一下“胖客户端是什么”。在微服务世界里，每个微服务实现自己的业务逻辑，向外提供服务，同时也是客户端去消费其他的服务。</p><p>而胖客户端是什么呢，它也有自己的业务逻辑，聚合数据、图形化都是它的业务逻辑。但是有一点特殊，胖客户端是微服务集群调用链条最早一个，它只会去调用别人，调用胖客户端的是终端用户。</p><p>从这个角度来看，胖客户端满足了提供服务，也消费其他服务的微服务特征，因此<strong>胖客户端本质上也是一个微服务。</strong></p><p>说到这里，胖客户端怎么测这个问题的答案就呼之欲出了。微服务该怎么测，胖客户端就该怎么测。什么意思呢？你还是要遵循测试3KU金字塔原则，胖客户端首先要做单元测试，再做集成测试，最后才是UI测试。</p><p>看到这里你可能会有点困惑，UI客户端还要分层，这是怎么回事呢？我拿WebUI的开发框架举个例子，你就明白了。</p><p>React是业界很常用的JavaScript开发框架，看看它是怎么实现下订单操作的：</p><pre><code class="language-javascript">class FlavorForm extends React.Component {\n&nbsp; constructor(props) {\n&nbsp; &nbsp; super(props);\n&nbsp; &nbsp; this.handleChange = this.handleChange.bind(this);\n&nbsp; &nbsp; this.handleSubmit = this.handleSubmit.bind(this);\n&nbsp; }\n\n&nbsp; handleChange(event) {&nbsp; &nbsp; this.setState({value: event.target.value});&nbsp; }\n&nbsp; handleSubmit(event) {\n&nbsp; &nbsp; alert(\'Your order is: \' + this.state.value);\n&nbsp; &nbsp; event.preventDefault();\n&nbsp; }\n\n&nbsp; render() {\n&nbsp; &nbsp; return (\n&nbsp; &nbsp; &nbsp; &lt;form onSubmit={this.handleSubmit}&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;label&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Pick your favorite flavor:\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;select value={this.state.value} onChange={this.handleChange}&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \n            &lt;option value="no1"&gt;宫保鸡丁&lt;/option&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;option value="no2"&gt;佛跳墙&lt;/option&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;option value="no3"&gt;珍珠翡翠白玉汤&lt;/option&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;/select&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;/label&gt;\n&nbsp; &nbsp; &nbsp; &nbsp; &lt;input type="submit" value="下订单" /&gt;\n&nbsp; &nbsp; &nbsp; &lt;/form&gt;\n&nbsp; &nbsp; );\n&nbsp; }\n}\n</code></pre><p>上面一段简单React JavaScript代码有render来做数据的展现，有Handler来做数据的处理，还有props做数据的存储。其实React开发的前端功能，跟一个后端服务的MVC结构是类似的。</p><p><img src="https://static001.geekbang.org/resource/image/0c/13/0c19d928a328cf566yyb180295e53b13.jpg?wh=1920x1242" alt="图片"></p><p>看到没有？UI前端也有设计模式，也可以实现很多业务逻辑。所以，你可以把UI前端当做一个微服务来测试，既然是微服务，那就可以分层，做单元测试。</p><p>那前端的单元测试怎么做呢？和后端原理是一样的，该写Test方法写Test方法，该Assert就Assert，该Mock就Mock。只是前端开发框架有很多种，相对应地，单元测试框架也有多种，你需要找到匹配的那一对。我给你总结了一个表格，你也可以结合自己实践拓展、丰富它。</p><p><img src="https://static001.geekbang.org/resource/image/cb/77/cb48a99e45156d32cedc40ddc7410b77.jpg?wh=1920x714" alt="图片"></p><p>下面是使用Vue Test Utils来执行单元测试的例子，在订单页面，点击一个check Order按钮，验证页面上是否会显示“order validated”的消息。</p><pre><code class="language-javascript">import { shallowMount } from \'@vue/test-utils\'\n\timport OrderToggle from \'@/components/OrderToggle.vue\'\n\timport Order from \'@/components/Order.vue\'\n\tdescribe(\'OrderToggle.vue\', () =&gt; {\n\t  it(\'toggles msg passed to Order when Place Order button is clicked\', () =&gt; {\n\t    const wrapper = shallowMount(OrderToggle)\n\t    const button = wrapper.find(\'#check-order\')\n\t    button.trigger(\'click\')\n\t    const OrderComponent = wrapper.find(Order)\n\t    expect(OrderComponent.props()).toEqual({msg: \'order validated\'})  \n\t  })\n\t})\n</code></pre><p>你可以看到，JavaScript单元测试能测试数据逻辑，也能测试页面事件，模拟人的行为，发送一个个点击、输入事件。那么你可能还想问，前端JavaScript的单元测试做完，是不是就不需要额外的UI测试了呢？</p><p>这是一个好问题，不过完成之上，我们希望做得更加完美、更有效益。结合我们专栏里我不厌其烦给你提到的3KU原则，本着“做有效的，不做浪费的测试”的目标，单元测试做完了，UI上只做单元测试没做到的事情。</p><p>你可以思考一下符合这个条件的场景有没有，在哪里？</p><h2>页面的Layout布局测试</h2><p>相比API测试，UI的测试还有一个特殊的地方，不但要验证UI的控件画出来了，而且还要验证它们都在正确的位置上，这个验证就叫做UI布局测试。</p><p>你可以这样理解，API测试里，我们检查数据的时候，是一维的检查，而在UI测试里，数据的检查是二维的，有了x、y的坐标。这个复杂度一下子就上来了。</p><p>布局测试怎么做？有两种方案，咱们分别来看看。</p><p>一种是抓图方案，它是在运行UI自动化测试的时候，顺便调用captureScreen函数，对当前的UI抓屏，保存成图片。然后利用图片比较技术，去看页面的布局有没有发生变化。所以这个方案的技术关键点，就是<strong>位图比较</strong>。业界比较成熟的技术实现有Applitools、Sikuli。</p><p>比如，用Applitools的eyes类进行对比：</p><pre><code class="language-java">driver = new ChromeDriver();\neyes = new CompareEyes();\n// 设置匹配级别为Layout布局\neyes.setMatchLevel(MatchLevel.LAYOUT);\neyes.setEnableComparison(true);\neyes.open(driver, appName, testName, viewPortSize);\neyes.switchToComparisonMode(driver);\n// 使用eyes对比当前窗口和已经保存的图片\neyes.check("/Users/sheng/Desktop/login.png", Target.window());\neyes.close();\ndriver.quit();\n</code></pre><p>上面的代码是，启动Selenium Web Driver，加载页面，初始化eyes，然后调用eyes的check函数来实现图片的比较。</p><p>Applitools有AI的功能，在早期，测试人员手工地对它的比对结果进行确认或纠正，这相当于是训练了AI比对模型。这样使用一段时间后，它的比对会越来越智能，结果会越来越准确。</p><p>第二种是Layout规格说明书方案，什么意思呢？跟传统测试一样，需要先写一份Layout规格说明书，比如屏幕上在什么位置应该出现什么元素等等，应该有一个列表展示。</p><p>然后，自动化测试运行的时候，就把render出来的页面和规格说明书相比较，测试成功或失败。在这个领域里的工具也有很多种，Galen和Lineup是其中的代表。</p><p>比如说，下面我用Galen这个工具，演示的FoodCome系统login页面的Layout规格说明书LoginPage.spec：</p><pre><code class="language-java">@objects\n\t    login-box           id  login-page\n\t    login-caption       css #login-page h2\n\t    username-textfield  css input[name=\'login.username\']\n\t    password-textfield  css input[name=\'login.password\']\n\t    login-button        css .button-login\n\t    cancel-button       css .button-cancel\n\t= Login box =\n\t    @on *\n\t        login-box:\n\t            centered horizontally inside content 1px\n\t            below menu 20 to 45px\n\t        login-caption:\n\t            height 20 to 35px\n\t            text is "Login"\n\t        username-textfield, password-textfield:\n\t            height 25 to 35 px\n\t        login-button, cancel-button:\n\t            height 40 to 50 px\n</code></pre><p>在这个spec里，描述了登录页面的布局，有6个页面对象：登录框、登录标题、用户名输入框，密码输入框、登录按钮和取消按钮，还说明了它们各自的样式和位置。</p><p>在运行测试的时候，当加载login页面的时候，会把展现出来的页面和LoginPage.spec进行匹配验证，匹配成功，说明Layout是按照预期加载的。</p><pre><code class="language-java">public void loginPage_shouldLookGood_onDevice(TestDevice device) throws IOException {\n\tload("/");\n\tgetDriver().findElement(By.xpath("//button[.=\'Login\']")).click();\n\tcheckLayout("/specs/loginPage.spec", device.getTags())\n}\n</code></pre><h2>小结</h2><p>到这里，总结一下我们今天学习到的内容。</p><p>UI测试主要有三个关注点：第一，用户的行为；第二，UI的布局；第三，用户的易用性。</p><p>我并没有在正文介绍易用性，是因为这个关注点，最终指向的问题是：用户体验是一个“感觉好还是坏”。这是一个通过计算机技术，很难做回答的问题。所以，用户体验还是手工测试的方法，你可以考虑用探索性测试的策略来去发现易用性的问题，而这一讲我们重点讨论了前两个关注点，用户的行为和UI的布局。</p><p>从用户行为这个视角分析，UI测试的客户端，可以分为瘦客户端和胖客户端，瘦客户端的测试简单，你可以按照Happy Path的思路找出一两个案例来跑一下就可以了。而胖客户端包含了大量的业务逻辑，你应该用测试服务的方法来测试胖客户端，也要做单元测试。这一讲中针对JavaScript开发框架，列出了相应的单元测试框架，供你参考。</p><p>UI的布局测试也是一个特殊的领域，业界里有两种自动化思路，一个是基于图片，一个是基于Spec，两种方法都各有优势和劣势。我们可以根据项目目标和具体情况，采用其中一个，也可以把这两个思路都用上。</p><h2>牛刀小试</h2><p>说说你的项目中，UI前端有没有做单元测试？</p><p>欢迎你在留言区跟我交流互动，也推荐你把这讲内容分享给更多同事、朋友。</p>',
        article_title: "15｜UI测试：如何让UI测试更轻快便捷？",
      },
      {
        title: "16｜概念重识：如何用3KU为端到端&验收测试赋能？",
        id: 511982,
        content:
          '<p>你好，我是柳胜。</p><p>看到这一讲标题里的“端到端测试”和“验收测试”，还有上一讲的“UI测试”，你可能还有点懵：在实践中，它们三个经常是一回事啊？</p><p>先给你理一理这三个概念。验收测试是指的客户视角，端到端的测试指的是测试方法，UI测试指的是测试发起的地方。听着不太一样，是吧？</p><p>可是我们为什么会觉得这些是一回事呢？因为在实践里，这三个测试概念常常指向同一个测试场景，即客户从UI端发起了一个对系统整体的可接受性测试。几年前的传统软件测试，这是成立的。但现在不一定了：客户不一定是UI用户，还有可能是API用户、SDK用户，端到端测试也不一定包括UI端。</p><p>这一讲，我们就用3KU法则重新审视一下这些测试概念，让我们的实践事半功倍。</p><h2>验收测试</h2><p>验收测试，相当于是一个契约履行。不同于建立在开发者之间的接口契约，验收契约建立在用户和系统之间。所以验收测试的前提条件有两条：第一，这个契约存在；第二，这个契约具有可测试性。</p><p>我们在<a href="https://time.geekbang.org/column/article/502863">第七讲</a>“单体应用测什么”的时候，已经把FoodCome的契约表达出来了，就是<strong>用Ghkerkin语法描述出来的用户使用场景</strong>。</p><pre><code class="language-plain">Given a consumer\n  And a restaurant\n  And a delivery address/time that can be served by that restaurant\n  And an order total that meets the restaurant\'s order minimum\nWhen the consumer places an order for the restaurant\nThen consumer\'s credit card is authorized\n  And an order is created in the PENDING_ACCEPTANCE state\n  And the order is associated with the consumer\n</code></pre><!-- [[[read_end]]] --><p>这样一段描述写在一个名为placeOrder.feature文件里，只要满足了Given的条件，做了When中定义的操作，就会得到Then里的结果。这就是契约的内容。</p><p>我之前和你说过Gherkins语法的好处，它的表达在自然语言和技术语言之间，需求人员理解起来不吃力，往前走一步又能成为测试案例，甚至自动化测试代码。</p><p>今天咱们就接着说说，这件事儿怎么实现。我介绍一个BDD自动化测试框架，它就是Cucumber。</p><p>Cucumber是支持行为驱动开发的软件工具。Cucumber的核心是它的Gherkin语言解析器，能够根据Feature文件直接生成自动化测试代码。详细情况，你可以参考Cucumber的<a href="https://cucumber.io">官方网站</a>。</p><p>下面，我们用一个例子来说明一下Cucumber怎么使用。</p><p>具体操作步骤如下：</p><p>第一步，我们先生成一个测试项目工程，Cucumber可以支持多种开发语言，Ruby，Java，Javascript，.NET等。我们这里以Java为例，使用mvn来生成一个模版项目：</p><pre><code class="language-java">mvn archetype:generate                      \\\n   -DarchetypeGroupId=io.cucumber           \\\n   -DarchetypeArtifactId=cucumber-archetype \\\n   -DarchetypeVersion=2.3.1.2               \\\n   -DgroupId=foodcometest                  \\\n   -DartifactId=foodcometest               \\\n   -Dpackage=foodcome                 \\\n   -Dversion=1.0.0-SNAPSHOT                 \\\n   -DinteractiveMode=false\n</code></pre><p>运行上面的命令，会生成一个空的Java项目，里面包含了Cucumber所需要的Library文件。</p><p>第二步，把上面的Feature文件，添加到项目路径：src/test/resources/foodcometest/placeorder.feature</p><p>接着是第三步，运行mvn命令：</p><pre><code class="language-plain">mvn test\n</code></pre><p>遵循输出的指示，最终就可以自动生成一个测试Class文件了。</p><pre><code class="language-plain">public class PlaceOrderTest ...  {\n  ...\n  @Given("A valid consumer")\n  public void useConsumer() { ... }\n  @Given("a valid restaurant")\n  public void useRestaurant() { ... }\n  @Given("a valid address")\n  public void validAddres(String address) { ... }\n  @Given("a valid order")\n  public void validAddres(Order orderDetails) { ... }\n  @When("I place an order")\n  public void placeOrder() { ... }\n  @Then("the credit card should be authorized")\n  public void authorizeCreditCard(Long creditCardNo) { ... }\n  @Then("order shoudl be Created with pending status")\n  public void orderCreatedInPendingStatus()  { ... }\n}\n</code></pre><p>在Feature文件里，使用Given，When，Then关键字描述的步骤，对应着PlaceOrderTest的一个个函数，你通过函数名上的注解就可以看到这个对应关系，但是函数体还是TODO，需要你去实现。等你实现了这些函数，再运行Cucumber，它会按照Given，When，Then这个顺序来执行契约的验证了！</p><p>你可以看到这样操作的好处，自动化测试代码是紧紧贴合Feature文件的，如果契约变化了，那可以重新运行mvn命令，同步自动化测试代码。那么同时也意味着，自动化测试成功了，就代表契约验证通过，验收测试通过。</p><p>当然，上面说的只是一个Feature的测试，验收测试里还有一个关键问题，验收测试的范围应该有多大？我的建议是，<strong>签订了多少契约，就做多少验收测试</strong>。也就是说，用户显式表达了多少需求，就应该以这个为基准来做验收。</p><p>你可能会问，有些需求不一定是显式的，但又确实存在。比如一些业务异常路径、边角案例，甚至性能指标，这些也需要整体测试，该怎么测呢？这就要说到端到端的测试。</p><h2>端到端测试</h2><p>为什么要做端到端测试呢？我们在单元测试验证了业务逻辑，在集成测试验证了接口，现在终于要真刀真枪，拉上战场了。所有服务都一起上线，要看是不是能匹配得上。</p><p>所以，端到端测试（End-to-end testing）指的是一个功能从开始到结束，贯穿了整个系统的A服务、B服务，一直到N服务。通常这个功能是从哪里发起的呢？一般是UI端。它又在哪里结束呢？在某个服务模块，比如是数据库。</p><p>但是，根据3KU测试金字塔，在UI执行测试是ROI最小的。有没有办法找到一种ROI较高的端到端测试方法呢？在<a href="https://time.geekbang.org/column/article/497405">第二讲</a>里，我提到过“<strong>分层是追求整体ROI的结果</strong> ”，反过来也是成立的，如果为了追求更高的ROI，你甚至可以创建出一个新的分层。</p><p>当时我就在想，UI测试ROI小，但好处是业务可见性强。如果下沉到代码层和接口层，ROI上来了，但是业务又模糊了。所以在接口测试层和系统测试层的中间地带，有没有可能找到一个业务可见性也比较强、ROI也比较高的测试层呢？</p><p>我很惊喜地发现，业界还真有人跟我一样在考虑这个问题了。Martin Fowler在他的网站提出了一种新的测试方法，叫做Subcutaneous Test，中文叫做<strong>皮下测试</strong>。</p><p>皮下测试，顾名思义，是当你要做的端到端测试在UI上测试很难做，或者能做但是成本很高，所以，选择紧贴着UI测试的下一层发起测试。在3KU测试金字塔里，它是在集成测试和UI测试中又加入了一层。</p><p><img src="https://static001.geekbang.org/resource/image/46/5b/4671cce5c9bb86fabc726016fa222b5b.jpg?wh=1920x1108" alt="图片"></p><h3>皮下测试</h3><p>要想实现皮下测试，首先要找到皮层在哪里，看看请求链路，肉眼可见的皮层就是Http request，手机APP是皮上层，后台的订单服务是皮下层。</p><p><img src="https://static001.geekbang.org/resource/image/c5/2e/c50744ea199518dcbdfc2a76d8d13a2e.jpg?wh=1920x986" alt="图片"></p><p>皮下测试就是模拟客户端发出的HTTP请求，直接发送到后端服务。这个用RestAssure测试框架就可以轻松做到：</p><pre><code class="language-java">public class E2ERestTest {\n    @Test\n    public void shouldOrderBeCreated() throws Exception {\n        when()\n                .post("https://api.foodcome.com/api/v1/orders", 443))\n        .then()\n                .statusCode(is(200))\n                .body(containsString("order created"));\n    }\n}\n</code></pre><p>可以看出来，刚才做的皮下测试在执行方法上就是一个API测试。不过它跟正常的API测试相比，有两点不同：</p><p>第一，测试请求注入的地方是订单服务，也是UI端直接连接的入口，这个请求也贯穿了后端的服务A，服务B直到服务N，只是它绕过了ROI最小的UI端。</p><p>第二，发起的测试请求，目的是模拟UI端行为，而不是单纯地为了测试订单服务。</p><p>我给你分析一下，这个皮下测试的方法论原理：本来我们要端到端测试n个服务，但是由于第1个服务，也就是UI端的测试ROI非常低。在这里，怎么把复杂的问题简单化呢？可以利用动态规划的思维，我们把原先的测试工作量f(n)做了这样一个分解。</p><p>具体公式如下：<strong>f(n)=f(1)+f(n-1)</strong></p><p>f(n-1)因为绕过了UI，它的难度一下子降下来了。而f(1) 我们上一讲单独讲到了UI测试，可以用单元测试的方法降低UI测试的复杂度。所以，分而治之后，两部分难度都降下来了。皮下测试的价值也就出来了。</p><p>这里插一句提示，动态规划你不了解的话，可以通过后面<a href="https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/529408">这个资料</a>了解一下。</p><p>我们说回正题，有哪些系统适合做皮下测试呢？ 刚才说到，自动化在UI层做不了，或者能做但是成本很大。比如一些带有画图功能的应用，在UI上有很多的曲线。像下面这样的，就适合皮下测试。</p><p><img src="https://static001.geekbang.org/resource/image/6c/89/6cfb23c331f5403bf4c1f2b559bac389.jpg?wh=1920x1138" alt="图片"></p><p>当然，皮下测试还有另外一个问题，就是这个离UI最近的这个“皮层”到底在哪里？</p><p>要找到这样一个合适的截面，需要结合你的项目而定。这个截面可能在网间请求，也可能就在客户端内部。但是原则就是，<strong>这个皮层离UI越近越好，能测试的逻辑最多越好，而且自动化实施的ROI越大越好</strong>。</p><h3>端到端测什么？</h3><p>皮下测试是一个准端到端的测试，本着3KU的原则，业务逻辑在单元测试已经验证过了，接口在集成测试也测过了，在端到端测试，我们的策略可以是 “Trust But Verify”，就是说信任前面阶段做的测试工作，但也要做一些基本的验证的工作。因此在策略上，端到端测试不会把全部的案例都走一遍。</p><p>那现在的端到端测什么？我们可以挑出一些测试案例，形成Workflow，作为端到端的测试案例。这个Workflow的选取原则可以参照集成测试的Happy Path。也就是说一个Workflow能够走过尽可能多的服务。</p><p>对FoodCome来说，客户下单-&gt;验证支付-&gt;餐馆接单-&gt;发送物流-&gt;通知客户，就是满足这样条件的一个Workflow。</p><h2>小结</h2><p>这一讲我们谈到了验收测试和端到端测试，这两种测试在业界经常被混在一起。还是那句话，如果它们是一回事，我们就没必要保留多余的概念。</p><p>经过我们的分析，实际上，这两者从测试角度和测试范围还是不一样的。验收测试是以客户视角，来验证是否按照契约交付，在这里我们用了Gherkins来表达契约，用Cucumber来生成测试代码，验收测试的范围是严格按照契约的内容来测试的。</p><p>对于端到端测试，我们依据3KU原则，提出了皮下测试的概念和实现方法，通过分析，这能够带来更高的ROI。</p><p>到这里，我们第二模块就结束了，我们把测试里的概念和策略都过了一遍，每种策略是什么样的，它在整体起到的什么作用。</p><p>你也可以看到，在3KU原则下，分层这个概念非常灵活：有的需求是在这个层测试，有的需求在那个层测试；甚至一个需求的一部分在这个层做，另外的部分在那个层做，只要ROI最高。</p><p>这就给自动化测试设计提出了挑战，原有的各层的测试方法就需要连接、兼容、打通，怎么做到呢？我们在第三模块设计篇，马上会引出微Job测试模型来解决这个问题。我们下一讲见吧。</p><h2><strong>思考题</strong></h2><p>UI测试、端到端测试还有验收测试的区别是什么？</p><p>欢迎你在留言区跟我交流互动，也推荐你把今天的内容分享给更多同事、朋友。</p>',
        article_title: "16｜概念重识：如何用3KU为端到端&验收测试赋能？",
      },
    ],
  },
  {
    chapterTitle: "优化还是腐化 - 设计篇",
    children: [
      {
        title: "17｜元数据模型（一）：小Job模型构建大蓝图",
        id: 512680,
        content:
          '<p>你好，我是柳胜。</p><p>在价值篇我们学习了3KU整体最优分层模型。而到了策略篇，又结合一个具体的订餐系统，为你提供了一个测试设计实现案例，演示具体如何应用3KU法则。</p><p>不过推演下来，你有没有隐约感觉到，事情有点不对劲了？以前我们是先分层，再在每个层上设计自己的TestCase，UI上的TestCase的功能定义和粒度大小，可能和API层上的TestCase完全不一样。</p><p>现在，不同的测试需求，可能会落到不同的分层截面上去做自动化。甚至，一个测试需求的不同部分，也可以放在不同截面上。比如，你可以在API上测试createOrder，在UI上测试verifyOrder，只要这样做ROI最高。</p><p>所以，在3KU法则下，自动化测试设计是先定义TestCase，然后再判断它应该落在哪个层面。这跟我们以往熟悉的自动化测试设计大相径庭，需要我们在设计方法论上有新的突破。没错，现在我们的挑战是，需要找到一种新的概念指导我们做任务建模和设计，从而跨越各层的“TestCase”。</p><p>因为内容比较多，为了让你跟得上，我安排了两讲内容，带你<strong>找到一个测试设计的元数据模型，将各种类型和层次的测试纳入到这同一个模型里。一生二，二生三，三生万物，从这一个模型里，衍生出我们自动化测试中所需要的设计方法和策略、执行计划，效益度量甚至生死定夺等等一切</strong>。</p><!-- [[[read_end]]] --><p>“好大的口气”，看到这里，我猜你会这么说，不过，你不妨耐心看完后面的内容，相信会改变你以往的认知，换一个新的角度来审视自动化测试，能抓住最关键的东西做好设计。</p><h2>TestCase的设计态和运行态</h2><p>设计新模型前，我们有必要先分析一下，原有自动化测试设计有什么问题。我们可以从设计态和运行态复盘一下，自动化测试的产生过程是怎样的，借此发现问题。这里，我们延续之前那个订餐系统的例子讲解。</p><p>先看<strong>设计态。</strong>设计态下，自动化测试表现为测试案例，一个测试集合TestSuite包含了多个测试案例TestCase。TestCase测试案例里的信息包含以下元数据：测试名字、测试环境、测试步骤、测试结果等等。</p><p>对于订餐系统里“订餐”这个测试案例，就会这么写。</p><ul>\n<li>测试名字：下单</li>\n<li>测试环境：Web终端</li>\n<li>测试步骤：第一步，登陆订餐系统；第二步，选择餐品、收货地址；第三步，下订单</li>\n<li>预期结果：下单成功，产生物流配送记录</li>\n</ul><p>然后，我们对应到运行态。在<strong>运行态</strong>下，也就是自动化测试跑起来，就成为了一个运行的程序功能。这个程序功能有自己的运行环境、对外依赖和数据交互，我们可以用微服务的六边形架构方法（参看<a href="https://time.geekbang.org/column/article/502863">第七讲</a>）描述订餐Job的运行态结构。</p><p><img src="https://static001.geekbang.org/resource/image/df/69/df80f398d588e6084b23445934d4db69.jpg?wh=1920x1285" alt="图片" title="自动化测试案例：六边形模型架构"></p><p>看到了没有，运行态的Job相比设计态的测试案例，多了不少信息，包括输入Inbound、输出Outbound、DAO，我们依次来看看。</p><ul>\n<li><strong>Inbound</strong>：本Job运行开始之前，接收的外部输入Input。</li>\n<li><strong>Outbound</strong>：本Job运行结束之后，对外的输出Output。用户在订餐系统完成下单后，会产生一个物流单号，比如123456。</li>\n<li><strong>DAO：</strong>Data Access Object,  本Job运行中需要持久化的信息。本次订餐测试运行结果的序列化，存储到数据库或文件里。</li>\n</ul><h2>原本的设计存在什么问题？</h2><p>分析完自动化测试的设计态和运行态长什么样，从内部和外部两个角度，我们很容易发现问题。</p><p>从内部看，传统的测试案例里的元素和自动化测试Job里的信息差别较大。用咱们现在流行的“元”概念来说，就是两者的元数据不一致。在基因上，它们是两个物种。</p><p>从外部看，传统测试案例之间关系比较松散，即使刚开始测试人员遵循规则来产生案例，但时间长了，也很难维护案例设计逻辑的一致性和完整性。而自动化测试Job从一开始就互相咬合，在生命周期中，遵循软件扩展和持续重构的规律：腐化或是优化。</p><p>这些问题导致了，自动化测试从设计态转化成运行态困难重重。反映到现实中，我们看到就是，测试案例设计和自动化测试实现脱节，貌合神离、各玩各的。造成的结果也很明显，就是自动化测试缺失了设计。代码一旦没有了设计，它的功能、效率、维护性、投产比都失去了追踪和控制。</p><p>那怎么解决这些问题呢？咱们开个脑洞，从软件设计的角度，重新审视一下自动化测试应该怎么做。</p><p>面向对象设计里，有Interface和Class概念，Interface定义行为表现，Class负责具体实现，Abstract Class提供代码重用。一个Interface，可以有多个实现；如果修改了Interface，那么Class也需要修改。</p><p>设计和实现解耦，但又保持一致，这个机制使得代码有内建生命力，有扩展能力而不会垮掉，对不对？</p><p>其实,我们可以把这个设计思路引入到测试模型里，测试案例设计就相当于定义Interface，暴露契约，要提供什么样的功能、达成什么目标，但是Interface不能实例化，更不能运行。</p><p>自动化测试Job就是实现了Interface的Class，有血有肉，能实例化也能跑。对一个测试案例，可以有不同的自动化实现，手工测试也相当于是测试案例的另外一个实现。如何定义这个Interface，就是我们要找的测试元数据模型。</p><p>好，说到这里，我们简单总结一下到现在的观点。</p><p>1.自动化测试和手工测试共用一套案例模型和设计方法。TestSuite和TestCase这些概念已经过时了，需要找到新的模型。</p><p>2.自动化测试设计本质是软件设计，精髓在于对测试场景的抽象和建模。这就像开发软件先设计Interface一样，而自动化测试工具和框架属于实现层面，用哪个取决于需求，而不能削足适履。</p><h2><strong>初探微测试Job模型</strong></h2><p>有了前面的推导，我们现在试图找到一个大一统的测试元数据模型，用它描述一个测试案例的设计态和运行态。为了区别于传统的测试案例，还有自动化测试脚本的叫法，我们管它叫<strong>自动化测试Job</strong>。</p><p>回顾一下运行态里的六边形，其实它已经初步勾勒出一个Job模型，但它还是像一个开发的通用模块，现在我们继续丰富它，<strong>添加更多的自动化测试基因，这个基因满足自动化测试的基本原则</strong>（你可以回顾<a href="https://time.geekbang.org/column/article/496857">第一讲</a>），让它成为一个针对自动化测试的Job。</p><p>为了对齐自动化测试的术语习惯，我们把Inbound重命名为Input，把Outbound重命名为Output。</p><p><img src="https://static001.geekbang.org/resource/image/e9/eb/e92bdfde99ffc5e5ca03c81f8f1214eb.jpg?wh=1920x1285" alt="图片" title="自动化测试Job六边形模型架构"></p><h3>模型属性</h3><p>先说结论，我们的自动化测试Job模型，除了上面的Input、Ouput和DAO 三个属性，下面还要加上Dependency、TestData、TestConfig、Document四个属性，一共七个属性。</p><p>这七个核心属性，其实是你在设计自动化测试案例时，需要考虑的七个方面，也是后续开发中要去实现的Interface（接口）。</p><p>这么多属性“扑面而来”，你也许有点应接不暇。别慌，下面我结合订餐系统例子，逐一给你解释。</p><p>对于自动化测试，我们需要创建一个依赖的概念，目的是通过阻断错误在Job链条上的传递、扩散，来缩短自动化测试的执行时间。Depedency的Job如果失败了，那么后续的Job没有必要再去运行。因此，我们要在后面的模型示意图中，用一个红色菱形描述这个<strong>Dependency。</strong>它的数据表达类型是List，存放1个或n个前置Job的名字。</p><p>结合具体例子，Depdency的使用场景更好理解。在下图，我们有2个Job，一个是登陆的Job，另外一个是下单的Job，让下单Job的前置依赖是登陆Job，登录成功后才要运行订餐案例，登陆失败则不必运行订餐案例。</p><p><img src="https://static001.geekbang.org/resource/image/d7/66/d7d533dee50603f28b6a7d4a59f38166.jpg?wh=1920x702" alt="图片" title="自动化测试Job模型Dependency"></p><p>除了可以引入Dependency概念，帮我们缩短测试执行时间，要想提升测试ROI，还有什么着手点呢？</p><p>早在<a href="https://time.geekbang.org/column/article/499382">第四讲</a>我们就说过，要提高自动化测试的ROI，一个方法就是增加自动化测试的运行次数。所以，从设计的角度来看，我们的期望是：一份代码，运行多次。这里的“多次”可以是多个场景、多个语言、多个客户端、多组数据，不管哪种，都是数据驱动的循环迭代。</p><p>所以，每一个自动化测试Job应该有一个自己的<strong>数据源TestData</strong>，它的数据表达类型是Hashmap，存放相似特征的N条KV（Key Value）数据记录，每一条KV记录触发一次Job运行。</p><p>看到这里，可能你会产生这样的疑问，在TestNG和Junit框架里，都有DataProvider机制，不就有了你说的TestData功能么？是，也不是，我们这里谈的是自动化测试Job的特征提取和建模，各个框架的DataProvider也好，DataValue也好，都是对模型的实现。</p><p>很好，我们又完成了一个TestData机制，让1份代码的产出效益翻n倍。</p><h2>课程小结</h2><p>为了设计一个更科学的模型<strong>，</strong>我们从传统自动化测试设计入手，通过传统自动化测试的设计态和运行态对比，看到了设计与实现之间的鸿沟。类似的鸿沟举不胜举，比如手工测试与自动化测试之间，测试分层之间。</p><p>从测试整体看，我们投入了这么多资源和精力，初心是编一张大网来捕捉bug的，但实际上却是各个小网工作，有重复、有遗漏，而这些问题不能度量，也无法提升。</p><p>为了编好大网，我们找到了一个统一的Job模型，用这个模型来设计我们各种类型各个层次的自动化测试，那我们不仅能明确大网有没有重复和遗漏，甚至网眼密度也可以统一。</p><p>这个Job模型包含七个属性，你在设计自动化测试的时候，需要把这七个属性想清楚。今天我们讲到了其中的5个属性，Input、Output、DAO、Dependency和TestData。</p><p>Input和Output要声明测试Job输入和输出是什么；DAO要解决自动化测试报告和Log的格式和持久化怎么做的问题；Dependency要回答的问题是，测试Job依赖的前置条件是什么，谁来提供？而TestData要回答的问题是，测试Job需要的测试数据是什么结构，有多少组？</p><p><img src="https://static001.geekbang.org/resource/image/3d/10/3da443024e8facbd7d7a6b160c16a710.jpg?wh=1920x1003" alt="图片" title="模型属性速记图"></p><p>在下一讲，我们会介绍剩下两个属性，并继续分析自动化测试设计中你必须关注的其他问题。比如，怎么保证自动化测试健壮性，你可以自己先想一下，我们下一讲一起探讨。</p><h2>思考题</h2><p>说一下你设计自动化测试任务的时候，有哪些比较好的实践，怎么在团队里推行的？</p><p>欢迎你在留言区跟我交流讨论，也推荐你把这一讲分享给更多朋友。</p>',
        article_title: "17｜元数据模型（一）：小Job模型构建大蓝图",
      },
      {
        title: "18｜元数据模型（二）：小Job模型构建大蓝图",
        id: 513617,
        content:
          '<p>你好，我是柳胜。</p><p>上一讲，我们分析了传统自动化测试设计态和运行态存在的鸿沟，并且提出了一个更科学的Job模型的设想。如下图所示，这个模型包含七个核心属性，其实也是后续在设计自动化测试案例时，我们需要考虑的七个方面，也是后续开发中要去实现的Interface（接口）。</p><p>模型属性我们上一讲开了个头，重点讲了Dependency和TestData，Dependency描述业务关联性、阻断错误、缩短执行时间，TestData可以实现一份代码多组数据运行，提升自动化测试的ROI。</p><p>今天咱们继续分析剩下的模型属性，勾勒整个Job模型的全貌，这样你就能进一步掌握自动化测试设计建模的利器了。</p><p><img src="https://static001.geekbang.org/resource/image/b7/59/b7b0596e823yya466ff87373b205e359.jpg?wh=1920x1310" alt="图片"></p><h2>模型属性</h2><p>自动化测试有一个令人头疼的问题——不稳定，经常失败，有没有办法通过设计攻克这个难题呢？</p><p>自动化测试Job像开发的微服务一样，都是独立的运行单元，我们可以通过给每个Job增加一个<strong>TestConfig</strong>，它的数据表达类型是HashMap，每一条记录代表一个配置，我们通过修改配置来控制Job的运行。结合实践，<strong>有三个关键配置，可以增强自动化测试的健壮性和诊断性，分别是：日志级别、超时时间以及重试次数</strong>。</p><p>Log是诊断程序运行问题最有力的工具，自动化测试也不例外，通过定义不同的log级别和相应输出信息，把它应用在不同环境下，可以形成一个自动化测试诊断策略。比如，Log level 如果是debug级别，抓取环境信息、屏幕截图、运行时堆栈，用于在自动化测试开发阶段做调试。Error级别记录出错trace和调用Job链状态，用在自动化测试生产运行环境。</p><!-- [[[read_end]]] --><p>我建议你在设计自动化测试Job的时候，一定要在TestConfig里加上<strong>Log_Level</strong>，用来提醒测试开发人员，在自动化开发中实现相应的Log信息的收集、分类和输出机制。</p><p>我们再看看超时问题，在自动化测试运行中，经常会因为各种奇怪的原因，导致运行不能返回，单元测试中阻塞调用不能返回，API测试中Http response超时，UI测试中页面刷不出来。</p><p>通常在技术层上不会无限等待，也有TimeOut的限制，比如http request的默认超时是120秒，我们这里关注的Timeout是执行整个Job的时间最大限值，从而保证自动化测试可以满足快速反馈的目标。</p><p>所以，我们应该在TestConfig里有一个Job的超时配置，<strong>TimeOut</strong>: 3min,  提醒自动化测试开发人员去做相应的代码实现。</p><p>定义了超时处理机制后，我们再来看看Retry重试，这是开发人员提高代码运行健壮性的常用手段，其实对于提高自动化测试的健壮性也很关键。</p><p>咱们在UI测试里经常遇到一些状况，比如在低环境里环境不稳定，有的页面刷一次出不来，第二次就没问题了。手工测试时测试人员通常会自己多刷两次，把功能测试完，这种不稳定性的问题，只要在生产环境里不重现即可。</p><p>那自动化程序怎么处理这种状况呢？我们可以加入一个<strong>Retry_Number</strong>的配置项，它的value是N。是什么意思呢？Job运行1次不成功，还可以尝试最多N-1次直到成功，或在N次失败后才返回失败状态。</p><p>在<strong>TestConfig</strong>中定义Log_Level、 TimeOut、 Retry_Number这些配置项，实际上是我们针对自动化测试的运行不稳定问题而设计的解决方案。TestConfig本身是一个HashMap，当然也可以加入其它你认为有用的配置项。至于怎么实现，那是代码阶段要去做的事情。</p><p>说完TestConfig后，别忘了我们还需要一个属性<strong>Document</strong>，来存放Job的描述信息。它的数据表达类型是一个对象，Document里可以存放Job的名字、测试执行步骤、测试环境信息等等。</p><p>到这里，我们的Job模型六边形，最终更新成了下面的样子。</p><p><img src="https://static001.geekbang.org/resource/image/e6/f7/e6de0d6d56ea556f8584de2353e51ff7.jpg?wh=1920x1310" alt="图片" title="自动化测试Job七属性模型"></p><p>讲到这里，你可能又有一个疑问：不对啊，之前学自动化测试都是在学框架，最重要的框架是不是忘了放进自动化测试Job模型里？</p><p>不，这正是我要强调的，在自动化测试Job模型里，我们关注的是设计，是如何满足测试需求和提高自动化的效益。而工具或框架，它是Job实现层面所关注的内容。</p><p>我们用Selenium也好，QTP也好，它们可以帮助我们实现设计意图，但不能喧宾夺主，倒逼我们按照它们的结构来设计，否则我们永远是一个工具使用者，而不能成为一个有设计思维的自动化测试人员。</p><p>这就相当于软件开发中，先定义了微服务实现业务接口，至于每个微服务选择哪种语言作为编程语言，选GO还是Java，这要交给开发人员根据经验和喜好权衡。</p><p>所以说，在Job模型里，七大属性是设计面的，而框架是Job实现面的。为了更好地理解，我们把刚才的六边形架构展成UML类关系图，就会看到框架在垂直下方。</p><p><img src="https://static001.geekbang.org/resource/image/83/4c/8388717b5b84d648073c0ff32ab1204c.jpg?wh=4435x2260" alt="" title="Job模型UML对象关系图"></p><h2>模型层级</h2><p>听到这里，你也许对Job模型有一点点明白了，但困惑也不少。以前接触的都是TestSuite和TestCase这些概念，这个Job模型到底说的是啥？是一个TestCase还是一个大场景？</p><p>我们暂且忘记TestSuite和TestCase，你先想一下软件设计是怎么做的：一个系统的行为设计是为了解决一个大问题，把这个大问题分解成若干个小问题，对应着系统分解成服务，依次递归下钻一直到单元级别。大问题与小问题同构，系统与服务同构，这叫自顶向下的设计。</p><p>讲到这，是不是顿时开悟了？Job模型描述的是一个同构的测试任务，它既可以是一个小小的测试案例，也可以是一个大大的测试需求。这小和大之间，是通过组合编排来完成的。</p><p>Job之间到底是如何组合的？一生二，二生三，三生万物，这描述的是一个树形关系，软件架构如此，自动化测试Job也一样。</p><p>一个Job的定义是由父节点完成，Job的实现由它的子Job们完成。我们可以类比开发的Interface、abstract class和final class，理解根节点和子节点的用处。</p><p><img src="https://static001.geekbang.org/resource/image/c6/86/c6686eb4eaa6aeebb6237dbcf9912186.jpg?wh=1920x951" alt="图片" title="Job模型层级图"></p><p>图中的根Job，是我们运行的自动化测试的任务，对应着interface。我们需要按照Job模型设计它的Input、Output、TestData、TestConfig等信息；叶子Job，这是已经实例化可运行的Job，相当于final class，也就是说一定有代码来负责这个Job的执行；在根Job与叶子Job之间的Job相当于abstract class，起到功能和接口划分的作用。</p><p>我们最终是要跑Job的，在Job跑起来的时候，会通过这个树形链接传递一些信息，我们定义以下四条规则。</p><p>1.一个Job的运行，实际上是运行其所有的子Job，并且Input和Output上也等价。也就是说，Job1 = Job11+Job12。 Job11+Job22是实现了Job1的定义。</p><p>2.Job的运行结果是其子Job们运行结果的与运算。这个很好理解，Job11和Job12全部成功，才能设定Job1成功，有一个失败，Job1就会失败。</p><p>3.子Job默认继承父Job的属性，除非自定义了属性去覆盖父Job上的同名属性。像TestConfig，比如父Job上已经定义了log级别为error，那么对其下子Job也适用，除非在子Job里定义不同的log级别。</p><p>4.一个Job的Depdency只能指向和它同一层次的Job。Job113可以一来Job112，但是不能依赖Job12。</p><p>这个层次模型，可以用自顶向下来去设计，也可以自底向上去组合。所以，根Job是相对的，不是绝对的，它完全可以和另外的Job组合在一起，生成一个更大的Job。</p><p>比如IT Ops开发的产品部署监控自动化Job对他们来说是终极任务，但是也可以和QA团队的测试自动化Job组合在一起，进行环境信息对接，形成一个部署测试一体自动化的Job，这就是我们常用的Pipeline。Pipeline本身就是一个有Input和Output的Job，Pipeline之间可以再对接组合成更多的场景。</p><h2>Job模型设计的四大优势</h2><p>好，到这里，我们已经把Job模型讲完了。明确了这个模型的设计之后，我们不妨进一步思考一下，Job模型是怎么帮助我们做好自动化测试的呢？我们可以从这四个方面来理解。</p><p><strong>第一，高可复用的自动化测试模块化设计。</strong>像软件设计逐层分解系统、子系统、服务和模块一样，自动化测试可以自顶向下分解一个大的任务，到中任务，再到小任务，直到可执行的代码级别；也可以自底向上聚合成新的测试场景，比如API测试可以和UI测试聚合生成跨端测试。</p><p><strong>第二，低成本的扩展和重构。</strong>Job任务的定义是基于自动化测试的需求，并不预先依赖于某个工具框架的实现，我们重构Job也更轻松了。更改一个Job里的实现代码，甚至更换工具从QTP切到Selenium，只要保持对外的Input和Output不变，那这就属于内部的事，不会影响到其他关联Job。这就叫高内聚，低耦合。</p><p><strong>第三，动态的生成执行计划。</strong>在Job执行的时候，根据我们定义的运行规则，就可以把树形图展成可执行的有向无环图，获得关键路径、关键Job，从而动态确定最优执行计划。</p><p><strong>第四，有助于后续的度量和改进。</strong>有了统一模型来做案例设计和自动化测试实现，我们就可以获得准确的度量数据了，比如自动化测试覆盖率、自动化测试ROI等等，可以持续驱动自动化测试效益的提升。</p><h2>课程小结</h2><p>我们通过两讲，一起推导建立了微测试Job模型。我这里再总结一下，Job模型包括属性和层级两个方面。</p><p>七个属性，其实是回答了自动化测试里，七个可以提高ROI的关键问题：</p><ul>\n<li>Input&amp;Output：测试Job的输入和输出是什么？</li>\n<li>DAO：测试Job应该用什么格式，怎么持久化自动化测试报告、日志、抓图等等。</li>\n<li>Depdedncy：测试Job的前置条件是什么，由谁来提供？</li>\n<li>TestData：测试Job的测试数据是什么结构，需要多少组？</li>\n<li>TestConfig：测试Job的运行时需不需要通过配置来调节？比如，健壮性、诊断性、环境信息等等。</li>\n<li>Document：测试Job的其它信息。</li>\n</ul><p>我准备了图解，方便你记忆：</p><p><img src="https://static001.geekbang.org/resource/image/f2/e3/f2481327e3d0dea9cdfcyy80fyy3a9e3.png?wh=1792x1142" alt="图片"></p><p>当你想清楚了这七大属性，就相当于Job的接口已经确定了。</p><p>但刚开始做自动化测试设计的时候，也是先想到一个大概要完成的任务，不可能一下子就到脚本实现的级别。就像软件设计，也是先有概要设计，再做详细设计。</p><p>微测试Job怎么赋能自动化测试开发人员做设计呢？那就是Job的层级能力，Job下面可以有子Job，一层层做细化，直到叶子节点Job，是可开发的自动化测试案例，至于怎么实现，那是自动化测试开发阶段需要考虑的事情。</p><p>你可能会问，这个Job模型真的好用么？可以用来做设计么？后面的课程里，我还会用几个实例，为你演示一下，怎么用Job模型来完成自动化测试的设计，敬请期待。</p><h2>练习题</h2><p>请用测试微Job七要素模型，描述一下你目前正在使用的测试案例。注意，不要代入工具和框架。</p><p>欢迎你在留言区跟我交流讨论，也推荐你把这一讲分享给更多朋友。</p>',
        article_title: "18｜元数据模型（二）：小Job模型构建大蓝图",
      },
    ],
  },
];
